{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, balanced_accuracy_score\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Databases/BTC/BTC-USD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>465.864014</td>\n",
       "      <td>468.174011</td>\n",
       "      <td>452.421997</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>21056800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>413.104004</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>34483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>424.102997</td>\n",
       "      <td>427.834991</td>\n",
       "      <td>384.532013</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>37919700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-20</td>\n",
       "      <td>394.673004</td>\n",
       "      <td>423.295990</td>\n",
       "      <td>389.882996</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>36863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-21</td>\n",
       "      <td>408.084991</td>\n",
       "      <td>412.425995</td>\n",
       "      <td>393.181000</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>26580100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>2024-08-26</td>\n",
       "      <td>64342.226563</td>\n",
       "      <td>64489.707031</td>\n",
       "      <td>62849.558594</td>\n",
       "      <td>62880.660156</td>\n",
       "      <td>62880.660156</td>\n",
       "      <td>27682040631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>2024-08-27</td>\n",
       "      <td>62879.707031</td>\n",
       "      <td>63210.796875</td>\n",
       "      <td>58116.750000</td>\n",
       "      <td>59504.132813</td>\n",
       "      <td>59504.132813</td>\n",
       "      <td>39103882198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>59507.925781</td>\n",
       "      <td>60236.449219</td>\n",
       "      <td>57890.675781</td>\n",
       "      <td>59027.625000</td>\n",
       "      <td>59027.625000</td>\n",
       "      <td>40289564698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>59027.468750</td>\n",
       "      <td>61184.082031</td>\n",
       "      <td>58786.226563</td>\n",
       "      <td>59388.179688</td>\n",
       "      <td>59388.179688</td>\n",
       "      <td>32224990582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>2024-08-30</td>\n",
       "      <td>59374.441406</td>\n",
       "      <td>59721.363281</td>\n",
       "      <td>58751.093750</td>\n",
       "      <td>59528.664063</td>\n",
       "      <td>59528.664063</td>\n",
       "      <td>32302868480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3636 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          Open          High           Low         Close  \\\n",
       "0     2014-09-17    465.864014    468.174011    452.421997    457.334015   \n",
       "1     2014-09-18    456.859985    456.859985    413.104004    424.440002   \n",
       "2     2014-09-19    424.102997    427.834991    384.532013    394.795990   \n",
       "3     2014-09-20    394.673004    423.295990    389.882996    408.903992   \n",
       "4     2014-09-21    408.084991    412.425995    393.181000    398.821014   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "3631  2024-08-26  64342.226563  64489.707031  62849.558594  62880.660156   \n",
       "3632  2024-08-27  62879.707031  63210.796875  58116.750000  59504.132813   \n",
       "3633  2024-08-28  59507.925781  60236.449219  57890.675781  59027.625000   \n",
       "3634  2024-08-29  59027.468750  61184.082031  58786.226563  59388.179688   \n",
       "3635  2024-08-30  59374.441406  59721.363281  58751.093750  59528.664063   \n",
       "\n",
       "         Adj Close       Volume  \n",
       "0       457.334015     21056800  \n",
       "1       424.440002     34483200  \n",
       "2       394.795990     37919700  \n",
       "3       408.903992     36863600  \n",
       "4       398.821014     26580100  \n",
       "...            ...          ...  \n",
       "3631  62880.660156  27682040631  \n",
       "3632  59504.132813  39103882198  \n",
       "3633  59027.625000  40289564698  \n",
       "3634  59388.179688  32224990582  \n",
       "3635  59528.664063  32302868480  \n",
       "\n",
       "[3636 rows x 7 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3636.000000</td>\n",
       "      <td>3636.000000</td>\n",
       "      <td>3636.000000</td>\n",
       "      <td>3636.000000</td>\n",
       "      <td>3636.000000</td>\n",
       "      <td>3.636000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17608.310300</td>\n",
       "      <td>18009.497204</td>\n",
       "      <td>17179.830799</td>\n",
       "      <td>17623.401260</td>\n",
       "      <td>17623.401260</td>\n",
       "      <td>1.756189e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19463.123079</td>\n",
       "      <td>19900.566388</td>\n",
       "      <td>18983.044122</td>\n",
       "      <td>19471.542851</td>\n",
       "      <td>19471.542851</td>\n",
       "      <td>1.919665e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>176.897003</td>\n",
       "      <td>211.731003</td>\n",
       "      <td>171.509995</td>\n",
       "      <td>178.102997</td>\n",
       "      <td>178.102997</td>\n",
       "      <td>5.914570e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1132.057526</td>\n",
       "      <td>1173.004975</td>\n",
       "      <td>1110.959991</td>\n",
       "      <td>1141.170044</td>\n",
       "      <td>1141.170044</td>\n",
       "      <td>2.823775e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9094.416504</td>\n",
       "      <td>9275.144043</td>\n",
       "      <td>8851.578613</td>\n",
       "      <td>9120.777832</td>\n",
       "      <td>9120.777832</td>\n",
       "      <td>1.373762e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29000.474121</td>\n",
       "      <td>29380.991211</td>\n",
       "      <td>28448.267090</td>\n",
       "      <td>29002.867676</td>\n",
       "      <td>29002.867676</td>\n",
       "      <td>2.844001e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>73079.375000</td>\n",
       "      <td>73750.070313</td>\n",
       "      <td>71334.093750</td>\n",
       "      <td>73083.500000</td>\n",
       "      <td>73083.500000</td>\n",
       "      <td>3.509679e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open          High           Low         Close     Adj Close  \\\n",
       "count   3636.000000   3636.000000   3636.000000   3636.000000   3636.000000   \n",
       "mean   17608.310300  18009.497204  17179.830799  17623.401260  17623.401260   \n",
       "std    19463.123079  19900.566388  18983.044122  19471.542851  19471.542851   \n",
       "min      176.897003    211.731003    171.509995    178.102997    178.102997   \n",
       "25%     1132.057526   1173.004975   1110.959991   1141.170044   1141.170044   \n",
       "50%     9094.416504   9275.144043   8851.578613   9120.777832   9120.777832   \n",
       "75%    29000.474121  29380.991211  28448.267090  29002.867676  29002.867676   \n",
       "max    73079.375000  73750.070313  71334.093750  73083.500000  73083.500000   \n",
       "\n",
       "             Volume  \n",
       "count  3.636000e+03  \n",
       "mean   1.756189e+10  \n",
       "std    1.919665e+10  \n",
       "min    5.914570e+06  \n",
       "25%    2.823775e+08  \n",
       "50%    1.373762e+10  \n",
       "75%    2.844001e+10  \n",
       "max    3.509679e+11  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         457.334015\n",
       "1         424.440002\n",
       "2         394.795990\n",
       "3         408.903992\n",
       "4         398.821014\n",
       "            ...     \n",
       "3631    62880.660156\n",
       "3632    59504.132813\n",
       "3633    59027.625000\n",
       "3634    59388.179688\n",
       "3635    59528.664063\n",
       "Name: Close, Length: 3636, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Close'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Close'].apply(np.log10).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3636"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_equals_close = data['Adj Close'] == data['Close']\n",
    "sum(adj_equals_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Adj Close', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>465.864014</td>\n",
       "      <td>468.174011</td>\n",
       "      <td>452.421997</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>21056800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>413.104004</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>34483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>424.102997</td>\n",
       "      <td>427.834991</td>\n",
       "      <td>384.532013</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>37919700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-20</td>\n",
       "      <td>394.673004</td>\n",
       "      <td>423.295990</td>\n",
       "      <td>389.882996</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>36863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-21</td>\n",
       "      <td>408.084991</td>\n",
       "      <td>412.425995</td>\n",
       "      <td>393.181000</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>26580100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>2024-08-26</td>\n",
       "      <td>64342.226563</td>\n",
       "      <td>64489.707031</td>\n",
       "      <td>62849.558594</td>\n",
       "      <td>62880.660156</td>\n",
       "      <td>27682040631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>2024-08-27</td>\n",
       "      <td>62879.707031</td>\n",
       "      <td>63210.796875</td>\n",
       "      <td>58116.750000</td>\n",
       "      <td>59504.132813</td>\n",
       "      <td>39103882198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>59507.925781</td>\n",
       "      <td>60236.449219</td>\n",
       "      <td>57890.675781</td>\n",
       "      <td>59027.625000</td>\n",
       "      <td>40289564698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>59027.468750</td>\n",
       "      <td>61184.082031</td>\n",
       "      <td>58786.226563</td>\n",
       "      <td>59388.179688</td>\n",
       "      <td>32224990582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>2024-08-30</td>\n",
       "      <td>59374.441406</td>\n",
       "      <td>59721.363281</td>\n",
       "      <td>58751.093750</td>\n",
       "      <td>59528.664063</td>\n",
       "      <td>32302868480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3636 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          Open          High           Low         Close  \\\n",
       "0     2014-09-17    465.864014    468.174011    452.421997    457.334015   \n",
       "1     2014-09-18    456.859985    456.859985    413.104004    424.440002   \n",
       "2     2014-09-19    424.102997    427.834991    384.532013    394.795990   \n",
       "3     2014-09-20    394.673004    423.295990    389.882996    408.903992   \n",
       "4     2014-09-21    408.084991    412.425995    393.181000    398.821014   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "3631  2024-08-26  64342.226563  64489.707031  62849.558594  62880.660156   \n",
       "3632  2024-08-27  62879.707031  63210.796875  58116.750000  59504.132813   \n",
       "3633  2024-08-28  59507.925781  60236.449219  57890.675781  59027.625000   \n",
       "3634  2024-08-29  59027.468750  61184.082031  58786.226563  59388.179688   \n",
       "3635  2024-08-30  59374.441406  59721.363281  58751.093750  59528.664063   \n",
       "\n",
       "           Volume  \n",
       "0        21056800  \n",
       "1        34483200  \n",
       "2        37919700  \n",
       "3        36863600  \n",
       "4        26580100  \n",
       "...           ...  \n",
       "3631  27682040631  \n",
       "3632  39103882198  \n",
       "3633  40289564698  \n",
       "3634  32224990582  \n",
       "3635  32302868480  \n",
       "\n",
       "[3636 rows x 6 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>465.864014</td>\n",
       "      <td>468.174011</td>\n",
       "      <td>452.421997</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>21056800</td>\n",
       "      <td>2.660234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>413.104004</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>34483200</td>\n",
       "      <td>2.627816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>424.102997</td>\n",
       "      <td>427.834991</td>\n",
       "      <td>384.532013</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>37919700</td>\n",
       "      <td>2.596373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-20</td>\n",
       "      <td>394.673004</td>\n",
       "      <td>423.295990</td>\n",
       "      <td>389.882996</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>36863600</td>\n",
       "      <td>2.611621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-21</td>\n",
       "      <td>408.084991</td>\n",
       "      <td>412.425995</td>\n",
       "      <td>393.181000</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>26580100</td>\n",
       "      <td>2.600778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>2024-08-26</td>\n",
       "      <td>64342.226563</td>\n",
       "      <td>64489.707031</td>\n",
       "      <td>62849.558594</td>\n",
       "      <td>62880.660156</td>\n",
       "      <td>27682040631</td>\n",
       "      <td>4.798517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>2024-08-27</td>\n",
       "      <td>62879.707031</td>\n",
       "      <td>63210.796875</td>\n",
       "      <td>58116.750000</td>\n",
       "      <td>59504.132813</td>\n",
       "      <td>39103882198</td>\n",
       "      <td>4.774547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>59507.925781</td>\n",
       "      <td>60236.449219</td>\n",
       "      <td>57890.675781</td>\n",
       "      <td>59027.625000</td>\n",
       "      <td>40289564698</td>\n",
       "      <td>4.771055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>59027.468750</td>\n",
       "      <td>61184.082031</td>\n",
       "      <td>58786.226563</td>\n",
       "      <td>59388.179688</td>\n",
       "      <td>32224990582</td>\n",
       "      <td>4.773700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>2024-08-30</td>\n",
       "      <td>59374.441406</td>\n",
       "      <td>59721.363281</td>\n",
       "      <td>58751.093750</td>\n",
       "      <td>59528.664063</td>\n",
       "      <td>32302868480</td>\n",
       "      <td>4.774726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3636 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          Open          High           Low         Close  \\\n",
       "0     2014-09-17    465.864014    468.174011    452.421997    457.334015   \n",
       "1     2014-09-18    456.859985    456.859985    413.104004    424.440002   \n",
       "2     2014-09-19    424.102997    427.834991    384.532013    394.795990   \n",
       "3     2014-09-20    394.673004    423.295990    389.882996    408.903992   \n",
       "4     2014-09-21    408.084991    412.425995    393.181000    398.821014   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "3631  2024-08-26  64342.226563  64489.707031  62849.558594  62880.660156   \n",
       "3632  2024-08-27  62879.707031  63210.796875  58116.750000  59504.132813   \n",
       "3633  2024-08-28  59507.925781  60236.449219  57890.675781  59027.625000   \n",
       "3634  2024-08-29  59027.468750  61184.082031  58786.226563  59388.179688   \n",
       "3635  2024-08-30  59374.441406  59721.363281  58751.093750  59528.664063   \n",
       "\n",
       "           Volume  Close_log  \n",
       "0        21056800   2.660234  \n",
       "1        34483200   2.627816  \n",
       "2        37919700   2.596373  \n",
       "3        36863600   2.611621  \n",
       "4        26580100   2.600778  \n",
       "...           ...        ...  \n",
       "3631  27682040631   4.798517  \n",
       "3632  39103882198   4.774547  \n",
       "3633  40289564698   4.771055  \n",
       "3634  32224990582   4.773700  \n",
       "3635  32302868480   4.774726  \n",
       "\n",
       "[3636 rows x 7 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Close_log'] = data['Close'].apply(np.log10)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close_log</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>465.864014</td>\n",
       "      <td>468.174011</td>\n",
       "      <td>452.421997</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>21056800</td>\n",
       "      <td>2.660234</td>\n",
       "      <td>-8.529999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>413.104004</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>34483200</td>\n",
       "      <td>2.627816</td>\n",
       "      <td>-32.419983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>424.102997</td>\n",
       "      <td>427.834991</td>\n",
       "      <td>384.532013</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>37919700</td>\n",
       "      <td>2.596373</td>\n",
       "      <td>-29.307007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-20</td>\n",
       "      <td>394.673004</td>\n",
       "      <td>423.295990</td>\n",
       "      <td>389.882996</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>36863600</td>\n",
       "      <td>2.611621</td>\n",
       "      <td>14.230988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-21</td>\n",
       "      <td>408.084991</td>\n",
       "      <td>412.425995</td>\n",
       "      <td>393.181000</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>26580100</td>\n",
       "      <td>2.600778</td>\n",
       "      <td>-9.263977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>2024-08-26</td>\n",
       "      <td>64342.226563</td>\n",
       "      <td>64489.707031</td>\n",
       "      <td>62849.558594</td>\n",
       "      <td>62880.660156</td>\n",
       "      <td>27682040631</td>\n",
       "      <td>4.798517</td>\n",
       "      <td>-1461.566407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>2024-08-27</td>\n",
       "      <td>62879.707031</td>\n",
       "      <td>63210.796875</td>\n",
       "      <td>58116.750000</td>\n",
       "      <td>59504.132813</td>\n",
       "      <td>39103882198</td>\n",
       "      <td>4.774547</td>\n",
       "      <td>-3375.574218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>59507.925781</td>\n",
       "      <td>60236.449219</td>\n",
       "      <td>57890.675781</td>\n",
       "      <td>59027.625000</td>\n",
       "      <td>40289564698</td>\n",
       "      <td>4.771055</td>\n",
       "      <td>-480.300781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>59027.468750</td>\n",
       "      <td>61184.082031</td>\n",
       "      <td>58786.226563</td>\n",
       "      <td>59388.179688</td>\n",
       "      <td>32224990582</td>\n",
       "      <td>4.773700</td>\n",
       "      <td>360.710938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>2024-08-30</td>\n",
       "      <td>59374.441406</td>\n",
       "      <td>59721.363281</td>\n",
       "      <td>58751.093750</td>\n",
       "      <td>59528.664063</td>\n",
       "      <td>32302868480</td>\n",
       "      <td>4.774726</td>\n",
       "      <td>154.222657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3636 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          Open          High           Low         Close  \\\n",
       "0     2014-09-17    465.864014    468.174011    452.421997    457.334015   \n",
       "1     2014-09-18    456.859985    456.859985    413.104004    424.440002   \n",
       "2     2014-09-19    424.102997    427.834991    384.532013    394.795990   \n",
       "3     2014-09-20    394.673004    423.295990    389.882996    408.903992   \n",
       "4     2014-09-21    408.084991    412.425995    393.181000    398.821014   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "3631  2024-08-26  64342.226563  64489.707031  62849.558594  62880.660156   \n",
       "3632  2024-08-27  62879.707031  63210.796875  58116.750000  59504.132813   \n",
       "3633  2024-08-28  59507.925781  60236.449219  57890.675781  59027.625000   \n",
       "3634  2024-08-29  59027.468750  61184.082031  58786.226563  59388.179688   \n",
       "3635  2024-08-30  59374.441406  59721.363281  58751.093750  59528.664063   \n",
       "\n",
       "           Volume  Close_log   Difference  \n",
       "0        21056800   2.660234    -8.529999  \n",
       "1        34483200   2.627816   -32.419983  \n",
       "2        37919700   2.596373   -29.307007  \n",
       "3        36863600   2.611621    14.230988  \n",
       "4        26580100   2.600778    -9.263977  \n",
       "...           ...        ...          ...  \n",
       "3631  27682040631   4.798517 -1461.566407  \n",
       "3632  39103882198   4.774547 -3375.574218  \n",
       "3633  40289564698   4.771055  -480.300781  \n",
       "3634  32224990582   4.773700   360.710938  \n",
       "3635  32302868480   4.774726   154.222657  \n",
       "\n",
       "[3636 rows x 8 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Difference'] = data['Close'] - data['Open']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Difference'].hist(bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close_log</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Difference_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>465.864014</td>\n",
       "      <td>468.174011</td>\n",
       "      <td>452.421997</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>21056800</td>\n",
       "      <td>2.660234</td>\n",
       "      <td>-8.529999</td>\n",
       "      <td>-0.018310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>413.104004</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>34483200</td>\n",
       "      <td>2.627816</td>\n",
       "      <td>-32.419983</td>\n",
       "      <td>-0.070963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>424.102997</td>\n",
       "      <td>427.834991</td>\n",
       "      <td>384.532013</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>37919700</td>\n",
       "      <td>2.596373</td>\n",
       "      <td>-29.307007</td>\n",
       "      <td>-0.069104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-20</td>\n",
       "      <td>394.673004</td>\n",
       "      <td>423.295990</td>\n",
       "      <td>389.882996</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>36863600</td>\n",
       "      <td>2.611621</td>\n",
       "      <td>14.230988</td>\n",
       "      <td>0.036058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-21</td>\n",
       "      <td>408.084991</td>\n",
       "      <td>412.425995</td>\n",
       "      <td>393.181000</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>26580100</td>\n",
       "      <td>2.600778</td>\n",
       "      <td>-9.263977</td>\n",
       "      <td>-0.022701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>2024-08-26</td>\n",
       "      <td>64342.226563</td>\n",
       "      <td>64489.707031</td>\n",
       "      <td>62849.558594</td>\n",
       "      <td>62880.660156</td>\n",
       "      <td>27682040631</td>\n",
       "      <td>4.798517</td>\n",
       "      <td>-1461.566407</td>\n",
       "      <td>-0.022716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>2024-08-27</td>\n",
       "      <td>62879.707031</td>\n",
       "      <td>63210.796875</td>\n",
       "      <td>58116.750000</td>\n",
       "      <td>59504.132813</td>\n",
       "      <td>39103882198</td>\n",
       "      <td>4.774547</td>\n",
       "      <td>-3375.574218</td>\n",
       "      <td>-0.053683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>59507.925781</td>\n",
       "      <td>60236.449219</td>\n",
       "      <td>57890.675781</td>\n",
       "      <td>59027.625000</td>\n",
       "      <td>40289564698</td>\n",
       "      <td>4.771055</td>\n",
       "      <td>-480.300781</td>\n",
       "      <td>-0.008071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>59027.468750</td>\n",
       "      <td>61184.082031</td>\n",
       "      <td>58786.226563</td>\n",
       "      <td>59388.179688</td>\n",
       "      <td>32224990582</td>\n",
       "      <td>4.773700</td>\n",
       "      <td>360.710938</td>\n",
       "      <td>0.006111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>2024-08-30</td>\n",
       "      <td>59374.441406</td>\n",
       "      <td>59721.363281</td>\n",
       "      <td>58751.093750</td>\n",
       "      <td>59528.664063</td>\n",
       "      <td>32302868480</td>\n",
       "      <td>4.774726</td>\n",
       "      <td>154.222657</td>\n",
       "      <td>0.002597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3636 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          Open          High           Low         Close  \\\n",
       "0     2014-09-17    465.864014    468.174011    452.421997    457.334015   \n",
       "1     2014-09-18    456.859985    456.859985    413.104004    424.440002   \n",
       "2     2014-09-19    424.102997    427.834991    384.532013    394.795990   \n",
       "3     2014-09-20    394.673004    423.295990    389.882996    408.903992   \n",
       "4     2014-09-21    408.084991    412.425995    393.181000    398.821014   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "3631  2024-08-26  64342.226563  64489.707031  62849.558594  62880.660156   \n",
       "3632  2024-08-27  62879.707031  63210.796875  58116.750000  59504.132813   \n",
       "3633  2024-08-28  59507.925781  60236.449219  57890.675781  59027.625000   \n",
       "3634  2024-08-29  59027.468750  61184.082031  58786.226563  59388.179688   \n",
       "3635  2024-08-30  59374.441406  59721.363281  58751.093750  59528.664063   \n",
       "\n",
       "           Volume  Close_log   Difference  Difference_Percentage  \n",
       "0        21056800   2.660234    -8.529999              -0.018310  \n",
       "1        34483200   2.627816   -32.419983              -0.070963  \n",
       "2        37919700   2.596373   -29.307007              -0.069104  \n",
       "3        36863600   2.611621    14.230988               0.036058  \n",
       "4        26580100   2.600778    -9.263977              -0.022701  \n",
       "...           ...        ...          ...                    ...  \n",
       "3631  27682040631   4.798517 -1461.566407              -0.022716  \n",
       "3632  39103882198   4.774547 -3375.574218              -0.053683  \n",
       "3633  40289564698   4.771055  -480.300781              -0.008071  \n",
       "3634  32224990582   4.773700   360.710938               0.006111  \n",
       "3635  32302868480   4.774726   154.222657               0.002597  \n",
       "\n",
       "[3636 rows x 9 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Difference_Percentage'] = data['Close'] / data['Open'] - 1\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Difference_Percentage'].hist(bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close_log</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Difference_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3636.000000</td>\n",
       "      <td>3636.000000</td>\n",
       "      <td>3636.000000</td>\n",
       "      <td>3636.000000</td>\n",
       "      <td>3.636000e+03</td>\n",
       "      <td>3636.000000</td>\n",
       "      <td>3636.000000</td>\n",
       "      <td>3636.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17608.310300</td>\n",
       "      <td>18009.497204</td>\n",
       "      <td>17179.830799</td>\n",
       "      <td>17623.401260</td>\n",
       "      <td>1.756189e+10</td>\n",
       "      <td>3.794419</td>\n",
       "      <td>15.090960</td>\n",
       "      <td>0.001940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19463.123079</td>\n",
       "      <td>19900.566388</td>\n",
       "      <td>18983.044122</td>\n",
       "      <td>19471.542851</td>\n",
       "      <td>1.919665e+10</td>\n",
       "      <td>0.782740</td>\n",
       "      <td>884.657221</td>\n",
       "      <td>0.036423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>176.897003</td>\n",
       "      <td>211.731003</td>\n",
       "      <td>171.509995</td>\n",
       "      <td>178.102997</td>\n",
       "      <td>5.914570e+06</td>\n",
       "      <td>2.250671</td>\n",
       "      <td>-7563.996094</td>\n",
       "      <td>-0.371869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1132.057526</td>\n",
       "      <td>1173.004975</td>\n",
       "      <td>1110.959991</td>\n",
       "      <td>1141.170044</td>\n",
       "      <td>2.823775e+08</td>\n",
       "      <td>3.057347</td>\n",
       "      <td>-103.439453</td>\n",
       "      <td>-0.012749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9094.416504</td>\n",
       "      <td>9275.144043</td>\n",
       "      <td>8851.578613</td>\n",
       "      <td>9120.777832</td>\n",
       "      <td>1.373762e+10</td>\n",
       "      <td>3.960032</td>\n",
       "      <td>1.444985</td>\n",
       "      <td>0.001176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29000.474121</td>\n",
       "      <td>29380.991211</td>\n",
       "      <td>28448.267090</td>\n",
       "      <td>29002.867676</td>\n",
       "      <td>2.844001e+10</td>\n",
       "      <td>4.462441</td>\n",
       "      <td>129.155884</td>\n",
       "      <td>0.016828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>73079.375000</td>\n",
       "      <td>73750.070313</td>\n",
       "      <td>71334.093750</td>\n",
       "      <td>73083.500000</td>\n",
       "      <td>3.509679e+11</td>\n",
       "      <td>4.863819</td>\n",
       "      <td>7309.636719</td>\n",
       "      <td>0.254702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open          High           Low         Close        Volume  \\\n",
       "count   3636.000000   3636.000000   3636.000000   3636.000000  3.636000e+03   \n",
       "mean   17608.310300  18009.497204  17179.830799  17623.401260  1.756189e+10   \n",
       "std    19463.123079  19900.566388  18983.044122  19471.542851  1.919665e+10   \n",
       "min      176.897003    211.731003    171.509995    178.102997  5.914570e+06   \n",
       "25%     1132.057526   1173.004975   1110.959991   1141.170044  2.823775e+08   \n",
       "50%     9094.416504   9275.144043   8851.578613   9120.777832  1.373762e+10   \n",
       "75%    29000.474121  29380.991211  28448.267090  29002.867676  2.844001e+10   \n",
       "max    73079.375000  73750.070313  71334.093750  73083.500000  3.509679e+11   \n",
       "\n",
       "         Close_log   Difference  Difference_Percentage  \n",
       "count  3636.000000  3636.000000            3636.000000  \n",
       "mean      3.794419    15.090960               0.001940  \n",
       "std       0.782740   884.657221               0.036423  \n",
       "min       2.250671 -7563.996094              -0.371869  \n",
       "25%       3.057347  -103.439453              -0.012749  \n",
       "50%       3.960032     1.444985               0.001176  \n",
       "75%       4.462441   129.155884               0.016828  \n",
       "max       4.863819  7309.636719               0.254702  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close_log</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Difference_Percentage</th>\n",
       "      <th>Following_Day_Difference_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>465.864014</td>\n",
       "      <td>468.174011</td>\n",
       "      <td>452.421997</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>21056800</td>\n",
       "      <td>2.660234</td>\n",
       "      <td>-8.529999</td>\n",
       "      <td>-0.018310</td>\n",
       "      <td>-0.070963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>413.104004</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>34483200</td>\n",
       "      <td>2.627816</td>\n",
       "      <td>-32.419983</td>\n",
       "      <td>-0.070963</td>\n",
       "      <td>-0.069104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>424.102997</td>\n",
       "      <td>427.834991</td>\n",
       "      <td>384.532013</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>37919700</td>\n",
       "      <td>2.596373</td>\n",
       "      <td>-29.307007</td>\n",
       "      <td>-0.069104</td>\n",
       "      <td>0.036058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-20</td>\n",
       "      <td>394.673004</td>\n",
       "      <td>423.295990</td>\n",
       "      <td>389.882996</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>36863600</td>\n",
       "      <td>2.611621</td>\n",
       "      <td>14.230988</td>\n",
       "      <td>0.036058</td>\n",
       "      <td>-0.022701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-21</td>\n",
       "      <td>408.084991</td>\n",
       "      <td>412.425995</td>\n",
       "      <td>393.181000</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>26580100</td>\n",
       "      <td>2.600778</td>\n",
       "      <td>-9.263977</td>\n",
       "      <td>-0.022701</td>\n",
       "      <td>0.007647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>2024-08-26</td>\n",
       "      <td>64342.226563</td>\n",
       "      <td>64489.707031</td>\n",
       "      <td>62849.558594</td>\n",
       "      <td>62880.660156</td>\n",
       "      <td>27682040631</td>\n",
       "      <td>4.798517</td>\n",
       "      <td>-1461.566407</td>\n",
       "      <td>-0.022716</td>\n",
       "      <td>-0.053683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>2024-08-27</td>\n",
       "      <td>62879.707031</td>\n",
       "      <td>63210.796875</td>\n",
       "      <td>58116.750000</td>\n",
       "      <td>59504.132813</td>\n",
       "      <td>39103882198</td>\n",
       "      <td>4.774547</td>\n",
       "      <td>-3375.574218</td>\n",
       "      <td>-0.053683</td>\n",
       "      <td>-0.008071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>59507.925781</td>\n",
       "      <td>60236.449219</td>\n",
       "      <td>57890.675781</td>\n",
       "      <td>59027.625000</td>\n",
       "      <td>40289564698</td>\n",
       "      <td>4.771055</td>\n",
       "      <td>-480.300781</td>\n",
       "      <td>-0.008071</td>\n",
       "      <td>0.006111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>59027.468750</td>\n",
       "      <td>61184.082031</td>\n",
       "      <td>58786.226563</td>\n",
       "      <td>59388.179688</td>\n",
       "      <td>32224990582</td>\n",
       "      <td>4.773700</td>\n",
       "      <td>360.710938</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>0.002597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>2024-08-30</td>\n",
       "      <td>59374.441406</td>\n",
       "      <td>59721.363281</td>\n",
       "      <td>58751.093750</td>\n",
       "      <td>59528.664063</td>\n",
       "      <td>32302868480</td>\n",
       "      <td>4.774726</td>\n",
       "      <td>154.222657</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3636 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          Open          High           Low         Close  \\\n",
       "0     2014-09-17    465.864014    468.174011    452.421997    457.334015   \n",
       "1     2014-09-18    456.859985    456.859985    413.104004    424.440002   \n",
       "2     2014-09-19    424.102997    427.834991    384.532013    394.795990   \n",
       "3     2014-09-20    394.673004    423.295990    389.882996    408.903992   \n",
       "4     2014-09-21    408.084991    412.425995    393.181000    398.821014   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "3631  2024-08-26  64342.226563  64489.707031  62849.558594  62880.660156   \n",
       "3632  2024-08-27  62879.707031  63210.796875  58116.750000  59504.132813   \n",
       "3633  2024-08-28  59507.925781  60236.449219  57890.675781  59027.625000   \n",
       "3634  2024-08-29  59027.468750  61184.082031  58786.226563  59388.179688   \n",
       "3635  2024-08-30  59374.441406  59721.363281  58751.093750  59528.664063   \n",
       "\n",
       "           Volume  Close_log   Difference  Difference_Percentage  \\\n",
       "0        21056800   2.660234    -8.529999              -0.018310   \n",
       "1        34483200   2.627816   -32.419983              -0.070963   \n",
       "2        37919700   2.596373   -29.307007              -0.069104   \n",
       "3        36863600   2.611621    14.230988               0.036058   \n",
       "4        26580100   2.600778    -9.263977              -0.022701   \n",
       "...           ...        ...          ...                    ...   \n",
       "3631  27682040631   4.798517 -1461.566407              -0.022716   \n",
       "3632  39103882198   4.774547 -3375.574218              -0.053683   \n",
       "3633  40289564698   4.771055  -480.300781              -0.008071   \n",
       "3634  32224990582   4.773700   360.710938               0.006111   \n",
       "3635  32302868480   4.774726   154.222657               0.002597   \n",
       "\n",
       "      Following_Day_Difference_Percentage  \n",
       "0                               -0.070963  \n",
       "1                               -0.069104  \n",
       "2                                0.036058  \n",
       "3                               -0.022701  \n",
       "4                                0.007647  \n",
       "...                                   ...  \n",
       "3631                            -0.053683  \n",
       "3632                            -0.008071  \n",
       "3633                             0.006111  \n",
       "3634                             0.002597  \n",
       "3635                                  NaN  \n",
       "\n",
       "[3636 rows x 10 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Following_Day_Difference_Percentage'] = data['Difference_Percentage'].shift(-1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close_log</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Difference_Percentage</th>\n",
       "      <th>Following_Day_Difference_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>465.864014</td>\n",
       "      <td>468.174011</td>\n",
       "      <td>452.421997</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>21056800</td>\n",
       "      <td>2.660234</td>\n",
       "      <td>-8.529999</td>\n",
       "      <td>-0.018310</td>\n",
       "      <td>-0.070963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>413.104004</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>34483200</td>\n",
       "      <td>2.627816</td>\n",
       "      <td>-32.419983</td>\n",
       "      <td>-0.070963</td>\n",
       "      <td>-0.069104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>424.102997</td>\n",
       "      <td>427.834991</td>\n",
       "      <td>384.532013</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>37919700</td>\n",
       "      <td>2.596373</td>\n",
       "      <td>-29.307007</td>\n",
       "      <td>-0.069104</td>\n",
       "      <td>0.036058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-20</td>\n",
       "      <td>394.673004</td>\n",
       "      <td>423.295990</td>\n",
       "      <td>389.882996</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>36863600</td>\n",
       "      <td>2.611621</td>\n",
       "      <td>14.230988</td>\n",
       "      <td>0.036058</td>\n",
       "      <td>-0.022701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-21</td>\n",
       "      <td>408.084991</td>\n",
       "      <td>412.425995</td>\n",
       "      <td>393.181000</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>26580100</td>\n",
       "      <td>2.600778</td>\n",
       "      <td>-9.263977</td>\n",
       "      <td>-0.022701</td>\n",
       "      <td>0.007647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>2024-08-25</td>\n",
       "      <td>64176.367188</td>\n",
       "      <td>64996.421875</td>\n",
       "      <td>63833.519531</td>\n",
       "      <td>64333.542969</td>\n",
       "      <td>18827683555</td>\n",
       "      <td>4.808437</td>\n",
       "      <td>157.175781</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>-0.022716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>2024-08-26</td>\n",
       "      <td>64342.226563</td>\n",
       "      <td>64489.707031</td>\n",
       "      <td>62849.558594</td>\n",
       "      <td>62880.660156</td>\n",
       "      <td>27682040631</td>\n",
       "      <td>4.798517</td>\n",
       "      <td>-1461.566407</td>\n",
       "      <td>-0.022716</td>\n",
       "      <td>-0.053683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>2024-08-27</td>\n",
       "      <td>62879.707031</td>\n",
       "      <td>63210.796875</td>\n",
       "      <td>58116.750000</td>\n",
       "      <td>59504.132813</td>\n",
       "      <td>39103882198</td>\n",
       "      <td>4.774547</td>\n",
       "      <td>-3375.574218</td>\n",
       "      <td>-0.053683</td>\n",
       "      <td>-0.008071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>59507.925781</td>\n",
       "      <td>60236.449219</td>\n",
       "      <td>57890.675781</td>\n",
       "      <td>59027.625000</td>\n",
       "      <td>40289564698</td>\n",
       "      <td>4.771055</td>\n",
       "      <td>-480.300781</td>\n",
       "      <td>-0.008071</td>\n",
       "      <td>0.006111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>59027.468750</td>\n",
       "      <td>61184.082031</td>\n",
       "      <td>58786.226563</td>\n",
       "      <td>59388.179688</td>\n",
       "      <td>32224990582</td>\n",
       "      <td>4.773700</td>\n",
       "      <td>360.710938</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>0.002597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3635 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          Open          High           Low         Close  \\\n",
       "0     2014-09-17    465.864014    468.174011    452.421997    457.334015   \n",
       "1     2014-09-18    456.859985    456.859985    413.104004    424.440002   \n",
       "2     2014-09-19    424.102997    427.834991    384.532013    394.795990   \n",
       "3     2014-09-20    394.673004    423.295990    389.882996    408.903992   \n",
       "4     2014-09-21    408.084991    412.425995    393.181000    398.821014   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "3630  2024-08-25  64176.367188  64996.421875  63833.519531  64333.542969   \n",
       "3631  2024-08-26  64342.226563  64489.707031  62849.558594  62880.660156   \n",
       "3632  2024-08-27  62879.707031  63210.796875  58116.750000  59504.132813   \n",
       "3633  2024-08-28  59507.925781  60236.449219  57890.675781  59027.625000   \n",
       "3634  2024-08-29  59027.468750  61184.082031  58786.226563  59388.179688   \n",
       "\n",
       "           Volume  Close_log   Difference  Difference_Percentage  \\\n",
       "0        21056800   2.660234    -8.529999              -0.018310   \n",
       "1        34483200   2.627816   -32.419983              -0.070963   \n",
       "2        37919700   2.596373   -29.307007              -0.069104   \n",
       "3        36863600   2.611621    14.230988               0.036058   \n",
       "4        26580100   2.600778    -9.263977              -0.022701   \n",
       "...           ...        ...          ...                    ...   \n",
       "3630  18827683555   4.808437   157.175781               0.002449   \n",
       "3631  27682040631   4.798517 -1461.566407              -0.022716   \n",
       "3632  39103882198   4.774547 -3375.574218              -0.053683   \n",
       "3633  40289564698   4.771055  -480.300781              -0.008071   \n",
       "3634  32224990582   4.773700   360.710938               0.006111   \n",
       "\n",
       "      Following_Day_Difference_Percentage  \n",
       "0                               -0.070963  \n",
       "1                               -0.069104  \n",
       "2                                0.036058  \n",
       "3                               -0.022701  \n",
       "4                                0.007647  \n",
       "...                                   ...  \n",
       "3630                            -0.022716  \n",
       "3631                            -0.053683  \n",
       "3632                            -0.008071  \n",
       "3633                             0.006111  \n",
       "3634                             0.002597  \n",
       "\n",
       "[3635 rows x 10 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = data.dropna()\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "    X = data[['Open', 'High', 'Low', 'Close', 'Volume', 'Close_log', 'Difference', 'Difference_Percentage']]\n",
    "    Y = data['Following_Day_Difference_Percentage']\n",
    "\n",
    "    total_lines = len(X)\n",
    "    train_lines = int(total_lines * 0.8)\n",
    "\n",
    "    X_train = X[:train_lines]\n",
    "    y_train = Y[:train_lines]\n",
    "    X_test = X[train_lines:]\n",
    "    y_test = Y[train_lines:]\n",
    "\n",
    "    return X_train.reset_index(drop=True), y_train.reset_index(drop=True), X_test.reset_index(drop=True), y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels, test_features, test_labels = load_data(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2908, 8), (2908,), (727, 8), (727,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, train_labels.shape, test_features.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2901, 8, 7), Training labels shape: (2901,)\n",
      "Testing data shape: (720, 8, 7), Testing labels shape: (720,)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_features)\n",
    "X_test = scaler.fit_transform(test_features)\n",
    "\n",
    "# Reshape data into sequences\n",
    "def create_sequences(data, labels, sequence_length):\n",
    "    sequences = []\n",
    "    seq_labels = []\n",
    "    \n",
    "    for i in range(len(data) - sequence_length):\n",
    "        seq = data[i:i+sequence_length]\n",
    "        label = labels[i+sequence_length-1]\n",
    "        sequences.append(seq)\n",
    "        seq_labels.append(label)\n",
    "    \n",
    "    return np.array(sequences), np.array(seq_labels)\n",
    "\n",
    "X_train, y_train = create_sequences(X_train, train_labels, SEQUENCE_LENGTH)\n",
    "X_test, y_test = create_sequences(X_test, test_labels, SEQUENCE_LENGTH)\n",
    "\n",
    "X_train = np.transpose(X_train, (0, 2, 1))\n",
    "X_test = np.transpose(X_test, (0, 2, 1))\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f'Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}')\n",
    "print(f'Testing data shape: {X_test.shape}, Testing labels shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PEN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(PEN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=2, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=2, batch_first=True)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Linear(hidden_size + 128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional path\n",
    "        x_cnn = self.conv1(x)\n",
    "        x_cnn = self.bn1(x_cnn)\n",
    "        x_cnn = self.relu(x_cnn)\n",
    "        x_cnn = self.pool(x_cnn)\n",
    "\n",
    "        x_cnn = self.conv2(x_cnn)\n",
    "        x_cnn = self.bn2(x_cnn)\n",
    "        x_cnn = self.relu(x_cnn)\n",
    "        x_cnn = self.pool(x_cnn)\n",
    "\n",
    "        x_cnn = self.conv3(x_cnn)\n",
    "        x_cnn = self.bn3(x_cnn)\n",
    "        x_cnn = self.relu(x_cnn)\n",
    "        x_cnn = self.pool(x_cnn)\n",
    "        \n",
    "        x_cnn = x_cnn.mean(dim=-1)  # Global Average Pooling\n",
    "\n",
    "        # LSTM path\n",
    "        x_lstm, _ = self.lstm(x.transpose(1, 2))  # Transpose to match LSTM input shape\n",
    "        x_lstm = x_lstm[:, -1, :]  # Take the last output of the sequence\n",
    "\n",
    "        # Concatenate CNN and LSTM paths\n",
    "        x = torch.cat((x_cnn, x_lstm), dim=1)\n",
    "\n",
    "        # Fully connected layer\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(loader, model):\n",
    "    model.eval()\n",
    "    total_mse = 0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in loader:\n",
    "            data, labels = x_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            outputs = model(data)\n",
    "            mse = torch.mean((outputs - labels) ** 2).item()\n",
    "            total_mse += mse\n",
    "    model.train()\n",
    "    return total_mse / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, criterion, optimizer, num_epochs, verbose=False):\n",
    "    model.train()\n",
    "    total_training_time = 0\n",
    "    times = []\n",
    "    train_losses = []\n",
    "    train_mses = []  # Mean Squared Error for training\n",
    "    test_mses = []   # Mean Squared Error for testing\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_epoch_time = time.time()\n",
    "        total_loss = 0\n",
    "\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            data, labels = x_batch.to(DEVICE), y_batch.to(DEVICE).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        end_epoch_time = time.time()\n",
    "        epoch_time = end_epoch_time - start_epoch_time\n",
    "        total_training_time += epoch_time\n",
    "        \n",
    "        # Compute training and testing MSE\n",
    "        train_mse = compute_mse(train_loader, model)\n",
    "        test_mse = compute_mse(test_loader, model)\n",
    "        \n",
    "        train_mses.append(train_mse)\n",
    "        test_mses.append(test_mse)\n",
    "        train_losses.append(avg_loss)\n",
    "        times.append(epoch_time)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_loss:.10f}, Train MSE: {train_mse:.10f}, \\\n",
    "            Test MSE: {test_mse:.10f}, Time: {epoch_time:.2f} seconds')\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Total Training Time: {total_training_time:.2f} seconds')\n",
    "\n",
    "    return train_losses, train_mses, test_mses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model, criterion, and optimizer\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 128\n",
    "\n",
    "model = PEN(input_size, hidden_size).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Train Loss: 0.0001041667, Train MSE: 0.0000436295,             Test MSE: 0.0001404836, Time: 1.18 seconds\n",
      "Epoch [2/1000], Train Loss: 0.0000923318, Train MSE: 0.0000687160,             Test MSE: 0.0001142291, Time: 1.20 seconds\n",
      "Epoch [3/1000], Train Loss: 0.0000862589, Train MSE: 0.0001422160,             Test MSE: 0.0001724184, Time: 1.23 seconds\n",
      "Epoch [4/1000], Train Loss: 0.0001702891, Train MSE: 0.0002665287,             Test MSE: 0.0002867887, Time: 1.20 seconds\n",
      "Epoch [5/1000], Train Loss: 0.0000906945, Train MSE: 0.0001308016,             Test MSE: 0.0001706362, Time: 1.26 seconds\n",
      "Epoch [6/1000], Train Loss: 0.0001313415, Train MSE: 0.0002129148,             Test MSE: 0.0002197490, Time: 1.26 seconds\n",
      "Epoch [7/1000], Train Loss: 0.0001068258, Train MSE: 0.0000131957,             Test MSE: 0.0000590506, Time: 1.27 seconds\n",
      "Epoch [8/1000], Train Loss: 0.0000360170, Train MSE: 0.0000465826,             Test MSE: 0.0000707639, Time: 1.28 seconds\n",
      "Epoch [9/1000], Train Loss: 0.0000331395, Train MSE: 0.0000334355,             Test MSE: 0.0000757739, Time: 1.34 seconds\n",
      "Epoch [10/1000], Train Loss: 0.0000443807, Train MSE: 0.0000273647,             Test MSE: 0.0000853411, Time: 1.64 seconds\n",
      "Epoch [11/1000], Train Loss: 0.0000367542, Train MSE: 0.0000227489,             Test MSE: 0.0000601175, Time: 2.05 seconds\n",
      "Epoch [12/1000], Train Loss: 0.0000416125, Train MSE: 0.0000161051,             Test MSE: 0.0000380795, Time: 1.42 seconds\n",
      "Epoch [13/1000], Train Loss: 0.0000288556, Train MSE: 0.0000195445,             Test MSE: 0.0000471536, Time: 1.67 seconds\n",
      "Epoch [14/1000], Train Loss: 0.0000355416, Train MSE: 0.0000176647,             Test MSE: 0.0000665925, Time: 1.55 seconds\n",
      "Epoch [15/1000], Train Loss: 0.0000313648, Train MSE: 0.0000390158,             Test MSE: 0.0000501609, Time: 1.43 seconds\n",
      "Epoch [16/1000], Train Loss: 0.0000455968, Train MSE: 0.0000486851,             Test MSE: 0.0000924876, Time: 1.67 seconds\n",
      "Epoch [17/1000], Train Loss: 0.0000861127, Train MSE: 0.0000229208,             Test MSE: 0.0000425605, Time: 1.48 seconds\n",
      "Epoch [18/1000], Train Loss: 0.0000735308, Train MSE: 0.0000564462,             Test MSE: 0.0000812316, Time: 1.52 seconds\n",
      "Epoch [19/1000], Train Loss: 0.0000813548, Train MSE: 0.0002945949,             Test MSE: 0.0002980629, Time: 1.41 seconds\n",
      "Epoch [20/1000], Train Loss: 0.0001686412, Train MSE: 0.0001567171,             Test MSE: 0.0001874911, Time: 1.46 seconds\n",
      "Epoch [21/1000], Train Loss: 0.0000512201, Train MSE: 0.0000088656,             Test MSE: 0.0000246630, Time: 1.67 seconds\n",
      "Epoch [22/1000], Train Loss: 0.0000480776, Train MSE: 0.0000417958,             Test MSE: 0.0000491673, Time: 1.36 seconds\n",
      "Epoch [23/1000], Train Loss: 0.0000506633, Train MSE: 0.0001413628,             Test MSE: 0.0001477883, Time: 1.42 seconds\n",
      "Epoch [24/1000], Train Loss: 0.0000540117, Train MSE: 0.0000060090,             Test MSE: 0.0000278439, Time: 1.85 seconds\n",
      "Epoch [25/1000], Train Loss: 0.0000407434, Train MSE: 0.0000255746,             Test MSE: 0.0000317630, Time: 2.07 seconds\n",
      "Epoch [26/1000], Train Loss: 0.0000987717, Train MSE: 0.0000188401,             Test MSE: 0.0000237555, Time: 1.79 seconds\n",
      "Epoch [27/1000], Train Loss: 0.0000490853, Train MSE: 0.0000094208,             Test MSE: 0.0000208615, Time: 1.67 seconds\n",
      "Epoch [28/1000], Train Loss: 0.0000486533, Train MSE: 0.0000181864,             Test MSE: 0.0000413717, Time: 1.80 seconds\n",
      "Epoch [29/1000], Train Loss: 0.0000787276, Train MSE: 0.0000543461,             Test MSE: 0.0000467981, Time: 1.72 seconds\n",
      "Epoch [30/1000], Train Loss: 0.0000352892, Train MSE: 0.0000228565,             Test MSE: 0.0000437049, Time: 1.48 seconds\n",
      "Epoch [31/1000], Train Loss: 0.0000341686, Train MSE: 0.0000450990,             Test MSE: 0.0000372915, Time: 1.48 seconds\n",
      "Epoch [32/1000], Train Loss: 0.0000300585, Train MSE: 0.0000463214,             Test MSE: 0.0000566312, Time: 1.29 seconds\n",
      "Epoch [33/1000], Train Loss: 0.0000716577, Train MSE: 0.0001033405,             Test MSE: 0.0001104896, Time: 1.33 seconds\n",
      "Epoch [34/1000], Train Loss: 0.0000242659, Train MSE: 0.0000260275,             Test MSE: 0.0000399602, Time: 1.26 seconds\n",
      "Epoch [35/1000], Train Loss: 0.0000249241, Train MSE: 0.0000249115,             Test MSE: 0.0000284827, Time: 1.29 seconds\n",
      "Epoch [36/1000], Train Loss: 0.0000189266, Train MSE: 0.0000053172,             Test MSE: 0.0000096428, Time: 1.34 seconds\n",
      "Epoch [37/1000], Train Loss: 0.0000396701, Train MSE: 0.0000286979,             Test MSE: 0.0000329737, Time: 1.25 seconds\n",
      "Epoch [38/1000], Train Loss: 0.0000278804, Train MSE: 0.0001548829,             Test MSE: 0.0000864314, Time: 1.37 seconds\n",
      "Epoch [39/1000], Train Loss: 0.0000398264, Train MSE: 0.0000495373,             Test MSE: 0.0000434110, Time: 1.39 seconds\n",
      "Epoch [40/1000], Train Loss: 0.0000126119, Train MSE: 0.0000207833,             Test MSE: 0.0000217871, Time: 1.33 seconds\n",
      "Epoch [41/1000], Train Loss: 0.0000211268, Train MSE: 0.0000109726,             Test MSE: 0.0000129983, Time: 1.31 seconds\n",
      "Epoch [42/1000], Train Loss: 0.0000795291, Train MSE: 0.0000482799,             Test MSE: 0.0000361685, Time: 1.37 seconds\n",
      "Epoch [43/1000], Train Loss: 0.0000356158, Train MSE: 0.0000033504,             Test MSE: 0.0000054105, Time: 1.25 seconds\n",
      "Epoch [44/1000], Train Loss: 0.0000243434, Train MSE: 0.0000051209,             Test MSE: 0.0000102558, Time: 1.40 seconds\n",
      "Epoch [45/1000], Train Loss: 0.0000197085, Train MSE: 0.0000141451,             Test MSE: 0.0000168635, Time: 1.55 seconds\n",
      "Epoch [46/1000], Train Loss: 0.0000234653, Train MSE: 0.0000047806,             Test MSE: 0.0000081100, Time: 1.43 seconds\n",
      "Epoch [47/1000], Train Loss: 0.0000149651, Train MSE: 0.0000022443,             Test MSE: 0.0000054326, Time: 1.29 seconds\n",
      "Epoch [48/1000], Train Loss: 0.0000193868, Train MSE: 0.0002255081,             Test MSE: 0.0001945701, Time: 1.28 seconds\n",
      "Epoch [49/1000], Train Loss: 0.0000415395, Train MSE: 0.0000057754,             Test MSE: 0.0000082683, Time: 1.28 seconds\n",
      "Epoch [50/1000], Train Loss: 0.0001060783, Train MSE: 0.0001451801,             Test MSE: 0.0001224314, Time: 1.25 seconds\n",
      "Epoch [51/1000], Train Loss: 0.0001677903, Train MSE: 0.0000369400,             Test MSE: 0.0000314574, Time: 1.23 seconds\n",
      "Epoch [52/1000], Train Loss: 0.0000438081, Train MSE: 0.0000105087,             Test MSE: 0.0000126450, Time: 1.37 seconds\n",
      "Epoch [53/1000], Train Loss: 0.0000122027, Train MSE: 0.0000162397,             Test MSE: 0.0000139430, Time: 1.29 seconds\n",
      "Epoch [54/1000], Train Loss: 0.0000076693, Train MSE: 0.0000070378,             Test MSE: 0.0000087569, Time: 1.32 seconds\n",
      "Epoch [55/1000], Train Loss: 0.0000107839, Train MSE: 0.0000216728,             Test MSE: 0.0000236571, Time: 1.38 seconds\n",
      "Epoch [56/1000], Train Loss: 0.0000104913, Train MSE: 0.0000025296,             Test MSE: 0.0000037599, Time: 1.31 seconds\n",
      "Epoch [57/1000], Train Loss: 0.0000069292, Train MSE: 0.0000016011,             Test MSE: 0.0000043429, Time: 1.33 seconds\n",
      "Epoch [58/1000], Train Loss: 0.0000112895, Train MSE: 0.0000229282,             Test MSE: 0.0000222854, Time: 1.39 seconds\n",
      "Epoch [59/1000], Train Loss: 0.0000169700, Train MSE: 0.0000020956,             Test MSE: 0.0000041629, Time: 1.34 seconds\n",
      "Epoch [60/1000], Train Loss: 0.0000193252, Train MSE: 0.0000386565,             Test MSE: 0.0000369701, Time: 1.26 seconds\n",
      "Epoch [61/1000], Train Loss: 0.0000177005, Train MSE: 0.0000513917,             Test MSE: 0.0000492400, Time: 1.33 seconds\n",
      "Epoch [62/1000], Train Loss: 0.0000092262, Train MSE: 0.0000070165,             Test MSE: 0.0000088513, Time: 1.34 seconds\n",
      "Epoch [63/1000], Train Loss: 0.0000251988, Train MSE: 0.0000010811,             Test MSE: 0.0000021885, Time: 1.34 seconds\n",
      "Epoch [64/1000], Train Loss: 0.0000126144, Train MSE: 0.0000048194,             Test MSE: 0.0000051063, Time: 1.68 seconds\n",
      "Epoch [65/1000], Train Loss: 0.0000155790, Train MSE: 0.0000040956,             Test MSE: 0.0000044074, Time: 1.50 seconds\n",
      "Epoch [66/1000], Train Loss: 0.0000111255, Train MSE: 0.0000042762,             Test MSE: 0.0000046339, Time: 2.35 seconds\n",
      "Epoch [67/1000], Train Loss: 0.0000120312, Train MSE: 0.0000354183,             Test MSE: 0.0000288616, Time: 3.37 seconds\n",
      "Epoch [68/1000], Train Loss: 0.0000151763, Train MSE: 0.0000225377,             Test MSE: 0.0000217454, Time: 2.15 seconds\n",
      "Epoch [69/1000], Train Loss: 0.0000164229, Train MSE: 0.0000671223,             Test MSE: 0.0000606816, Time: 1.76 seconds\n",
      "Epoch [70/1000], Train Loss: 0.0000152601, Train MSE: 0.0000169804,             Test MSE: 0.0000176862, Time: 1.80 seconds\n",
      "Epoch [71/1000], Train Loss: 0.0000268062, Train MSE: 0.0000292430,             Test MSE: 0.0000263143, Time: 2.72 seconds\n",
      "Epoch [72/1000], Train Loss: 0.0000502375, Train MSE: 0.0001292363,             Test MSE: 0.0001141302, Time: 2.00 seconds\n",
      "Epoch [73/1000], Train Loss: 0.0000236408, Train MSE: 0.0000086276,             Test MSE: 0.0000098683, Time: 1.84 seconds\n",
      "Epoch [74/1000], Train Loss: 0.0000251780, Train MSE: 0.0000053782,             Test MSE: 0.0000073844, Time: 1.77 seconds\n",
      "Epoch [75/1000], Train Loss: 0.0000075983, Train MSE: 0.0000306840,             Test MSE: 0.0000250120, Time: 1.75 seconds\n",
      "Epoch [76/1000], Train Loss: 0.0000105194, Train MSE: 0.0000124269,             Test MSE: 0.0000103581, Time: 2.13 seconds\n",
      "Epoch [77/1000], Train Loss: 0.0000099057, Train MSE: 0.0000013431,             Test MSE: 0.0000024593, Time: 1.98 seconds\n",
      "Epoch [78/1000], Train Loss: 0.0000170337, Train MSE: 0.0000145561,             Test MSE: 0.0000138518, Time: 1.84 seconds\n",
      "Epoch [79/1000], Train Loss: 0.0000170025, Train MSE: 0.0000035971,             Test MSE: 0.0000040838, Time: 1.86 seconds\n",
      "Epoch [80/1000], Train Loss: 0.0000294823, Train MSE: 0.0000291472,             Test MSE: 0.0000241905, Time: 1.77 seconds\n",
      "Epoch [81/1000], Train Loss: 0.0000183971, Train MSE: 0.0000123945,             Test MSE: 0.0000111630, Time: 1.79 seconds\n",
      "Epoch [82/1000], Train Loss: 0.0000045965, Train MSE: 0.0000021675,             Test MSE: 0.0000025691, Time: 1.84 seconds\n",
      "Epoch [83/1000], Train Loss: 0.0000041300, Train MSE: 0.0000004471,             Test MSE: 0.0000007965, Time: 2.23 seconds\n",
      "Epoch [84/1000], Train Loss: 0.0000038359, Train MSE: 0.0000007429,             Test MSE: 0.0000015968, Time: 2.07 seconds\n",
      "Epoch [85/1000], Train Loss: 0.0000040924, Train MSE: 0.0000058562,             Test MSE: 0.0000053975, Time: 3.03 seconds\n",
      "Epoch [86/1000], Train Loss: 0.0000052581, Train MSE: 0.0000019762,             Test MSE: 0.0000020065, Time: 2.18 seconds\n",
      "Epoch [87/1000], Train Loss: 0.0000052620, Train MSE: 0.0000141572,             Test MSE: 0.0000127558, Time: 1.62 seconds\n",
      "Epoch [88/1000], Train Loss: 0.0000107882, Train MSE: 0.0000099706,             Test MSE: 0.0000092813, Time: 1.91 seconds\n",
      "Epoch [89/1000], Train Loss: 0.0000043430, Train MSE: 0.0000020517,             Test MSE: 0.0000021781, Time: 2.18 seconds\n",
      "Epoch [90/1000], Train Loss: 0.0000092924, Train MSE: 0.0000099911,             Test MSE: 0.0000089843, Time: 1.88 seconds\n",
      "Epoch [91/1000], Train Loss: 0.0000113229, Train MSE: 0.0000079900,             Test MSE: 0.0000093854, Time: 2.22 seconds\n",
      "Epoch [92/1000], Train Loss: 0.0000105118, Train MSE: 0.0000249302,             Test MSE: 0.0000225819, Time: 2.10 seconds\n",
      "Epoch [93/1000], Train Loss: 0.0000132370, Train MSE: 0.0000481833,             Test MSE: 0.0000442355, Time: 1.72 seconds\n",
      "Epoch [94/1000], Train Loss: 0.0000100348, Train MSE: 0.0000376646,             Test MSE: 0.0000357167, Time: 1.81 seconds\n",
      "Epoch [95/1000], Train Loss: 0.0000345752, Train MSE: 0.0000751564,             Test MSE: 0.0000540965, Time: 1.58 seconds\n",
      "Epoch [96/1000], Train Loss: 0.0000178329, Train MSE: 0.0000280095,             Test MSE: 0.0000238276, Time: 1.82 seconds\n",
      "Epoch [97/1000], Train Loss: 0.0000150036, Train MSE: 0.0000155413,             Test MSE: 0.0000124695, Time: 2.07 seconds\n",
      "Epoch [98/1000], Train Loss: 0.0000149579, Train MSE: 0.0000284823,             Test MSE: 0.0000237708, Time: 2.09 seconds\n",
      "Epoch [99/1000], Train Loss: 0.0000119750, Train MSE: 0.0000177249,             Test MSE: 0.0000133277, Time: 2.37 seconds\n",
      "Epoch [100/1000], Train Loss: 0.0000071245, Train MSE: 0.0000128996,             Test MSE: 0.0000103247, Time: 1.88 seconds\n",
      "Epoch [101/1000], Train Loss: 0.0000037046, Train MSE: 0.0000032169,             Test MSE: 0.0000043281, Time: 2.00 seconds\n",
      "Epoch [102/1000], Train Loss: 0.0000055590, Train MSE: 0.0000184007,             Test MSE: 0.0000168391, Time: 2.46 seconds\n",
      "Epoch [103/1000], Train Loss: 0.0000116562, Train MSE: 0.0000042708,             Test MSE: 0.0000031479, Time: 1.92 seconds\n",
      "Epoch [104/1000], Train Loss: 0.0000129358, Train MSE: 0.0000791392,             Test MSE: 0.0000653874, Time: 2.24 seconds\n",
      "Epoch [105/1000], Train Loss: 0.0000409012, Train MSE: 0.0001587825,             Test MSE: 0.0001245449, Time: 1.94 seconds\n",
      "Epoch [106/1000], Train Loss: 0.0000157876, Train MSE: 0.0000012675,             Test MSE: 0.0000013731, Time: 1.99 seconds\n",
      "Epoch [107/1000], Train Loss: 0.0000017530, Train MSE: 0.0000006938,             Test MSE: 0.0000010749, Time: 1.84 seconds\n",
      "Epoch [108/1000], Train Loss: 0.0000031176, Train MSE: 0.0000014492,             Test MSE: 0.0000017698, Time: 1.60 seconds\n",
      "Epoch [109/1000], Train Loss: 0.0000051124, Train MSE: 0.0000136416,             Test MSE: 0.0000118901, Time: 1.74 seconds\n",
      "Epoch [110/1000], Train Loss: 0.0000044535, Train MSE: 0.0000042393,             Test MSE: 0.0000031886, Time: 1.71 seconds\n",
      "Epoch [111/1000], Train Loss: 0.0000016313, Train MSE: 0.0000010350,             Test MSE: 0.0000007945, Time: 1.58 seconds\n",
      "Epoch [112/1000], Train Loss: 0.0000021799, Train MSE: 0.0000004543,             Test MSE: 0.0000007890, Time: 2.15 seconds\n",
      "Epoch [113/1000], Train Loss: 0.0000059785, Train MSE: 0.0000048958,             Test MSE: 0.0000044405, Time: 1.68 seconds\n",
      "Epoch [114/1000], Train Loss: 0.0000144458, Train MSE: 0.0000471576,             Test MSE: 0.0000319938, Time: 2.24 seconds\n",
      "Epoch [115/1000], Train Loss: 0.0000076625, Train MSE: 0.0000031266,             Test MSE: 0.0000028846, Time: 2.10 seconds\n",
      "Epoch [116/1000], Train Loss: 0.0000232920, Train MSE: 0.0000147470,             Test MSE: 0.0000136697, Time: 1.58 seconds\n",
      "Epoch [117/1000], Train Loss: 0.0000196259, Train MSE: 0.0001003582,             Test MSE: 0.0000760734, Time: 1.60 seconds\n",
      "Epoch [118/1000], Train Loss: 0.0000092619, Train MSE: 0.0000060876,             Test MSE: 0.0000038681, Time: 1.65 seconds\n",
      "Epoch [119/1000], Train Loss: 0.0000065768, Train MSE: 0.0000022521,             Test MSE: 0.0000021428, Time: 1.64 seconds\n",
      "Epoch [120/1000], Train Loss: 0.0000020112, Train MSE: 0.0000032657,             Test MSE: 0.0000029654, Time: 1.60 seconds\n",
      "Epoch [121/1000], Train Loss: 0.0000048949, Train MSE: 0.0000017961,             Test MSE: 0.0000018391, Time: 1.70 seconds\n",
      "Epoch [122/1000], Train Loss: 0.0000048473, Train MSE: 0.0000150449,             Test MSE: 0.0000105330, Time: 1.62 seconds\n",
      "Epoch [123/1000], Train Loss: 0.0000046699, Train MSE: 0.0000050540,             Test MSE: 0.0000036439, Time: 1.61 seconds\n",
      "Epoch [124/1000], Train Loss: 0.0000053742, Train MSE: 0.0000058499,             Test MSE: 0.0000032086, Time: 1.50 seconds\n",
      "Epoch [125/1000], Train Loss: 0.0000079251, Train MSE: 0.0000589685,             Test MSE: 0.0000450842, Time: 1.72 seconds\n",
      "Epoch [126/1000], Train Loss: 0.0000131139, Train MSE: 0.0000016696,             Test MSE: 0.0000007763, Time: 1.67 seconds\n",
      "Epoch [127/1000], Train Loss: 0.0000049378, Train MSE: 0.0000005291,             Test MSE: 0.0000005103, Time: 1.57 seconds\n",
      "Epoch [128/1000], Train Loss: 0.0000076459, Train MSE: 0.0000240503,             Test MSE: 0.0000169614, Time: 1.89 seconds\n",
      "Epoch [129/1000], Train Loss: 0.0000062888, Train MSE: 0.0000019579,             Test MSE: 0.0000015906, Time: 1.72 seconds\n",
      "Epoch [130/1000], Train Loss: 0.0000029221, Train MSE: 0.0000036034,             Test MSE: 0.0000022894, Time: 1.63 seconds\n",
      "Epoch [131/1000], Train Loss: 0.0000036675, Train MSE: 0.0000210928,             Test MSE: 0.0000161996, Time: 1.82 seconds\n",
      "Epoch [132/1000], Train Loss: 0.0000075737, Train MSE: 0.0000118083,             Test MSE: 0.0000079004, Time: 1.70 seconds\n",
      "Epoch [133/1000], Train Loss: 0.0000024324, Train MSE: 0.0000042754,             Test MSE: 0.0000031919, Time: 1.63 seconds\n",
      "Epoch [134/1000], Train Loss: 0.0000008524, Train MSE: 0.0000078714,             Test MSE: 0.0000052963, Time: 1.54 seconds\n",
      "Epoch [135/1000], Train Loss: 0.0000032072, Train MSE: 0.0000025632,             Test MSE: 0.0000015800, Time: 1.56 seconds\n",
      "Epoch [136/1000], Train Loss: 0.0000201439, Train MSE: 0.0000578020,             Test MSE: 0.0000458203, Time: 1.63 seconds\n",
      "Epoch [137/1000], Train Loss: 0.0000356788, Train MSE: 0.0000063759,             Test MSE: 0.0000067827, Time: 1.72 seconds\n",
      "Epoch [138/1000], Train Loss: 0.0000017395, Train MSE: 0.0000191202,             Test MSE: 0.0000148681, Time: 1.60 seconds\n",
      "Epoch [139/1000], Train Loss: 0.0000022772, Train MSE: 0.0000022056,             Test MSE: 0.0000021428, Time: 1.55 seconds\n",
      "Epoch [140/1000], Train Loss: 0.0000019118, Train MSE: 0.0000022848,             Test MSE: 0.0000019048, Time: 1.69 seconds\n",
      "Epoch [141/1000], Train Loss: 0.0000007275, Train MSE: 0.0000005964,             Test MSE: 0.0000006133, Time: 1.53 seconds\n",
      "Epoch [142/1000], Train Loss: 0.0000014267, Train MSE: 0.0000003015,             Test MSE: 0.0000002600, Time: 1.63 seconds\n",
      "Epoch [143/1000], Train Loss: 0.0000024448, Train MSE: 0.0000016773,             Test MSE: 0.0000015031, Time: 1.55 seconds\n",
      "Epoch [144/1000], Train Loss: 0.0000315242, Train MSE: 0.0000048253,             Test MSE: 0.0000022233, Time: 1.84 seconds\n",
      "Epoch [145/1000], Train Loss: 0.0000396244, Train MSE: 0.0000220300,             Test MSE: 0.0000117900, Time: 1.62 seconds\n",
      "Epoch [146/1000], Train Loss: 0.0000041753, Train MSE: 0.0000021728,             Test MSE: 0.0000014122, Time: 1.60 seconds\n",
      "Epoch [147/1000], Train Loss: 0.0000002928, Train MSE: 0.0000001130,             Test MSE: 0.0000000795, Time: 1.73 seconds\n",
      "Epoch [148/1000], Train Loss: 0.0000006534, Train MSE: 0.0000001684,             Test MSE: 0.0000001070, Time: 1.84 seconds\n",
      "Epoch [149/1000], Train Loss: 0.0000045232, Train MSE: 0.0000089092,             Test MSE: 0.0000060811, Time: 1.74 seconds\n",
      "Epoch [150/1000], Train Loss: 0.0000040852, Train MSE: 0.0000017118,             Test MSE: 0.0000018241, Time: 1.57 seconds\n",
      "Epoch [151/1000], Train Loss: 0.0000011030, Train MSE: 0.0000003587,             Test MSE: 0.0000002249, Time: 2.08 seconds\n",
      "Epoch [152/1000], Train Loss: 0.0000006200, Train MSE: 0.0000008063,             Test MSE: 0.0000006878, Time: 2.37 seconds\n",
      "Epoch [153/1000], Train Loss: 0.0000009913, Train MSE: 0.0000007496,             Test MSE: 0.0000004859, Time: 2.09 seconds\n",
      "Epoch [154/1000], Train Loss: 0.0000038972, Train MSE: 0.0000047958,             Test MSE: 0.0000035868, Time: 1.83 seconds\n",
      "Epoch [155/1000], Train Loss: 0.0000020644, Train MSE: 0.0000017695,             Test MSE: 0.0000014975, Time: 1.90 seconds\n",
      "Epoch [156/1000], Train Loss: 0.0000043768, Train MSE: 0.0000009097,             Test MSE: 0.0000007995, Time: 2.24 seconds\n",
      "Epoch [157/1000], Train Loss: 0.0000106273, Train MSE: 0.0000001533,             Test MSE: 0.0000001831, Time: 2.73 seconds\n",
      "Epoch [158/1000], Train Loss: 0.0000072045, Train MSE: 0.0000098897,             Test MSE: 0.0000082273, Time: 2.07 seconds\n",
      "Epoch [159/1000], Train Loss: 0.0000070501, Train MSE: 0.0000042092,             Test MSE: 0.0000029447, Time: 1.98 seconds\n",
      "Epoch [160/1000], Train Loss: 0.0000111922, Train MSE: 0.0000009401,             Test MSE: 0.0000009009, Time: 1.95 seconds\n",
      "Epoch [161/1000], Train Loss: 0.0000042759, Train MSE: 0.0000012138,             Test MSE: 0.0000009514, Time: 2.63 seconds\n",
      "Epoch [162/1000], Train Loss: 0.0000029333, Train MSE: 0.0000002905,             Test MSE: 0.0000001443, Time: 1.60 seconds\n",
      "Epoch [163/1000], Train Loss: 0.0000005063, Train MSE: 0.0000002687,             Test MSE: 0.0000002160, Time: 2.15 seconds\n",
      "Epoch [164/1000], Train Loss: 0.0000026026, Train MSE: 0.0000124682,             Test MSE: 0.0000084805, Time: 1.89 seconds\n",
      "Epoch [165/1000], Train Loss: 0.0000358173, Train MSE: 0.0000707537,             Test MSE: 0.0000398108, Time: 2.10 seconds\n",
      "Epoch [166/1000], Train Loss: 0.0000282763, Train MSE: 0.0000021589,             Test MSE: 0.0000012072, Time: 2.18 seconds\n",
      "Epoch [167/1000], Train Loss: 0.0000022012, Train MSE: 0.0000006431,             Test MSE: 0.0000004808, Time: 1.96 seconds\n",
      "Epoch [168/1000], Train Loss: 0.0000002173, Train MSE: 0.0000001216,             Test MSE: 0.0000001077, Time: 1.76 seconds\n",
      "Epoch [169/1000], Train Loss: 0.0000003987, Train MSE: 0.0000000567,             Test MSE: 0.0000000642, Time: 2.07 seconds\n",
      "Epoch [170/1000], Train Loss: 0.0000009224, Train MSE: 0.0000001762,             Test MSE: 0.0000001048, Time: 1.56 seconds\n",
      "Epoch [171/1000], Train Loss: 0.0000006895, Train MSE: 0.0000002411,             Test MSE: 0.0000001378, Time: 1.79 seconds\n",
      "Epoch [172/1000], Train Loss: 0.0000012564, Train MSE: 0.0000004086,             Test MSE: 0.0000003487, Time: 1.81 seconds\n",
      "Epoch [173/1000], Train Loss: 0.0000012873, Train MSE: 0.0000003935,             Test MSE: 0.0000005082, Time: 1.89 seconds\n",
      "Epoch [174/1000], Train Loss: 0.0000021199, Train MSE: 0.0000027432,             Test MSE: 0.0000015892, Time: 1.64 seconds\n",
      "Epoch [175/1000], Train Loss: 0.0000054171, Train MSE: 0.0000017019,             Test MSE: 0.0000009350, Time: 1.78 seconds\n",
      "Epoch [176/1000], Train Loss: 0.0000201327, Train MSE: 0.0000083358,             Test MSE: 0.0000034380, Time: 2.19 seconds\n",
      "Epoch [177/1000], Train Loss: 0.0000044607, Train MSE: 0.0000000782,             Test MSE: 0.0000000974, Time: 2.25 seconds\n",
      "Epoch [178/1000], Train Loss: 0.0000003155, Train MSE: 0.0000000525,             Test MSE: 0.0000000380, Time: 2.00 seconds\n",
      "Epoch [179/1000], Train Loss: 0.0000115404, Train MSE: 0.0000265571,             Test MSE: 0.0000078208, Time: 1.73 seconds\n",
      "Epoch [180/1000], Train Loss: 0.0000078998, Train MSE: 0.0000010106,             Test MSE: 0.0000010349, Time: 2.10 seconds\n",
      "Epoch [181/1000], Train Loss: 0.0000004382, Train MSE: 0.0000006587,             Test MSE: 0.0000005787, Time: 1.69 seconds\n",
      "Epoch [182/1000], Train Loss: 0.0000007321, Train MSE: 0.0000088318,             Test MSE: 0.0000068711, Time: 2.05 seconds\n",
      "Epoch [183/1000], Train Loss: 0.0000025080, Train MSE: 0.0000000189,             Test MSE: 0.0000000361, Time: 2.18 seconds\n",
      "Epoch [184/1000], Train Loss: 0.0000002628, Train MSE: 0.0000001569,             Test MSE: 0.0000001212, Time: 2.36 seconds\n",
      "Epoch [185/1000], Train Loss: 0.0000014114, Train MSE: 0.0000002411,             Test MSE: 0.0000002842, Time: 2.23 seconds\n",
      "Epoch [186/1000], Train Loss: 0.0000041136, Train MSE: 0.0000000828,             Test MSE: 0.0000000886, Time: 1.84 seconds\n",
      "Epoch [187/1000], Train Loss: 0.0000192487, Train MSE: 0.0000681783,             Test MSE: 0.0000465802, Time: 1.61 seconds\n",
      "Epoch [188/1000], Train Loss: 0.0000071162, Train MSE: 0.0000010756,             Test MSE: 0.0000004883, Time: 1.43 seconds\n",
      "Epoch [189/1000], Train Loss: 0.0000004852, Train MSE: 0.0000000686,             Test MSE: 0.0000000549, Time: 1.58 seconds\n",
      "Epoch [190/1000], Train Loss: 0.0000003532, Train MSE: 0.0000003604,             Test MSE: 0.0000003308, Time: 2.20 seconds\n",
      "Epoch [191/1000], Train Loss: 0.0000156647, Train MSE: 0.0000030867,             Test MSE: 0.0000017183, Time: 1.93 seconds\n",
      "Epoch [192/1000], Train Loss: 0.0000013968, Train MSE: 0.0000008997,             Test MSE: 0.0000004975, Time: 1.84 seconds\n",
      "Epoch [193/1000], Train Loss: 0.0000096732, Train MSE: 0.0000163249,             Test MSE: 0.0000081761, Time: 1.73 seconds\n",
      "Epoch [194/1000], Train Loss: 0.0000035068, Train MSE: 0.0000002374,             Test MSE: 0.0000002679, Time: 1.76 seconds\n",
      "Epoch [195/1000], Train Loss: 0.0000003498, Train MSE: 0.0000010811,             Test MSE: 0.0000009482, Time: 1.54 seconds\n",
      "Epoch [196/1000], Train Loss: 0.0000030045, Train MSE: 0.0000016504,             Test MSE: 0.0000012818, Time: 1.66 seconds\n",
      "Epoch [197/1000], Train Loss: 0.0000010787, Train MSE: 0.0000002676,             Test MSE: 0.0000002274, Time: 1.49 seconds\n",
      "Epoch [198/1000], Train Loss: 0.0000008933, Train MSE: 0.0000001545,             Test MSE: 0.0000001332, Time: 1.46 seconds\n",
      "Epoch [199/1000], Train Loss: 0.0000009410, Train MSE: 0.0000078024,             Test MSE: 0.0000063588, Time: 1.82 seconds\n",
      "Epoch [200/1000], Train Loss: 0.0000083727, Train MSE: 0.0000008315,             Test MSE: 0.0000007845, Time: 1.55 seconds\n",
      "Epoch [201/1000], Train Loss: 0.0000042473, Train MSE: 0.0000104376,             Test MSE: 0.0000051307, Time: 1.71 seconds\n",
      "Epoch [202/1000], Train Loss: 0.0000075864, Train MSE: 0.0000005800,             Test MSE: 0.0000004312, Time: 1.54 seconds\n",
      "Epoch [203/1000], Train Loss: 0.0000090789, Train MSE: 0.0000188674,             Test MSE: 0.0000130324, Time: 1.72 seconds\n",
      "Epoch [204/1000], Train Loss: 0.0000151863, Train MSE: 0.0000078206,             Test MSE: 0.0000042867, Time: 2.08 seconds\n",
      "Epoch [205/1000], Train Loss: 0.0000017413, Train MSE: 0.0000010193,             Test MSE: 0.0000006142, Time: 1.81 seconds\n",
      "Epoch [206/1000], Train Loss: 0.0000006476, Train MSE: 0.0000026825,             Test MSE: 0.0000018936, Time: 1.47 seconds\n",
      "Epoch [207/1000], Train Loss: 0.0000002633, Train MSE: 0.0000002177,             Test MSE: 0.0000001775, Time: 1.51 seconds\n",
      "Epoch [208/1000], Train Loss: 0.0000045391, Train MSE: 0.0000518050,             Test MSE: 0.0000309767, Time: 1.46 seconds\n",
      "Epoch [209/1000], Train Loss: 0.0000238339, Train MSE: 0.0000031123,             Test MSE: 0.0000023994, Time: 1.47 seconds\n",
      "Epoch [210/1000], Train Loss: 0.0000032042, Train MSE: 0.0000026435,             Test MSE: 0.0000022895, Time: 1.44 seconds\n",
      "Epoch [211/1000], Train Loss: 0.0000004223, Train MSE: 0.0000000105,             Test MSE: 0.0000000094, Time: 1.58 seconds\n",
      "Epoch [212/1000], Train Loss: 0.0000000294, Train MSE: 0.0000000219,             Test MSE: 0.0000000151, Time: 1.47 seconds\n",
      "Epoch [213/1000], Train Loss: 0.0000000635, Train MSE: 0.0000000382,             Test MSE: 0.0000000364, Time: 1.55 seconds\n",
      "Epoch [214/1000], Train Loss: 0.0000000872, Train MSE: 0.0000000430,             Test MSE: 0.0000000315, Time: 1.88 seconds\n",
      "Epoch [215/1000], Train Loss: 0.0000001738, Train MSE: 0.0000008474,             Test MSE: 0.0000005255, Time: 1.94 seconds\n",
      "Epoch [216/1000], Train Loss: 0.0000002894, Train MSE: 0.0000017434,             Test MSE: 0.0000009742, Time: 1.61 seconds\n",
      "Epoch [217/1000], Train Loss: 0.0000107622, Train MSE: 0.0000005550,             Test MSE: 0.0000007215, Time: 1.67 seconds\n",
      "Epoch [218/1000], Train Loss: 0.0000058591, Train MSE: 0.0000001083,             Test MSE: 0.0000000882, Time: 1.85 seconds\n",
      "Epoch [219/1000], Train Loss: 0.0000007685, Train MSE: 0.0000021665,             Test MSE: 0.0000014550, Time: 1.78 seconds\n",
      "Epoch [220/1000], Train Loss: 0.0000022710, Train MSE: 0.0000001075,             Test MSE: 0.0000001219, Time: 1.90 seconds\n",
      "Epoch [221/1000], Train Loss: 0.0000032081, Train MSE: 0.0000003537,             Test MSE: 0.0000002488, Time: 1.44 seconds\n",
      "Epoch [222/1000], Train Loss: 0.0000029887, Train MSE: 0.0000004600,             Test MSE: 0.0000003977, Time: 1.65 seconds\n",
      "Epoch [223/1000], Train Loss: 0.0000186180, Train MSE: 0.0000021204,             Test MSE: 0.0000021623, Time: 1.84 seconds\n",
      "Epoch [224/1000], Train Loss: 0.0000005400, Train MSE: 0.0000003151,             Test MSE: 0.0000001688, Time: 1.58 seconds\n",
      "Epoch [225/1000], Train Loss: 0.0000001758, Train MSE: 0.0000001720,             Test MSE: 0.0000001575, Time: 1.63 seconds\n",
      "Epoch [226/1000], Train Loss: 0.0000007316, Train MSE: 0.0000019200,             Test MSE: 0.0000014455, Time: 1.80 seconds\n",
      "Epoch [227/1000], Train Loss: 0.0000014651, Train MSE: 0.0000001760,             Test MSE: 0.0000001562, Time: 1.74 seconds\n",
      "Epoch [228/1000], Train Loss: 0.0000018705, Train MSE: 0.0000089379,             Test MSE: 0.0000051885, Time: 1.97 seconds\n",
      "Epoch [229/1000], Train Loss: 0.0000129100, Train MSE: 0.0000046379,             Test MSE: 0.0000030338, Time: 1.68 seconds\n",
      "Epoch [230/1000], Train Loss: 0.0000063523, Train MSE: 0.0000001313,             Test MSE: 0.0000000924, Time: 1.55 seconds\n",
      "Epoch [231/1000], Train Loss: 0.0000001264, Train MSE: 0.0000000033,             Test MSE: 0.0000000062, Time: 1.60 seconds\n",
      "Epoch [232/1000], Train Loss: 0.0000001734, Train MSE: 0.0000004600,             Test MSE: 0.0000002817, Time: 1.80 seconds\n",
      "Epoch [233/1000], Train Loss: 0.0000004634, Train MSE: 0.0000035723,             Test MSE: 0.0000022095, Time: 2.32 seconds\n",
      "Epoch [234/1000], Train Loss: 0.0000036875, Train MSE: 0.0000007923,             Test MSE: 0.0000004470, Time: 1.73 seconds\n",
      "Epoch [235/1000], Train Loss: 0.0000037352, Train MSE: 0.0000000616,             Test MSE: 0.0000000481, Time: 1.73 seconds\n",
      "Epoch [236/1000], Train Loss: 0.0000099699, Train MSE: 0.0000036084,             Test MSE: 0.0000030995, Time: 1.97 seconds\n",
      "Epoch [237/1000], Train Loss: 0.0000075978, Train MSE: 0.0000011292,             Test MSE: 0.0000006958, Time: 1.89 seconds\n",
      "Epoch [238/1000], Train Loss: 0.0000003324, Train MSE: 0.0000002003,             Test MSE: 0.0000000976, Time: 1.67 seconds\n",
      "Epoch [239/1000], Train Loss: 0.0000033350, Train MSE: 0.0000002660,             Test MSE: 0.0000001585, Time: 1.74 seconds\n",
      "Epoch [240/1000], Train Loss: 0.0000004500, Train MSE: 0.0000027367,             Test MSE: 0.0000018602, Time: 1.62 seconds\n",
      "Epoch [241/1000], Train Loss: 0.0000156849, Train MSE: 0.0000429698,             Test MSE: 0.0000256470, Time: 1.55 seconds\n",
      "Epoch [242/1000], Train Loss: 0.0000050007, Train MSE: 0.0000202832,             Test MSE: 0.0000117956, Time: 1.62 seconds\n",
      "Epoch [243/1000], Train Loss: 0.0000008978, Train MSE: 0.0000005888,             Test MSE: 0.0000003152, Time: 1.53 seconds\n",
      "Epoch [244/1000], Train Loss: 0.0000008557, Train MSE: 0.0000041727,             Test MSE: 0.0000024157, Time: 1.62 seconds\n",
      "Epoch [245/1000], Train Loss: 0.0000076353, Train MSE: 0.0000009287,             Test MSE: 0.0000007542, Time: 1.78 seconds\n",
      "Epoch [246/1000], Train Loss: 0.0000027566, Train MSE: 0.0000125339,             Test MSE: 0.0000064072, Time: 2.11 seconds\n",
      "Epoch [247/1000], Train Loss: 0.0000026432, Train MSE: 0.0000000388,             Test MSE: 0.0000000505, Time: 1.76 seconds\n",
      "Epoch [248/1000], Train Loss: 0.0000008478, Train MSE: 0.0000009250,             Test MSE: 0.0000004712, Time: 1.91 seconds\n",
      "Epoch [249/1000], Train Loss: 0.0000009661, Train MSE: 0.0000051791,             Test MSE: 0.0000026785, Time: 1.91 seconds\n",
      "Epoch [250/1000], Train Loss: 0.0000027848, Train MSE: 0.0000002816,             Test MSE: 0.0000002551, Time: 1.77 seconds\n",
      "Epoch [251/1000], Train Loss: 0.0000036431, Train MSE: 0.0000004587,             Test MSE: 0.0000002423, Time: 1.89 seconds\n",
      "Epoch [252/1000], Train Loss: 0.0000077527, Train MSE: 0.0000002125,             Test MSE: 0.0000004511, Time: 1.48 seconds\n",
      "Epoch [253/1000], Train Loss: 0.0000093742, Train MSE: 0.0000015080,             Test MSE: 0.0000005935, Time: 1.89 seconds\n",
      "Epoch [254/1000], Train Loss: 0.0000003221, Train MSE: 0.0000001450,             Test MSE: 0.0000001154, Time: 1.60 seconds\n",
      "Epoch [255/1000], Train Loss: 0.0000001021, Train MSE: 0.0000000612,             Test MSE: 0.0000000431, Time: 1.67 seconds\n",
      "Epoch [256/1000], Train Loss: 0.0000003008, Train MSE: 0.0000000373,             Test MSE: 0.0000000372, Time: 1.56 seconds\n",
      "Epoch [257/1000], Train Loss: 0.0000026252, Train MSE: 0.0000021922,             Test MSE: 0.0000020733, Time: 2.02 seconds\n",
      "Epoch [258/1000], Train Loss: 0.0000095523, Train MSE: 0.0000006180,             Test MSE: 0.0000003238, Time: 1.60 seconds\n",
      "Epoch [259/1000], Train Loss: 0.0000003203, Train MSE: 0.0000002670,             Test MSE: 0.0000001270, Time: 1.58 seconds\n",
      "Epoch [260/1000], Train Loss: 0.0000030555, Train MSE: 0.0000027921,             Test MSE: 0.0000013211, Time: 1.67 seconds\n",
      "Epoch [261/1000], Train Loss: 0.0000258035, Train MSE: 0.0000030733,             Test MSE: 0.0000010388, Time: 1.80 seconds\n",
      "Epoch [262/1000], Train Loss: 0.0000020519, Train MSE: 0.0000000847,             Test MSE: 0.0000000429, Time: 1.85 seconds\n",
      "Epoch [263/1000], Train Loss: 0.0000001675, Train MSE: 0.0000000900,             Test MSE: 0.0000000686, Time: 1.74 seconds\n",
      "Epoch [264/1000], Train Loss: 0.0000001579, Train MSE: 0.0000001491,             Test MSE: 0.0000001231, Time: 1.84 seconds\n",
      "Epoch [265/1000], Train Loss: 0.0000001124, Train MSE: 0.0000000015,             Test MSE: 0.0000000036, Time: 1.68 seconds\n",
      "Epoch [266/1000], Train Loss: 0.0000002861, Train MSE: 0.0000000797,             Test MSE: 0.0000000294, Time: 1.75 seconds\n",
      "Epoch [267/1000], Train Loss: 0.0000001660, Train MSE: 0.0000006546,             Test MSE: 0.0000003350, Time: 1.71 seconds\n",
      "Epoch [268/1000], Train Loss: 0.0000031064, Train MSE: 0.0000020233,             Test MSE: 0.0000017207, Time: 1.56 seconds\n",
      "Epoch [269/1000], Train Loss: 0.0000055807, Train MSE: 0.0000003568,             Test MSE: 0.0000002042, Time: 1.57 seconds\n",
      "Epoch [270/1000], Train Loss: 0.0000028937, Train MSE: 0.0000032573,             Test MSE: 0.0000016014, Time: 1.43 seconds\n",
      "Epoch [271/1000], Train Loss: 0.0000083379, Train MSE: 0.0000330583,             Test MSE: 0.0000156548, Time: 1.36 seconds\n",
      "Epoch [272/1000], Train Loss: 0.0000021390, Train MSE: 0.0000002877,             Test MSE: 0.0000001831, Time: 1.79 seconds\n",
      "Epoch [273/1000], Train Loss: 0.0000001230, Train MSE: 0.0000008512,             Test MSE: 0.0000003322, Time: 1.49 seconds\n",
      "Epoch [274/1000], Train Loss: 0.0000055242, Train MSE: 0.0000692851,             Test MSE: 0.0000393661, Time: 1.81 seconds\n",
      "Epoch [275/1000], Train Loss: 0.0000047535, Train MSE: 0.0000020864,             Test MSE: 0.0000012838, Time: 1.42 seconds\n",
      "Epoch [276/1000], Train Loss: 0.0000007987, Train MSE: 0.0000001596,             Test MSE: 0.0000000881, Time: 1.58 seconds\n",
      "Epoch [277/1000], Train Loss: 0.0000014829, Train MSE: 0.0000199716,             Test MSE: 0.0000111416, Time: 1.85 seconds\n",
      "Epoch [278/1000], Train Loss: 0.0000170942, Train MSE: 0.0000199155,             Test MSE: 0.0000103177, Time: 1.59 seconds\n",
      "Epoch [279/1000], Train Loss: 0.0000089974, Train MSE: 0.0000037846,             Test MSE: 0.0000023940, Time: 1.59 seconds\n",
      "Epoch [280/1000], Train Loss: 0.0000018077, Train MSE: 0.0000049601,             Test MSE: 0.0000025411, Time: 1.66 seconds\n",
      "Epoch [281/1000], Train Loss: 0.0000034048, Train MSE: 0.0000011325,             Test MSE: 0.0000007217, Time: 1.64 seconds\n",
      "Epoch [282/1000], Train Loss: 0.0000001642, Train MSE: 0.0000000479,             Test MSE: 0.0000000284, Time: 1.74 seconds\n",
      "Epoch [283/1000], Train Loss: 0.0000010097, Train MSE: 0.0000003342,             Test MSE: 0.0000001044, Time: 1.55 seconds\n",
      "Epoch [284/1000], Train Loss: 0.0000002035, Train MSE: 0.0000000045,             Test MSE: 0.0000000068, Time: 1.58 seconds\n",
      "Epoch [285/1000], Train Loss: 0.0000004293, Train MSE: 0.0000022585,             Test MSE: 0.0000013223, Time: 1.96 seconds\n",
      "Epoch [286/1000], Train Loss: 0.0000024707, Train MSE: 0.0000046054,             Test MSE: 0.0000033592, Time: 1.64 seconds\n",
      "Epoch [287/1000], Train Loss: 0.0000218408, Train MSE: 0.0000245148,             Test MSE: 0.0000110599, Time: 1.99 seconds\n",
      "Epoch [288/1000], Train Loss: 0.0000062789, Train MSE: 0.0000003100,             Test MSE: 0.0000002702, Time: 1.64 seconds\n",
      "Epoch [289/1000], Train Loss: 0.0000008252, Train MSE: 0.0000004909,             Test MSE: 0.0000002476, Time: 1.57 seconds\n",
      "Epoch [290/1000], Train Loss: 0.0000001113, Train MSE: 0.0000000145,             Test MSE: 0.0000000149, Time: 1.58 seconds\n",
      "Epoch [291/1000], Train Loss: 0.0000001836, Train MSE: 0.0000011736,             Test MSE: 0.0000005292, Time: 1.70 seconds\n",
      "Epoch [292/1000], Train Loss: 0.0000002408, Train MSE: 0.0000002515,             Test MSE: 0.0000001232, Time: 1.64 seconds\n",
      "Epoch [293/1000], Train Loss: 0.0000055368, Train MSE: 0.0000377626,             Test MSE: 0.0000199061, Time: 1.49 seconds\n",
      "Epoch [294/1000], Train Loss: 0.0000090550, Train MSE: 0.0000135613,             Test MSE: 0.0000076258, Time: 1.63 seconds\n",
      "Epoch [295/1000], Train Loss: 0.0000030650, Train MSE: 0.0000026227,             Test MSE: 0.0000008289, Time: 1.51 seconds\n",
      "Epoch [296/1000], Train Loss: 0.0000006684, Train MSE: 0.0000002109,             Test MSE: 0.0000001087, Time: 1.52 seconds\n",
      "Epoch [297/1000], Train Loss: 0.0000002042, Train MSE: 0.0000000163,             Test MSE: 0.0000000143, Time: 1.74 seconds\n",
      "Epoch [298/1000], Train Loss: 0.0000000877, Train MSE: 0.0000000458,             Test MSE: 0.0000000296, Time: 1.76 seconds\n",
      "Epoch [299/1000], Train Loss: 0.0000059432, Train MSE: 0.0000743917,             Test MSE: 0.0000385313, Time: 1.50 seconds\n",
      "Epoch [300/1000], Train Loss: 0.0000160161, Train MSE: 0.0000060233,             Test MSE: 0.0000035421, Time: 1.61 seconds\n",
      "Epoch [301/1000], Train Loss: 0.0000010556, Train MSE: 0.0000001449,             Test MSE: 0.0000000787, Time: 1.77 seconds\n",
      "Epoch [302/1000], Train Loss: 0.0000000537, Train MSE: 0.0000000901,             Test MSE: 0.0000000662, Time: 1.78 seconds\n",
      "Epoch [303/1000], Train Loss: 0.0000000644, Train MSE: 0.0000000041,             Test MSE: 0.0000000042, Time: 1.71 seconds\n",
      "Epoch [304/1000], Train Loss: 0.0000000422, Train MSE: 0.0000001176,             Test MSE: 0.0000000886, Time: 1.66 seconds\n",
      "Epoch [305/1000], Train Loss: 0.0000019264, Train MSE: 0.0000023765,             Test MSE: 0.0000010589, Time: 1.76 seconds\n",
      "Epoch [306/1000], Train Loss: 0.0000057531, Train MSE: 0.0000004422,             Test MSE: 0.0000002881, Time: 1.60 seconds\n",
      "Epoch [307/1000], Train Loss: 0.0000015405, Train MSE: 0.0000000076,             Test MSE: 0.0000000059, Time: 1.54 seconds\n",
      "Epoch [308/1000], Train Loss: 0.0000067591, Train MSE: 0.0000006546,             Test MSE: 0.0000004510, Time: 1.61 seconds\n",
      "Epoch [309/1000], Train Loss: 0.0000013576, Train MSE: 0.0000000331,             Test MSE: 0.0000000124, Time: 1.75 seconds\n",
      "Epoch [310/1000], Train Loss: 0.0000000679, Train MSE: 0.0000000895,             Test MSE: 0.0000000807, Time: 1.50 seconds\n",
      "Epoch [311/1000], Train Loss: 0.0000089766, Train MSE: 0.0000662124,             Test MSE: 0.0000385517, Time: 1.67 seconds\n",
      "Epoch [312/1000], Train Loss: 0.0000105686, Train MSE: 0.0000016865,             Test MSE: 0.0000006972, Time: 1.79 seconds\n",
      "Epoch [313/1000], Train Loss: 0.0000029552, Train MSE: 0.0000003109,             Test MSE: 0.0000002781, Time: 1.55 seconds\n",
      "Epoch [314/1000], Train Loss: 0.0000001080, Train MSE: 0.0000000220,             Test MSE: 0.0000000083, Time: 1.74 seconds\n",
      "Epoch [315/1000], Train Loss: 0.0000000153, Train MSE: 0.0000000020,             Test MSE: 0.0000000019, Time: 1.74 seconds\n",
      "Epoch [316/1000], Train Loss: 0.0000000169, Train MSE: 0.0000000223,             Test MSE: 0.0000000139, Time: 1.79 seconds\n",
      "Epoch [317/1000], Train Loss: 0.0000108729, Train MSE: 0.0000188643,             Test MSE: 0.0000086663, Time: 1.49 seconds\n",
      "Epoch [318/1000], Train Loss: 0.0000011697, Train MSE: 0.0000000174,             Test MSE: 0.0000000092, Time: 1.68 seconds\n",
      "Epoch [319/1000], Train Loss: 0.0000000098, Train MSE: 0.0000000046,             Test MSE: 0.0000000058, Time: 1.82 seconds\n",
      "Epoch [320/1000], Train Loss: 0.0000000346, Train MSE: 0.0000002593,             Test MSE: 0.0000001527, Time: 1.91 seconds\n",
      "Epoch [321/1000], Train Loss: 0.0000040196, Train MSE: 0.0000006485,             Test MSE: 0.0000003013, Time: 1.52 seconds\n",
      "Epoch [322/1000], Train Loss: 0.0000052823, Train MSE: 0.0000003111,             Test MSE: 0.0000002467, Time: 1.72 seconds\n",
      "Epoch [323/1000], Train Loss: 0.0000014889, Train MSE: 0.0000008640,             Test MSE: 0.0000004829, Time: 1.53 seconds\n",
      "Epoch [324/1000], Train Loss: 0.0000064681, Train MSE: 0.0000011336,             Test MSE: 0.0000005164, Time: 1.56 seconds\n",
      "Epoch [325/1000], Train Loss: 0.0000002963, Train MSE: 0.0000000451,             Test MSE: 0.0000000226, Time: 1.66 seconds\n",
      "Epoch [326/1000], Train Loss: 0.0000006077, Train MSE: 0.0000046320,             Test MSE: 0.0000024515, Time: 1.60 seconds\n",
      "Epoch [327/1000], Train Loss: 0.0000091424, Train MSE: 0.0000018704,             Test MSE: 0.0000007822, Time: 1.45 seconds\n",
      "Epoch [328/1000], Train Loss: 0.0000032231, Train MSE: 0.0000019547,             Test MSE: 0.0000012943, Time: 1.62 seconds\n",
      "Epoch [329/1000], Train Loss: 0.0000026368, Train MSE: 0.0000000641,             Test MSE: 0.0000000246, Time: 1.72 seconds\n",
      "Epoch [330/1000], Train Loss: 0.0000004881, Train MSE: 0.0000001755,             Test MSE: 0.0000001662, Time: 1.51 seconds\n",
      "Epoch [331/1000], Train Loss: 0.0000021588, Train MSE: 0.0000094400,             Test MSE: 0.0000047389, Time: 1.74 seconds\n",
      "Epoch [332/1000], Train Loss: 0.0000087129, Train MSE: 0.0000062836,             Test MSE: 0.0000038711, Time: 1.75 seconds\n",
      "Epoch [333/1000], Train Loss: 0.0000038208, Train MSE: 0.0000083042,             Test MSE: 0.0000042470, Time: 1.63 seconds\n",
      "Epoch [334/1000], Train Loss: 0.0000008293, Train MSE: 0.0000001866,             Test MSE: 0.0000001663, Time: 1.69 seconds\n",
      "Epoch [335/1000], Train Loss: 0.0000001317, Train MSE: 0.0000000202,             Test MSE: 0.0000000176, Time: 1.66 seconds\n",
      "Epoch [336/1000], Train Loss: 0.0000012080, Train MSE: 0.0000073772,             Test MSE: 0.0000054691, Time: 1.63 seconds\n",
      "Epoch [337/1000], Train Loss: 0.0000119566, Train MSE: 0.0000004205,             Test MSE: 0.0000004857, Time: 1.88 seconds\n",
      "Epoch [338/1000], Train Loss: 0.0000011221, Train MSE: 0.0000001190,             Test MSE: 0.0000000791, Time: 1.73 seconds\n",
      "Epoch [339/1000], Train Loss: 0.0000000789, Train MSE: 0.0000000249,             Test MSE: 0.0000000171, Time: 1.87 seconds\n",
      "Epoch [340/1000], Train Loss: 0.0000002484, Train MSE: 0.0000002608,             Test MSE: 0.0000001076, Time: 1.66 seconds\n",
      "Epoch [341/1000], Train Loss: 0.0000087059, Train MSE: 0.0000048300,             Test MSE: 0.0000033392, Time: 1.65 seconds\n",
      "Epoch [342/1000], Train Loss: 0.0000007167, Train MSE: 0.0000002470,             Test MSE: 0.0000001168, Time: 1.67 seconds\n",
      "Epoch [343/1000], Train Loss: 0.0000001739, Train MSE: 0.0000000704,             Test MSE: 0.0000000672, Time: 1.85 seconds\n",
      "Epoch [344/1000], Train Loss: 0.0000123613, Train MSE: 0.0000060131,             Test MSE: 0.0000046917, Time: 1.64 seconds\n",
      "Epoch [345/1000], Train Loss: 0.0000021630, Train MSE: 0.0000000097,             Test MSE: 0.0000000057, Time: 1.53 seconds\n",
      "Epoch [346/1000], Train Loss: 0.0000001614, Train MSE: 0.0000000181,             Test MSE: 0.0000000141, Time: 1.69 seconds\n",
      "Epoch [347/1000], Train Loss: 0.0000003451, Train MSE: 0.0000000347,             Test MSE: 0.0000000150, Time: 1.55 seconds\n",
      "Epoch [348/1000], Train Loss: 0.0000009820, Train MSE: 0.0000054270,             Test MSE: 0.0000033590, Time: 1.57 seconds\n",
      "Epoch [349/1000], Train Loss: 0.0000109202, Train MSE: 0.0000075270,             Test MSE: 0.0000054728, Time: 1.86 seconds\n",
      "Epoch [350/1000], Train Loss: 0.0000042548, Train MSE: 0.0000000978,             Test MSE: 0.0000001034, Time: 1.51 seconds\n",
      "Epoch [351/1000], Train Loss: 0.0000030206, Train MSE: 0.0000021802,             Test MSE: 0.0000012434, Time: 1.69 seconds\n",
      "Epoch [352/1000], Train Loss: 0.0000004148, Train MSE: 0.0000003101,             Test MSE: 0.0000001690, Time: 1.77 seconds\n",
      "Epoch [353/1000], Train Loss: 0.0000056554, Train MSE: 0.0000061715,             Test MSE: 0.0000033583, Time: 1.86 seconds\n",
      "Epoch [354/1000], Train Loss: 0.0000040507, Train MSE: 0.0000104216,             Test MSE: 0.0000064993, Time: 1.79 seconds\n",
      "Epoch [355/1000], Train Loss: 0.0000037546, Train MSE: 0.0000011314,             Test MSE: 0.0000008885, Time: 2.01 seconds\n",
      "Epoch [356/1000], Train Loss: 0.0000003572, Train MSE: 0.0000000051,             Test MSE: 0.0000000049, Time: 1.83 seconds\n",
      "Epoch [357/1000], Train Loss: 0.0000002604, Train MSE: 0.0000012162,             Test MSE: 0.0000007830, Time: 1.68 seconds\n",
      "Epoch [358/1000], Train Loss: 0.0000002330, Train MSE: 0.0000001882,             Test MSE: 0.0000001502, Time: 1.54 seconds\n",
      "Epoch [359/1000], Train Loss: 0.0000106603, Train MSE: 0.0000051359,             Test MSE: 0.0000039336, Time: 1.45 seconds\n",
      "Epoch [360/1000], Train Loss: 0.0000081559, Train MSE: 0.0000049582,             Test MSE: 0.0000031264, Time: 1.46 seconds\n",
      "Epoch [361/1000], Train Loss: 0.0000019517, Train MSE: 0.0000000041,             Test MSE: 0.0000000080, Time: 1.55 seconds\n",
      "Epoch [362/1000], Train Loss: 0.0000000159, Train MSE: 0.0000000101,             Test MSE: 0.0000000052, Time: 1.65 seconds\n",
      "Epoch [363/1000], Train Loss: 0.0000000602, Train MSE: 0.0000002027,             Test MSE: 0.0000001916, Time: 1.54 seconds\n",
      "Epoch [364/1000], Train Loss: 0.0000007393, Train MSE: 0.0000006112,             Test MSE: 0.0000004532, Time: 1.54 seconds\n",
      "Epoch [365/1000], Train Loss: 0.0000024308, Train MSE: 0.0000023029,             Test MSE: 0.0000017747, Time: 1.68 seconds\n",
      "Epoch [366/1000], Train Loss: 0.0000272399, Train MSE: 0.0000000560,             Test MSE: 0.0000000950, Time: 1.55 seconds\n",
      "Epoch [367/1000], Train Loss: 0.0000002433, Train MSE: 0.0000000094,             Test MSE: 0.0000000090, Time: 1.59 seconds\n",
      "Epoch [368/1000], Train Loss: 0.0000000958, Train MSE: 0.0000000189,             Test MSE: 0.0000000165, Time: 1.65 seconds\n",
      "Epoch [369/1000], Train Loss: 0.0000000378, Train MSE: 0.0000001555,             Test MSE: 0.0000001114, Time: 1.69 seconds\n",
      "Epoch [370/1000], Train Loss: 0.0000000167, Train MSE: 0.0000000021,             Test MSE: 0.0000000021, Time: 1.73 seconds\n",
      "Epoch [371/1000], Train Loss: 0.0000000011, Train MSE: 0.0000000003,             Test MSE: 0.0000000007, Time: 1.46 seconds\n",
      "Epoch [372/1000], Train Loss: 0.0000000061, Train MSE: 0.0000000494,             Test MSE: 0.0000000360, Time: 1.57 seconds\n",
      "Epoch [373/1000], Train Loss: 0.0000057228, Train MSE: 0.0000238692,             Test MSE: 0.0000157809, Time: 1.54 seconds\n",
      "Epoch [374/1000], Train Loss: 0.0000059739, Train MSE: 0.0000003056,             Test MSE: 0.0000003488, Time: 1.52 seconds\n",
      "Epoch [375/1000], Train Loss: 0.0000010909, Train MSE: 0.0000000261,             Test MSE: 0.0000000220, Time: 1.54 seconds\n",
      "Epoch [376/1000], Train Loss: 0.0000008874, Train MSE: 0.0000024622,             Test MSE: 0.0000016335, Time: 1.63 seconds\n",
      "Epoch [377/1000], Train Loss: 0.0000013830, Train MSE: 0.0000000043,             Test MSE: 0.0000000081, Time: 1.71 seconds\n",
      "Epoch [378/1000], Train Loss: 0.0000023839, Train MSE: 0.0000002102,             Test MSE: 0.0000001931, Time: 1.58 seconds\n",
      "Epoch [379/1000], Train Loss: 0.0000044114, Train MSE: 0.0000067329,             Test MSE: 0.0000038457, Time: 1.59 seconds\n",
      "Epoch [380/1000], Train Loss: 0.0000056117, Train MSE: 0.0000049323,             Test MSE: 0.0000033532, Time: 1.56 seconds\n",
      "Epoch [381/1000], Train Loss: 0.0000004726, Train MSE: 0.0000000151,             Test MSE: 0.0000000150, Time: 1.56 seconds\n",
      "Epoch [382/1000], Train Loss: 0.0000016267, Train MSE: 0.0000246408,             Test MSE: 0.0000172453, Time: 1.56 seconds\n",
      "Epoch [383/1000], Train Loss: 0.0000049577, Train MSE: 0.0000035964,             Test MSE: 0.0000022838, Time: 1.54 seconds\n",
      "Epoch [384/1000], Train Loss: 0.0000006726, Train MSE: 0.0000001872,             Test MSE: 0.0000001786, Time: 1.52 seconds\n",
      "Epoch [385/1000], Train Loss: 0.0000077913, Train MSE: 0.0000006898,             Test MSE: 0.0000006547, Time: 1.74 seconds\n",
      "Epoch [386/1000], Train Loss: 0.0000029012, Train MSE: 0.0000001004,             Test MSE: 0.0000000573, Time: 1.56 seconds\n",
      "Epoch [387/1000], Train Loss: 0.0000007121, Train MSE: 0.0000000147,             Test MSE: 0.0000000112, Time: 1.56 seconds\n",
      "Epoch [388/1000], Train Loss: 0.0000005247, Train MSE: 0.0000018115,             Test MSE: 0.0000013802, Time: 1.53 seconds\n",
      "Epoch [389/1000], Train Loss: 0.0000077098, Train MSE: 0.0000010355,             Test MSE: 0.0000006337, Time: 1.57 seconds\n",
      "Epoch [390/1000], Train Loss: 0.0000006936, Train MSE: 0.0000000076,             Test MSE: 0.0000000061, Time: 1.67 seconds\n",
      "Epoch [391/1000], Train Loss: 0.0000000826, Train MSE: 0.0000000044,             Test MSE: 0.0000000066, Time: 1.58 seconds\n",
      "Epoch [392/1000], Train Loss: 0.0000057309, Train MSE: 0.0000001885,             Test MSE: 0.0000001543, Time: 1.59 seconds\n",
      "Epoch [393/1000], Train Loss: 0.0000010862, Train MSE: 0.0000003409,             Test MSE: 0.0000002476, Time: 1.57 seconds\n",
      "Epoch [394/1000], Train Loss: 0.0000045239, Train MSE: 0.0000000104,             Test MSE: 0.0000000113, Time: 1.56 seconds\n",
      "Epoch [395/1000], Train Loss: 0.0000005866, Train MSE: 0.0000047563,             Test MSE: 0.0000033939, Time: 1.55 seconds\n",
      "Epoch [396/1000], Train Loss: 0.0000060171, Train MSE: 0.0000018835,             Test MSE: 0.0000012138, Time: 1.58 seconds\n",
      "Epoch [397/1000], Train Loss: 0.0000011408, Train MSE: 0.0000010153,             Test MSE: 0.0000006911, Time: 1.54 seconds\n",
      "Epoch [398/1000], Train Loss: 0.0000025894, Train MSE: 0.0000000500,             Test MSE: 0.0000000398, Time: 1.57 seconds\n",
      "Epoch [399/1000], Train Loss: 0.0000012032, Train MSE: 0.0000060548,             Test MSE: 0.0000044493, Time: 1.57 seconds\n",
      "Epoch [400/1000], Train Loss: 0.0000117686, Train MSE: 0.0000017650,             Test MSE: 0.0000011144, Time: 1.61 seconds\n",
      "Epoch [401/1000], Train Loss: 0.0000002466, Train MSE: 0.0000000169,             Test MSE: 0.0000000147, Time: 1.82 seconds\n",
      "Epoch [402/1000], Train Loss: 0.0000000180, Train MSE: 0.0000000005,             Test MSE: 0.0000000008, Time: 1.74 seconds\n",
      "Epoch [403/1000], Train Loss: 0.0000001268, Train MSE: 0.0000001981,             Test MSE: 0.0000001422, Time: 1.74 seconds\n",
      "Epoch [404/1000], Train Loss: 0.0000066299, Train MSE: 0.0000001110,             Test MSE: 0.0000000925, Time: 1.53 seconds\n",
      "Epoch [405/1000], Train Loss: 0.0000006540, Train MSE: 0.0000005681,             Test MSE: 0.0000003926, Time: 1.55 seconds\n",
      "Epoch [406/1000], Train Loss: 0.0000025282, Train MSE: 0.0000000307,             Test MSE: 0.0000000323, Time: 1.50 seconds\n",
      "Epoch [407/1000], Train Loss: 0.0000065340, Train MSE: 0.0000127006,             Test MSE: 0.0000101969, Time: 1.56 seconds\n",
      "Epoch [408/1000], Train Loss: 0.0000050259, Train MSE: 0.0000004947,             Test MSE: 0.0000004669, Time: 1.56 seconds\n",
      "Epoch [409/1000], Train Loss: 0.0000001077, Train MSE: 0.0000002284,             Test MSE: 0.0000001737, Time: 1.55 seconds\n",
      "Epoch [410/1000], Train Loss: 0.0000005016, Train MSE: 0.0000000057,             Test MSE: 0.0000000052, Time: 1.56 seconds\n",
      "Epoch [411/1000], Train Loss: 0.0000115439, Train MSE: 0.0000000376,             Test MSE: 0.0000000555, Time: 1.53 seconds\n",
      "Epoch [412/1000], Train Loss: 0.0000022114, Train MSE: 0.0000000119,             Test MSE: 0.0000000094, Time: 1.60 seconds\n",
      "Epoch [413/1000], Train Loss: 0.0000002030, Train MSE: 0.0000000199,             Test MSE: 0.0000000245, Time: 1.54 seconds\n",
      "Epoch [414/1000], Train Loss: 0.0000000054, Train MSE: 0.0000000007,             Test MSE: 0.0000000010, Time: 1.53 seconds\n",
      "Epoch [415/1000], Train Loss: 0.0000000172, Train MSE: 0.0000001355,             Test MSE: 0.0000001049, Time: 1.57 seconds\n",
      "Epoch [416/1000], Train Loss: 0.0000050052, Train MSE: 0.0000005854,             Test MSE: 0.0000002863, Time: 1.56 seconds\n",
      "Epoch [417/1000], Train Loss: 0.0000066490, Train MSE: 0.0000152389,             Test MSE: 0.0000109296, Time: 1.55 seconds\n",
      "Epoch [418/1000], Train Loss: 0.0000044417, Train MSE: 0.0000003892,             Test MSE: 0.0000003147, Time: 1.54 seconds\n",
      "Epoch [419/1000], Train Loss: 0.0000001635, Train MSE: 0.0000000064,             Test MSE: 0.0000000068, Time: 1.56 seconds\n",
      "Epoch [420/1000], Train Loss: 0.0000000033, Train MSE: 0.0000000002,             Test MSE: 0.0000000005, Time: 1.74 seconds\n",
      "Epoch [421/1000], Train Loss: 0.0000053724, Train MSE: 0.0000103234,             Test MSE: 0.0000086555, Time: 1.59 seconds\n",
      "Epoch [422/1000], Train Loss: 0.0000040865, Train MSE: 0.0000009200,             Test MSE: 0.0000006508, Time: 1.82 seconds\n",
      "Epoch [423/1000], Train Loss: 0.0000003153, Train MSE: 0.0000010843,             Test MSE: 0.0000008433, Time: 1.80 seconds\n",
      "Epoch [424/1000], Train Loss: 0.0000088544, Train MSE: 0.0000257114,             Test MSE: 0.0000174929, Time: 2.06 seconds\n",
      "Epoch [425/1000], Train Loss: 0.0000028051, Train MSE: 0.0000004676,             Test MSE: 0.0000003562, Time: 1.59 seconds\n",
      "Epoch [426/1000], Train Loss: 0.0000018457, Train MSE: 0.0000010939,             Test MSE: 0.0000008518, Time: 1.60 seconds\n",
      "Epoch [427/1000], Train Loss: 0.0000007107, Train MSE: 0.0000008249,             Test MSE: 0.0000007095, Time: 1.73 seconds\n",
      "Epoch [428/1000], Train Loss: 0.0000015208, Train MSE: 0.0000015399,             Test MSE: 0.0000009434, Time: 1.68 seconds\n",
      "Epoch [429/1000], Train Loss: 0.0000051512, Train MSE: 0.0000009925,             Test MSE: 0.0000007026, Time: 1.58 seconds\n",
      "Epoch [430/1000], Train Loss: 0.0000012865, Train MSE: 0.0000064422,             Test MSE: 0.0000046328, Time: 1.56 seconds\n",
      "Epoch [431/1000], Train Loss: 0.0000038747, Train MSE: 0.0000013693,             Test MSE: 0.0000011728, Time: 1.57 seconds\n",
      "Epoch [432/1000], Train Loss: 0.0000010118, Train MSE: 0.0000064679,             Test MSE: 0.0000045745, Time: 1.54 seconds\n",
      "Epoch [433/1000], Train Loss: 0.0000047483, Train MSE: 0.0000010039,             Test MSE: 0.0000006178, Time: 1.75 seconds\n",
      "Epoch [434/1000], Train Loss: 0.0000059864, Train MSE: 0.0000016312,             Test MSE: 0.0000012058, Time: 1.76 seconds\n",
      "Epoch [435/1000], Train Loss: 0.0000079537, Train MSE: 0.0000038979,             Test MSE: 0.0000027228, Time: 1.49 seconds\n",
      "Epoch [436/1000], Train Loss: 0.0000004114, Train MSE: 0.0000000326,             Test MSE: 0.0000000362, Time: 1.52 seconds\n",
      "Epoch [437/1000], Train Loss: 0.0000007122, Train MSE: 0.0000000084,             Test MSE: 0.0000000069, Time: 1.59 seconds\n",
      "Epoch [438/1000], Train Loss: 0.0000000872, Train MSE: 0.0000002127,             Test MSE: 0.0000001519, Time: 1.53 seconds\n",
      "Epoch [439/1000], Train Loss: 0.0000021047, Train MSE: 0.0000006062,             Test MSE: 0.0000003782, Time: 1.57 seconds\n",
      "Epoch [440/1000], Train Loss: 0.0000076661, Train MSE: 0.0000016334,             Test MSE: 0.0000010883, Time: 1.52 seconds\n",
      "Epoch [441/1000], Train Loss: 0.0000001371, Train MSE: 0.0000001271,             Test MSE: 0.0000001105, Time: 1.57 seconds\n",
      "Epoch [442/1000], Train Loss: 0.0000008935, Train MSE: 0.0000026069,             Test MSE: 0.0000021596, Time: 1.57 seconds\n",
      "Epoch [443/1000], Train Loss: 0.0000091071, Train MSE: 0.0000025972,             Test MSE: 0.0000019345, Time: 1.57 seconds\n",
      "Epoch [444/1000], Train Loss: 0.0000087420, Train MSE: 0.0000003748,             Test MSE: 0.0000003452, Time: 1.59 seconds\n",
      "Epoch [445/1000], Train Loss: 0.0000017764, Train MSE: 0.0000004737,             Test MSE: 0.0000004526, Time: 1.55 seconds\n",
      "Epoch [446/1000], Train Loss: 0.0000003179, Train MSE: 0.0000015255,             Test MSE: 0.0000012339, Time: 1.73 seconds\n",
      "Epoch [447/1000], Train Loss: 0.0000004533, Train MSE: 0.0000000079,             Test MSE: 0.0000000141, Time: 1.57 seconds\n",
      "Epoch [448/1000], Train Loss: 0.0000000160, Train MSE: 0.0000000108,             Test MSE: 0.0000000078, Time: 1.56 seconds\n",
      "Epoch [449/1000], Train Loss: 0.0000008708, Train MSE: 0.0000060025,             Test MSE: 0.0000045686, Time: 1.67 seconds\n",
      "Epoch [450/1000], Train Loss: 0.0000034254, Train MSE: 0.0000001838,             Test MSE: 0.0000001158, Time: 1.55 seconds\n",
      "Epoch [451/1000], Train Loss: 0.0000060110, Train MSE: 0.0000002336,             Test MSE: 0.0000001755, Time: 1.74 seconds\n",
      "Epoch [452/1000], Train Loss: 0.0000059597, Train MSE: 0.0000014620,             Test MSE: 0.0000010755, Time: 1.58 seconds\n",
      "Epoch [453/1000], Train Loss: 0.0000000817, Train MSE: 0.0000000980,             Test MSE: 0.0000000852, Time: 1.61 seconds\n",
      "Epoch [454/1000], Train Loss: 0.0000001069, Train MSE: 0.0000018422,             Test MSE: 0.0000014236, Time: 1.55 seconds\n",
      "Epoch [455/1000], Train Loss: 0.0000051749, Train MSE: 0.0000213200,             Test MSE: 0.0000166111, Time: 1.58 seconds\n",
      "Epoch [456/1000], Train Loss: 0.0000102717, Train MSE: 0.0000039051,             Test MSE: 0.0000033094, Time: 1.60 seconds\n",
      "Epoch [457/1000], Train Loss: 0.0000003674, Train MSE: 0.0000000136,             Test MSE: 0.0000000074, Time: 1.62 seconds\n",
      "Epoch [458/1000], Train Loss: 0.0000000891, Train MSE: 0.0000000009,             Test MSE: 0.0000000011, Time: 1.56 seconds\n",
      "Epoch [459/1000], Train Loss: 0.0000000194, Train MSE: 0.0000000067,             Test MSE: 0.0000000059, Time: 1.57 seconds\n",
      "Epoch [460/1000], Train Loss: 0.0000005625, Train MSE: 0.0000204877,             Test MSE: 0.0000173273, Time: 1.53 seconds\n",
      "Epoch [461/1000], Train Loss: 0.0000165214, Train MSE: 0.0000062504,             Test MSE: 0.0000046293, Time: 1.53 seconds\n",
      "Epoch [462/1000], Train Loss: 0.0000010198, Train MSE: 0.0000005171,             Test MSE: 0.0000004542, Time: 1.57 seconds\n",
      "Epoch [463/1000], Train Loss: 0.0000069378, Train MSE: 0.0000000822,             Test MSE: 0.0000000747, Time: 1.52 seconds\n",
      "Epoch [464/1000], Train Loss: 0.0000000607, Train MSE: 0.0000000201,             Test MSE: 0.0000000176, Time: 1.74 seconds\n",
      "Epoch [465/1000], Train Loss: 0.0000000347, Train MSE: 0.0000002672,             Test MSE: 0.0000002091, Time: 1.64 seconds\n",
      "Epoch [466/1000], Train Loss: 0.0000004936, Train MSE: 0.0000000900,             Test MSE: 0.0000000630, Time: 1.77 seconds\n",
      "Epoch [467/1000], Train Loss: 0.0000003225, Train MSE: 0.0000003683,             Test MSE: 0.0000002989, Time: 1.71 seconds\n",
      "Epoch [468/1000], Train Loss: 0.0000061920, Train MSE: 0.0000004236,             Test MSE: 0.0000004777, Time: 1.60 seconds\n",
      "Epoch [469/1000], Train Loss: 0.0000007333, Train MSE: 0.0000000285,             Test MSE: 0.0000000225, Time: 1.59 seconds\n",
      "Epoch [470/1000], Train Loss: 0.0000002779, Train MSE: 0.0000006368,             Test MSE: 0.0000004509, Time: 1.56 seconds\n",
      "Epoch [471/1000], Train Loss: 0.0000075203, Train MSE: 0.0000015182,             Test MSE: 0.0000010683, Time: 1.52 seconds\n",
      "Epoch [472/1000], Train Loss: 0.0000023246, Train MSE: 0.0000001499,             Test MSE: 0.0000000943, Time: 1.54 seconds\n",
      "Epoch [473/1000], Train Loss: 0.0000000396, Train MSE: 0.0000000021,             Test MSE: 0.0000000020, Time: 1.59 seconds\n",
      "Epoch [474/1000], Train Loss: 0.0000044751, Train MSE: 0.0000067207,             Test MSE: 0.0000051588, Time: 1.54 seconds\n",
      "Epoch [475/1000], Train Loss: 0.0000030893, Train MSE: 0.0000007913,             Test MSE: 0.0000006288, Time: 1.53 seconds\n",
      "Epoch [476/1000], Train Loss: 0.0000008536, Train MSE: 0.0000000095,             Test MSE: 0.0000000121, Time: 1.57 seconds\n",
      "Epoch [477/1000], Train Loss: 0.0000021970, Train MSE: 0.0000151287,             Test MSE: 0.0000115012, Time: 1.58 seconds\n",
      "Epoch [478/1000], Train Loss: 0.0000025331, Train MSE: 0.0000000353,             Test MSE: 0.0000000416, Time: 1.55 seconds\n",
      "Epoch [479/1000], Train Loss: 0.0000032433, Train MSE: 0.0000032688,             Test MSE: 0.0000028141, Time: 1.66 seconds\n",
      "Epoch [480/1000], Train Loss: 0.0000028585, Train MSE: 0.0000026912,             Test MSE: 0.0000019383, Time: 1.55 seconds\n",
      "Epoch [481/1000], Train Loss: 0.0000011746, Train MSE: 0.0000000337,             Test MSE: 0.0000000365, Time: 1.65 seconds\n",
      "Epoch [482/1000], Train Loss: 0.0000038230, Train MSE: 0.0000017992,             Test MSE: 0.0000015532, Time: 1.64 seconds\n",
      "Epoch [483/1000], Train Loss: 0.0000006229, Train MSE: 0.0000000572,             Test MSE: 0.0000000519, Time: 1.64 seconds\n",
      "Epoch [484/1000], Train Loss: 0.0000035593, Train MSE: 0.0000015870,             Test MSE: 0.0000013843, Time: 1.59 seconds\n",
      "Epoch [485/1000], Train Loss: 0.0000267862, Train MSE: 0.0000005143,             Test MSE: 0.0000004884, Time: 1.55 seconds\n",
      "Epoch [486/1000], Train Loss: 0.0000001154, Train MSE: 0.0000000550,             Test MSE: 0.0000000555, Time: 1.62 seconds\n",
      "Epoch [487/1000], Train Loss: 0.0000000271, Train MSE: 0.0000000007,             Test MSE: 0.0000000009, Time: 1.51 seconds\n",
      "Epoch [488/1000], Train Loss: 0.0000000039, Train MSE: 0.0000000014,             Test MSE: 0.0000000017, Time: 1.65 seconds\n",
      "Epoch [489/1000], Train Loss: 0.0000000059, Train MSE: 0.0000000091,             Test MSE: 0.0000000080, Time: 1.70 seconds\n",
      "Epoch [490/1000], Train Loss: 0.0000001924, Train MSE: 0.0000012870,             Test MSE: 0.0000011263, Time: 1.57 seconds\n",
      "Epoch [491/1000], Train Loss: 0.0000005554, Train MSE: 0.0000007950,             Test MSE: 0.0000006374, Time: 1.55 seconds\n",
      "Epoch [492/1000], Train Loss: 0.0000016583, Train MSE: 0.0000000935,             Test MSE: 0.0000000815, Time: 1.56 seconds\n",
      "Epoch [493/1000], Train Loss: 0.0000130710, Train MSE: 0.0000348797,             Test MSE: 0.0000290475, Time: 1.59 seconds\n",
      "Epoch [494/1000], Train Loss: 0.0000053160, Train MSE: 0.0000030526,             Test MSE: 0.0000024317, Time: 1.56 seconds\n",
      "Epoch [495/1000], Train Loss: 0.0000010225, Train MSE: 0.0000000113,             Test MSE: 0.0000000130, Time: 1.54 seconds\n",
      "Epoch [496/1000], Train Loss: 0.0000001003, Train MSE: 0.0000000120,             Test MSE: 0.0000000137, Time: 1.56 seconds\n",
      "Epoch [497/1000], Train Loss: 0.0000001797, Train MSE: 0.0000001919,             Test MSE: 0.0000001535, Time: 1.59 seconds\n",
      "Epoch [498/1000], Train Loss: 0.0000005161, Train MSE: 0.0000002559,             Test MSE: 0.0000001915, Time: 1.65 seconds\n",
      "Epoch [499/1000], Train Loss: 0.0000016810, Train MSE: 0.0000075283,             Test MSE: 0.0000057626, Time: 1.69 seconds\n",
      "Epoch [500/1000], Train Loss: 0.0000039188, Train MSE: 0.0000001298,             Test MSE: 0.0000001089, Time: 1.65 seconds\n",
      "Epoch [501/1000], Train Loss: 0.0000005247, Train MSE: 0.0000004961,             Test MSE: 0.0000004124, Time: 1.55 seconds\n",
      "Epoch [502/1000], Train Loss: 0.0000043168, Train MSE: 0.0000000999,             Test MSE: 0.0000001029, Time: 1.55 seconds\n",
      "Epoch [503/1000], Train Loss: 0.0000103765, Train MSE: 0.0000191159,             Test MSE: 0.0000147530, Time: 1.61 seconds\n",
      "Epoch [504/1000], Train Loss: 0.0000055811, Train MSE: 0.0000000127,             Test MSE: 0.0000000132, Time: 1.57 seconds\n",
      "Epoch [505/1000], Train Loss: 0.0000019629, Train MSE: 0.0000005500,             Test MSE: 0.0000004868, Time: 1.56 seconds\n",
      "Epoch [506/1000], Train Loss: 0.0000001733, Train MSE: 0.0000002445,             Test MSE: 0.0000002159, Time: 1.63 seconds\n",
      "Epoch [507/1000], Train Loss: 0.0000002518, Train MSE: 0.0000002048,             Test MSE: 0.0000001703, Time: 1.51 seconds\n",
      "Epoch [508/1000], Train Loss: 0.0000005939, Train MSE: 0.0000001877,             Test MSE: 0.0000001579, Time: 1.57 seconds\n",
      "Epoch [509/1000], Train Loss: 0.0000005537, Train MSE: 0.0000005938,             Test MSE: 0.0000004667, Time: 1.57 seconds\n",
      "Epoch [510/1000], Train Loss: 0.0000164402, Train MSE: 0.0000053781,             Test MSE: 0.0000063165, Time: 1.69 seconds\n",
      "Epoch [511/1000], Train Loss: 0.0000027323, Train MSE: 0.0000004605,             Test MSE: 0.0000003034, Time: 1.54 seconds\n",
      "Epoch [512/1000], Train Loss: 0.0000003061, Train MSE: 0.0000000369,             Test MSE: 0.0000000447, Time: 1.53 seconds\n",
      "Epoch [513/1000], Train Loss: 0.0000011748, Train MSE: 0.0000036213,             Test MSE: 0.0000027858, Time: 1.56 seconds\n",
      "Epoch [514/1000], Train Loss: 0.0000049561, Train MSE: 0.0000017477,             Test MSE: 0.0000013854, Time: 1.54 seconds\n",
      "Epoch [515/1000], Train Loss: 0.0000014696, Train MSE: 0.0000034867,             Test MSE: 0.0000026990, Time: 1.57 seconds\n",
      "Epoch [516/1000], Train Loss: 0.0000025648, Train MSE: 0.0000007685,             Test MSE: 0.0000005368, Time: 1.56 seconds\n",
      "Epoch [517/1000], Train Loss: 0.0000018114, Train MSE: 0.0000065386,             Test MSE: 0.0000044503, Time: 1.50 seconds\n",
      "Epoch [518/1000], Train Loss: 0.0000046955, Train MSE: 0.0000000419,             Test MSE: 0.0000000237, Time: 1.60 seconds\n",
      "Epoch [519/1000], Train Loss: 0.0000004774, Train MSE: 0.0000002265,             Test MSE: 0.0000001768, Time: 1.58 seconds\n",
      "Epoch [520/1000], Train Loss: 0.0000020970, Train MSE: 0.0000002113,             Test MSE: 0.0000001307, Time: 1.55 seconds\n",
      "Epoch [521/1000], Train Loss: 0.0000044411, Train MSE: 0.0000102566,             Test MSE: 0.0000075259, Time: 1.54 seconds\n",
      "Epoch [522/1000], Train Loss: 0.0000019171, Train MSE: 0.0000018643,             Test MSE: 0.0000013975, Time: 1.55 seconds\n",
      "Epoch [523/1000], Train Loss: 0.0000023543, Train MSE: 0.0000002336,             Test MSE: 0.0000002975, Time: 1.61 seconds\n",
      "Epoch [524/1000], Train Loss: 0.0000052599, Train MSE: 0.0000000758,             Test MSE: 0.0000000634, Time: 1.58 seconds\n",
      "Epoch [525/1000], Train Loss: 0.0000011332, Train MSE: 0.0000005946,             Test MSE: 0.0000003997, Time: 1.64 seconds\n",
      "Epoch [526/1000], Train Loss: 0.0000000431, Train MSE: 0.0000000375,             Test MSE: 0.0000000294, Time: 1.58 seconds\n",
      "Epoch [527/1000], Train Loss: 0.0000120960, Train MSE: 0.0000005375,             Test MSE: 0.0000003915, Time: 1.53 seconds\n",
      "Epoch [528/1000], Train Loss: 0.0000074855, Train MSE: 0.0000080767,             Test MSE: 0.0000069923, Time: 1.56 seconds\n",
      "Epoch [529/1000], Train Loss: 0.0000077253, Train MSE: 0.0000073098,             Test MSE: 0.0000056439, Time: 1.64 seconds\n",
      "Epoch [530/1000], Train Loss: 0.0000042511, Train MSE: 0.0000050728,             Test MSE: 0.0000037436, Time: 1.53 seconds\n",
      "Epoch [531/1000], Train Loss: 0.0000027408, Train MSE: 0.0000042218,             Test MSE: 0.0000032301, Time: 1.64 seconds\n",
      "Epoch [532/1000], Train Loss: 0.0000027393, Train MSE: 0.0000031046,             Test MSE: 0.0000020090, Time: 1.73 seconds\n",
      "Epoch [533/1000], Train Loss: 0.0000006990, Train MSE: 0.0000000586,             Test MSE: 0.0000000330, Time: 1.65 seconds\n",
      "Epoch [534/1000], Train Loss: 0.0000000323, Train MSE: 0.0000000018,             Test MSE: 0.0000000011, Time: 1.64 seconds\n",
      "Epoch [535/1000], Train Loss: 0.0000000313, Train MSE: 0.0000000053,             Test MSE: 0.0000000034, Time: 1.52 seconds\n",
      "Epoch [536/1000], Train Loss: 0.0000000061, Train MSE: 0.0000000020,             Test MSE: 0.0000000011, Time: 1.62 seconds\n",
      "Epoch [537/1000], Train Loss: 0.0000000769, Train MSE: 0.0000001994,             Test MSE: 0.0000001264, Time: 1.63 seconds\n",
      "Epoch [538/1000], Train Loss: 0.0000060014, Train MSE: 0.0000127512,             Test MSE: 0.0000097982, Time: 1.63 seconds\n",
      "Epoch [539/1000], Train Loss: 0.0000011128, Train MSE: 0.0000000380,             Test MSE: 0.0000000201, Time: 1.57 seconds\n",
      "Epoch [540/1000], Train Loss: 0.0000025998, Train MSE: 0.0000005769,             Test MSE: 0.0000003182, Time: 1.60 seconds\n",
      "Epoch [541/1000], Train Loss: 0.0000059036, Train MSE: 0.0000076280,             Test MSE: 0.0000059412, Time: 1.58 seconds\n",
      "Epoch [542/1000], Train Loss: 0.0000014072, Train MSE: 0.0000001397,             Test MSE: 0.0000001295, Time: 1.56 seconds\n",
      "Epoch [543/1000], Train Loss: 0.0000002972, Train MSE: 0.0000001022,             Test MSE: 0.0000000803, Time: 1.63 seconds\n",
      "Epoch [544/1000], Train Loss: 0.0000013348, Train MSE: 0.0000001122,             Test MSE: 0.0000000988, Time: 1.59 seconds\n",
      "Epoch [545/1000], Train Loss: 0.0000138418, Train MSE: 0.0000069852,             Test MSE: 0.0000047379, Time: 1.57 seconds\n",
      "Epoch [546/1000], Train Loss: 0.0000015353, Train MSE: 0.0000005753,             Test MSE: 0.0000005428, Time: 1.56 seconds\n",
      "Epoch [547/1000], Train Loss: 0.0000002578, Train MSE: 0.0000000053,             Test MSE: 0.0000000038, Time: 1.61 seconds\n",
      "Epoch [548/1000], Train Loss: 0.0000000071, Train MSE: 0.0000000003,             Test MSE: 0.0000000005, Time: 1.56 seconds\n",
      "Epoch [549/1000], Train Loss: 0.0000000796, Train MSE: 0.0000001697,             Test MSE: 0.0000000962, Time: 1.56 seconds\n",
      "Epoch [550/1000], Train Loss: 0.0000101748, Train MSE: 0.0000001172,             Test MSE: 0.0000001147, Time: 1.57 seconds\n",
      "Epoch [551/1000], Train Loss: 0.0000000677, Train MSE: 0.0000000023,             Test MSE: 0.0000000017, Time: 1.59 seconds\n",
      "Epoch [552/1000], Train Loss: 0.0000000110, Train MSE: 0.0000000035,             Test MSE: 0.0000000039, Time: 1.56 seconds\n",
      "Epoch [553/1000], Train Loss: 0.0000043469, Train MSE: 0.0000172019,             Test MSE: 0.0000120500, Time: 1.57 seconds\n",
      "Epoch [554/1000], Train Loss: 0.0000010810, Train MSE: 0.0000001329,             Test MSE: 0.0000000905, Time: 1.65 seconds\n",
      "Epoch [555/1000], Train Loss: 0.0000024053, Train MSE: 0.0000000826,             Test MSE: 0.0000000529, Time: 1.65 seconds\n",
      "Epoch [556/1000], Train Loss: 0.0000027626, Train MSE: 0.0000091389,             Test MSE: 0.0000071227, Time: 1.60 seconds\n",
      "Epoch [557/1000], Train Loss: 0.0000080281, Train MSE: 0.0000005605,             Test MSE: 0.0000004599, Time: 1.58 seconds\n",
      "Epoch [558/1000], Train Loss: 0.0000000622, Train MSE: 0.0000000019,             Test MSE: 0.0000000017, Time: 1.55 seconds\n",
      "Epoch [559/1000], Train Loss: 0.0000000348, Train MSE: 0.0000000309,             Test MSE: 0.0000000276, Time: 1.60 seconds\n",
      "Epoch [560/1000], Train Loss: 0.0000041487, Train MSE: 0.0000001338,             Test MSE: 0.0000000991, Time: 1.59 seconds\n",
      "Epoch [561/1000], Train Loss: 0.0000002160, Train MSE: 0.0000002222,             Test MSE: 0.0000001750, Time: 1.58 seconds\n",
      "Epoch [562/1000], Train Loss: 0.0000065770, Train MSE: 0.0000180873,             Test MSE: 0.0000138378, Time: 1.55 seconds\n",
      "Epoch [563/1000], Train Loss: 0.0000016306, Train MSE: 0.0000005715,             Test MSE: 0.0000004520, Time: 1.67 seconds\n",
      "Epoch [564/1000], Train Loss: 0.0000000657, Train MSE: 0.0000000025,             Test MSE: 0.0000000036, Time: 1.78 seconds\n",
      "Epoch [565/1000], Train Loss: 0.0000069808, Train MSE: 0.0000001173,             Test MSE: 0.0000000899, Time: 1.73 seconds\n",
      "Epoch [566/1000], Train Loss: 0.0000010968, Train MSE: 0.0000004002,             Test MSE: 0.0000002627, Time: 1.62 seconds\n",
      "Epoch [567/1000], Train Loss: 0.0000001094, Train MSE: 0.0000001009,             Test MSE: 0.0000000792, Time: 1.56 seconds\n",
      "Epoch [568/1000], Train Loss: 0.0000028714, Train MSE: 0.0000005466,             Test MSE: 0.0000003352, Time: 1.59 seconds\n",
      "Epoch [569/1000], Train Loss: 0.0000160230, Train MSE: 0.0000311177,             Test MSE: 0.0000241362, Time: 1.62 seconds\n",
      "Epoch [570/1000], Train Loss: 0.0000070637, Train MSE: 0.0000031662,             Test MSE: 0.0000026026, Time: 1.58 seconds\n",
      "Epoch [571/1000], Train Loss: 0.0000023308, Train MSE: 0.0000007479,             Test MSE: 0.0000006305, Time: 1.70 seconds\n",
      "Epoch [572/1000], Train Loss: 0.0000003049, Train MSE: 0.0000000110,             Test MSE: 0.0000000053, Time: 1.57 seconds\n",
      "Epoch [573/1000], Train Loss: 0.0000001287, Train MSE: 0.0000000557,             Test MSE: 0.0000000451, Time: 1.58 seconds\n",
      "Epoch [574/1000], Train Loss: 0.0000001367, Train MSE: 0.0000001637,             Test MSE: 0.0000001384, Time: 1.73 seconds\n",
      "Epoch [575/1000], Train Loss: 0.0000000805, Train MSE: 0.0000000008,             Test MSE: 0.0000000009, Time: 1.54 seconds\n",
      "Epoch [576/1000], Train Loss: 0.0000001612, Train MSE: 0.0000003899,             Test MSE: 0.0000003358, Time: 1.61 seconds\n",
      "Epoch [577/1000], Train Loss: 0.0000064916, Train MSE: 0.0000005843,             Test MSE: 0.0000003873, Time: 1.55 seconds\n",
      "Epoch [578/1000], Train Loss: 0.0000036833, Train MSE: 0.0000001712,             Test MSE: 0.0000001319, Time: 1.58 seconds\n",
      "Epoch [579/1000], Train Loss: 0.0000001635, Train MSE: 0.0000000019,             Test MSE: 0.0000000025, Time: 1.66 seconds\n",
      "Epoch [580/1000], Train Loss: 0.0000000328, Train MSE: 0.0000001915,             Test MSE: 0.0000001491, Time: 1.56 seconds\n",
      "Epoch [581/1000], Train Loss: 0.0000044844, Train MSE: 0.0000032494,             Test MSE: 0.0000025962, Time: 1.59 seconds\n",
      "Epoch [582/1000], Train Loss: 0.0000010062, Train MSE: 0.0000000159,             Test MSE: 0.0000000145, Time: 1.59 seconds\n",
      "Epoch [583/1000], Train Loss: 0.0000072599, Train MSE: 0.0000038290,             Test MSE: 0.0000038441, Time: 1.59 seconds\n",
      "Epoch [584/1000], Train Loss: 0.0000017605, Train MSE: 0.0000004916,             Test MSE: 0.0000004618, Time: 1.57 seconds\n",
      "Epoch [585/1000], Train Loss: 0.0000009804, Train MSE: 0.0000001868,             Test MSE: 0.0000001620, Time: 1.57 seconds\n",
      "Epoch [586/1000], Train Loss: 0.0000016798, Train MSE: 0.0000000229,             Test MSE: 0.0000000244, Time: 1.63 seconds\n",
      "Epoch [587/1000], Train Loss: 0.0000003675, Train MSE: 0.0000038506,             Test MSE: 0.0000032215, Time: 1.56 seconds\n",
      "Epoch [588/1000], Train Loss: 0.0000138196, Train MSE: 0.0000080561,             Test MSE: 0.0000085892, Time: 1.56 seconds\n",
      "Epoch [589/1000], Train Loss: 0.0000015513, Train MSE: 0.0000003185,             Test MSE: 0.0000002961, Time: 1.62 seconds\n",
      "Epoch [590/1000], Train Loss: 0.0000002101, Train MSE: 0.0000015205,             Test MSE: 0.0000013952, Time: 1.55 seconds\n",
      "Epoch [591/1000], Train Loss: 0.0000003712, Train MSE: 0.0000000501,             Test MSE: 0.0000000425, Time: 1.60 seconds\n",
      "Epoch [592/1000], Train Loss: 0.0000002007, Train MSE: 0.0000026258,             Test MSE: 0.0000024284, Time: 1.57 seconds\n",
      "Epoch [593/1000], Train Loss: 0.0000032835, Train MSE: 0.0000041636,             Test MSE: 0.0000040199, Time: 1.59 seconds\n",
      "Epoch [594/1000], Train Loss: 0.0000031079, Train MSE: 0.0000017077,             Test MSE: 0.0000015920, Time: 1.57 seconds\n",
      "Epoch [595/1000], Train Loss: 0.0000003921, Train MSE: 0.0000005116,             Test MSE: 0.0000004444, Time: 1.81 seconds\n",
      "Epoch [596/1000], Train Loss: 0.0000022563, Train MSE: 0.0000078359,             Test MSE: 0.0000074383, Time: 1.76 seconds\n",
      "Epoch [597/1000], Train Loss: 0.0000067074, Train MSE: 0.0000025723,             Test MSE: 0.0000024367, Time: 1.72 seconds\n",
      "Epoch [598/1000], Train Loss: 0.0000005851, Train MSE: 0.0000004355,             Test MSE: 0.0000004370, Time: 1.67 seconds\n",
      "Epoch [599/1000], Train Loss: 0.0000007312, Train MSE: 0.0000000429,             Test MSE: 0.0000000428, Time: 1.58 seconds\n",
      "Epoch [600/1000], Train Loss: 0.0000001574, Train MSE: 0.0000022110,             Test MSE: 0.0000021854, Time: 1.56 seconds\n",
      "Epoch [601/1000], Train Loss: 0.0000129723, Train MSE: 0.0000001419,             Test MSE: 0.0000001558, Time: 1.58 seconds\n",
      "Epoch [602/1000], Train Loss: 0.0000001529, Train MSE: 0.0000000204,             Test MSE: 0.0000000188, Time: 1.55 seconds\n",
      "Epoch [603/1000], Train Loss: 0.0000000581, Train MSE: 0.0000000145,             Test MSE: 0.0000000127, Time: 1.76 seconds\n",
      "Epoch [604/1000], Train Loss: 0.0000000212, Train MSE: 0.0000000017,             Test MSE: 0.0000000017, Time: 1.55 seconds\n",
      "Epoch [605/1000], Train Loss: 0.0000024602, Train MSE: 0.0000003349,             Test MSE: 0.0000003090, Time: 1.54 seconds\n",
      "Epoch [606/1000], Train Loss: 0.0000011062, Train MSE: 0.0000007220,             Test MSE: 0.0000006390, Time: 1.56 seconds\n",
      "Epoch [607/1000], Train Loss: 0.0000027518, Train MSE: 0.0000046271,             Test MSE: 0.0000041573, Time: 1.57 seconds\n",
      "Epoch [608/1000], Train Loss: 0.0000051457, Train MSE: 0.0000025687,             Test MSE: 0.0000023559, Time: 1.63 seconds\n",
      "Epoch [609/1000], Train Loss: 0.0000023979, Train MSE: 0.0000004538,             Test MSE: 0.0000004085, Time: 1.54 seconds\n",
      "Epoch [610/1000], Train Loss: 0.0000010756, Train MSE: 0.0000001337,             Test MSE: 0.0000001178, Time: 1.88 seconds\n",
      "Epoch [611/1000], Train Loss: 0.0000000420, Train MSE: 0.0000000466,             Test MSE: 0.0000000415, Time: 1.60 seconds\n",
      "Epoch [612/1000], Train Loss: 0.0000006769, Train MSE: 0.0000060963,             Test MSE: 0.0000051589, Time: 1.59 seconds\n",
      "Epoch [613/1000], Train Loss: 0.0000020664, Train MSE: 0.0000021808,             Test MSE: 0.0000017117, Time: 1.75 seconds\n",
      "Epoch [614/1000], Train Loss: 0.0000062022, Train MSE: 0.0000001407,             Test MSE: 0.0000001336, Time: 1.86 seconds\n",
      "Epoch [615/1000], Train Loss: 0.0000001040, Train MSE: 0.0000000076,             Test MSE: 0.0000000072, Time: 1.74 seconds\n",
      "Epoch [616/1000], Train Loss: 0.0000000343, Train MSE: 0.0000006826,             Test MSE: 0.0000005746, Time: 1.92 seconds\n",
      "Epoch [617/1000], Train Loss: 0.0000036657, Train MSE: 0.0000045596,             Test MSE: 0.0000033296, Time: 1.92 seconds\n",
      "Epoch [618/1000], Train Loss: 0.0000015127, Train MSE: 0.0000020111,             Test MSE: 0.0000013173, Time: 1.79 seconds\n",
      "Epoch [619/1000], Train Loss: 0.0000046479, Train MSE: 0.0000114190,             Test MSE: 0.0000080722, Time: 1.63 seconds\n",
      "Epoch [620/1000], Train Loss: 0.0000028617, Train MSE: 0.0000004225,             Test MSE: 0.0000003123, Time: 1.63 seconds\n",
      "Epoch [621/1000], Train Loss: 0.0000005256, Train MSE: 0.0000000267,             Test MSE: 0.0000000189, Time: 1.80 seconds\n",
      "Epoch [622/1000], Train Loss: 0.0000015432, Train MSE: 0.0000057458,             Test MSE: 0.0000038085, Time: 1.88 seconds\n",
      "Epoch [623/1000], Train Loss: 0.0000012672, Train MSE: 0.0000004787,             Test MSE: 0.0000003384, Time: 2.69 seconds\n",
      "Epoch [624/1000], Train Loss: 0.0000008007, Train MSE: 0.0000093316,             Test MSE: 0.0000051797, Time: 2.23 seconds\n",
      "Epoch [625/1000], Train Loss: 0.0000256727, Train MSE: 0.0000119136,             Test MSE: 0.0000130643, Time: 1.94 seconds\n",
      "Epoch [626/1000], Train Loss: 0.0000213370, Train MSE: 0.0000007746,             Test MSE: 0.0000008185, Time: 1.71 seconds\n",
      "Epoch [627/1000], Train Loss: 0.0000001086, Train MSE: 0.0000000126,             Test MSE: 0.0000000149, Time: 1.95 seconds\n",
      "Epoch [628/1000], Train Loss: 0.0000000326, Train MSE: 0.0000000198,             Test MSE: 0.0000000191, Time: 1.64 seconds\n",
      "Epoch [629/1000], Train Loss: 0.0000000240, Train MSE: 0.0000000017,             Test MSE: 0.0000000021, Time: 1.65 seconds\n",
      "Epoch [630/1000], Train Loss: 0.0000000183, Train MSE: 0.0000000065,             Test MSE: 0.0000000036, Time: 1.61 seconds\n",
      "Epoch [631/1000], Train Loss: 0.0000000148, Train MSE: 0.0000000232,             Test MSE: 0.0000000272, Time: 1.69 seconds\n",
      "Epoch [632/1000], Train Loss: 0.0000000115, Train MSE: 0.0000000782,             Test MSE: 0.0000000799, Time: 1.70 seconds\n",
      "Epoch [633/1000], Train Loss: 0.0000000208, Train MSE: 0.0000001355,             Test MSE: 0.0000001444, Time: 1.65 seconds\n",
      "Epoch [634/1000], Train Loss: 0.0000000134, Train MSE: 0.0000000093,             Test MSE: 0.0000000078, Time: 1.60 seconds\n",
      "Epoch [635/1000], Train Loss: 0.0000000090, Train MSE: 0.0000000842,             Test MSE: 0.0000000907, Time: 1.88 seconds\n",
      "Epoch [636/1000], Train Loss: 0.0000000481, Train MSE: 0.0000000398,             Test MSE: 0.0000000466, Time: 2.07 seconds\n",
      "Epoch [637/1000], Train Loss: 0.0000010576, Train MSE: 0.0000040700,             Test MSE: 0.0000038421, Time: 1.91 seconds\n",
      "Epoch [638/1000], Train Loss: 0.0000043072, Train MSE: 0.0000000620,             Test MSE: 0.0000000855, Time: 1.81 seconds\n",
      "Epoch [639/1000], Train Loss: 0.0000017318, Train MSE: 0.0000000232,             Test MSE: 0.0000000267, Time: 1.65 seconds\n",
      "Epoch [640/1000], Train Loss: 0.0000005559, Train MSE: 0.0000000916,             Test MSE: 0.0000000809, Time: 1.64 seconds\n",
      "Epoch [641/1000], Train Loss: 0.0000010473, Train MSE: 0.0000000364,             Test MSE: 0.0000000307, Time: 1.80 seconds\n",
      "Epoch [642/1000], Train Loss: 0.0000060986, Train MSE: 0.0000039148,             Test MSE: 0.0000026580, Time: 1.65 seconds\n",
      "Epoch [643/1000], Train Loss: 0.0000102969, Train MSE: 0.0000025376,             Test MSE: 0.0000019850, Time: 1.65 seconds\n",
      "Epoch [644/1000], Train Loss: 0.0000012560, Train MSE: 0.0000000016,             Test MSE: 0.0000000021, Time: 1.69 seconds\n",
      "Epoch [645/1000], Train Loss: 0.0000000473, Train MSE: 0.0000000689,             Test MSE: 0.0000000451, Time: 4.11 seconds\n",
      "Epoch [646/1000], Train Loss: 0.0000000210, Train MSE: 0.0000001080,             Test MSE: 0.0000000798, Time: 3.44 seconds\n",
      "Epoch [647/1000], Train Loss: 0.0000000113, Train MSE: 0.0000000134,             Test MSE: 0.0000000122, Time: 2.25 seconds\n",
      "Epoch [648/1000], Train Loss: 0.0000001536, Train MSE: 0.0000003141,             Test MSE: 0.0000002232, Time: 2.68 seconds\n",
      "Epoch [649/1000], Train Loss: 0.0000027311, Train MSE: 0.0000008706,             Test MSE: 0.0000006488, Time: 2.89 seconds\n",
      "Epoch [650/1000], Train Loss: 0.0000012036, Train MSE: 0.0000007366,             Test MSE: 0.0000005267, Time: 2.58 seconds\n",
      "Epoch [651/1000], Train Loss: 0.0000023678, Train MSE: 0.0000008863,             Test MSE: 0.0000005419, Time: 2.46 seconds\n",
      "Epoch [652/1000], Train Loss: 0.0000024804, Train MSE: 0.0000162753,             Test MSE: 0.0000087739, Time: 2.54 seconds\n",
      "Epoch [653/1000], Train Loss: 0.0000035470, Train MSE: 0.0000006019,             Test MSE: 0.0000003856, Time: 2.12 seconds\n",
      "Epoch [654/1000], Train Loss: 0.0000002861, Train MSE: 0.0000008562,             Test MSE: 0.0000005274, Time: 1.73 seconds\n",
      "Epoch [655/1000], Train Loss: 0.0000009150, Train MSE: 0.0000036152,             Test MSE: 0.0000020705, Time: 1.72 seconds\n",
      "Epoch [656/1000], Train Loss: 0.0000084655, Train MSE: 0.0000022763,             Test MSE: 0.0000012572, Time: 1.65 seconds\n",
      "Epoch [657/1000], Train Loss: 0.0000015159, Train MSE: 0.0000002440,             Test MSE: 0.0000001420, Time: 1.66 seconds\n",
      "Epoch [658/1000], Train Loss: 0.0000000680, Train MSE: 0.0000000215,             Test MSE: 0.0000000149, Time: 1.62 seconds\n",
      "Epoch [659/1000], Train Loss: 0.0000000365, Train MSE: 0.0000001164,             Test MSE: 0.0000000690, Time: 1.63 seconds\n",
      "Epoch [660/1000], Train Loss: 0.0000022222, Train MSE: 0.0000001599,             Test MSE: 0.0000002011, Time: 1.79 seconds\n",
      "Epoch [661/1000], Train Loss: 0.0000455935, Train MSE: 0.0000082034,             Test MSE: 0.0000044849, Time: 1.98 seconds\n",
      "Epoch [662/1000], Train Loss: 0.0000023584, Train MSE: 0.0000004362,             Test MSE: 0.0000003528, Time: 2.40 seconds\n",
      "Epoch [663/1000], Train Loss: 0.0000062843, Train MSE: 0.0000077246,             Test MSE: 0.0000042230, Time: 3.66 seconds\n",
      "Epoch [664/1000], Train Loss: 0.0000004495, Train MSE: 0.0000000060,             Test MSE: 0.0000000160, Time: 3.69 seconds\n",
      "Epoch [665/1000], Train Loss: 0.0000000132, Train MSE: 0.0000000707,             Test MSE: 0.0000000508, Time: 3.37 seconds\n",
      "Epoch [666/1000], Train Loss: 0.0000000269, Train MSE: 0.0000000152,             Test MSE: 0.0000000123, Time: 1.70 seconds\n",
      "Epoch [667/1000], Train Loss: 0.0000002690, Train MSE: 0.0000001514,             Test MSE: 0.0000000975, Time: 1.69 seconds\n",
      "Epoch [668/1000], Train Loss: 0.0000000331, Train MSE: 0.0000000024,             Test MSE: 0.0000000037, Time: 1.79 seconds\n",
      "Epoch [669/1000], Train Loss: 0.0000000172, Train MSE: 0.0000000073,             Test MSE: 0.0000000090, Time: 1.82 seconds\n",
      "Epoch [670/1000], Train Loss: 0.0000000217, Train MSE: 0.0000001361,             Test MSE: 0.0000000841, Time: 1.64 seconds\n",
      "Epoch [671/1000], Train Loss: 0.0000000709, Train MSE: 0.0000000218,             Test MSE: 0.0000000166, Time: 1.68 seconds\n",
      "Epoch [672/1000], Train Loss: 0.0000005620, Train MSE: 0.0000000558,             Test MSE: 0.0000000450, Time: 1.83 seconds\n",
      "Epoch [673/1000], Train Loss: 0.0000162689, Train MSE: 0.0000145456,             Test MSE: 0.0000102064, Time: 1.63 seconds\n",
      "Epoch [674/1000], Train Loss: 0.0000049116, Train MSE: 0.0000017098,             Test MSE: 0.0000009576, Time: 1.82 seconds\n",
      "Epoch [675/1000], Train Loss: 0.0000011440, Train MSE: 0.0000000044,             Test MSE: 0.0000000068, Time: 1.72 seconds\n",
      "Epoch [676/1000], Train Loss: 0.0000004002, Train MSE: 0.0000002220,             Test MSE: 0.0000001529, Time: 1.80 seconds\n",
      "Epoch [677/1000], Train Loss: 0.0000003456, Train MSE: 0.0000002986,             Test MSE: 0.0000001671, Time: 1.75 seconds\n",
      "Epoch [678/1000], Train Loss: 0.0000000672, Train MSE: 0.0000001068,             Test MSE: 0.0000000661, Time: 1.91 seconds\n",
      "Epoch [679/1000], Train Loss: 0.0000000592, Train MSE: 0.0000001713,             Test MSE: 0.0000000972, Time: 1.92 seconds\n",
      "Epoch [680/1000], Train Loss: 0.0000000831, Train MSE: 0.0000000404,             Test MSE: 0.0000000283, Time: 1.78 seconds\n",
      "Epoch [681/1000], Train Loss: 0.0000021982, Train MSE: 0.0000156887,             Test MSE: 0.0000107292, Time: 1.79 seconds\n",
      "Epoch [682/1000], Train Loss: 0.0000414965, Train MSE: 0.0000015281,             Test MSE: 0.0000004722, Time: 1.68 seconds\n",
      "Epoch [683/1000], Train Loss: 0.0000002427, Train MSE: 0.0000000457,             Test MSE: 0.0000000990, Time: 2.00 seconds\n",
      "Epoch [684/1000], Train Loss: 0.0000000135, Train MSE: 0.0000000061,             Test MSE: 0.0000000276, Time: 1.62 seconds\n",
      "Epoch [685/1000], Train Loss: 0.0000000113, Train MSE: 0.0000000076,             Test MSE: 0.0000000574, Time: 1.76 seconds\n",
      "Epoch [686/1000], Train Loss: 0.0000000112, Train MSE: 0.0000000103,             Test MSE: 0.0000000348, Time: 1.66 seconds\n",
      "Epoch [687/1000], Train Loss: 0.0000000351, Train MSE: 0.0000000060,             Test MSE: 0.0000000287, Time: 1.86 seconds\n",
      "Epoch [688/1000], Train Loss: 0.0000000226, Train MSE: 0.0000000301,             Test MSE: 0.0000000413, Time: 2.16 seconds\n",
      "Epoch [689/1000], Train Loss: 0.0000000123, Train MSE: 0.0000000011,             Test MSE: 0.0000000508, Time: 3.27 seconds\n",
      "Epoch [690/1000], Train Loss: 0.0000000282, Train MSE: 0.0000000939,             Test MSE: 0.0000000688, Time: 2.56 seconds\n",
      "Epoch [691/1000], Train Loss: 0.0000000408, Train MSE: 0.0000001196,             Test MSE: 0.0000000652, Time: 1.90 seconds\n",
      "Epoch [692/1000], Train Loss: 0.0000001205, Train MSE: 0.0000002822,             Test MSE: 0.0000001828, Time: 2.51 seconds\n",
      "Epoch [693/1000], Train Loss: 0.0000006088, Train MSE: 0.0000000075,             Test MSE: 0.0000000148, Time: 2.27 seconds\n",
      "Epoch [694/1000], Train Loss: 0.0000056785, Train MSE: 0.0000016747,             Test MSE: 0.0000006717, Time: 2.11 seconds\n",
      "Epoch [695/1000], Train Loss: 0.0000002396, Train MSE: 0.0000000790,             Test MSE: 0.0000000588, Time: 1.82 seconds\n",
      "Epoch [696/1000], Train Loss: 0.0000002176, Train MSE: 0.0000000045,             Test MSE: 0.0000000333, Time: 1.79 seconds\n",
      "Epoch [697/1000], Train Loss: 0.0000001874, Train MSE: 0.0000002486,             Test MSE: 0.0000001982, Time: 1.96 seconds\n",
      "Epoch [698/1000], Train Loss: 0.0000005105, Train MSE: 0.0000003741,             Test MSE: 0.0000003329, Time: 1.94 seconds\n",
      "Epoch [699/1000], Train Loss: 0.0000360061, Train MSE: 0.0000021448,             Test MSE: 0.0000007361, Time: 1.80 seconds\n",
      "Epoch [700/1000], Train Loss: 0.0000026555, Train MSE: 0.0000003376,             Test MSE: 0.0000002280, Time: 2.05 seconds\n",
      "Epoch [701/1000], Train Loss: 0.0000008468, Train MSE: 0.0000001001,             Test MSE: 0.0000001016, Time: 1.69 seconds\n",
      "Epoch [702/1000], Train Loss: 0.0000000206, Train MSE: 0.0000001227,             Test MSE: 0.0000001081, Time: 1.88 seconds\n",
      "Epoch [703/1000], Train Loss: 0.0000000280, Train MSE: 0.0000000016,             Test MSE: 0.0000000282, Time: 1.77 seconds\n",
      "Epoch [704/1000], Train Loss: 0.0000000186, Train MSE: 0.0000000139,             Test MSE: 0.0000000119, Time: 2.03 seconds\n",
      "Epoch [705/1000], Train Loss: 0.0000000064, Train MSE: 0.0000000008,             Test MSE: 0.0000000169, Time: 1.86 seconds\n",
      "Epoch [706/1000], Train Loss: 0.0000000026, Train MSE: 0.0000000030,             Test MSE: 0.0000000258, Time: 1.89 seconds\n",
      "Epoch [707/1000], Train Loss: 0.0000000019, Train MSE: 0.0000000012,             Test MSE: 0.0000000182, Time: 1.76 seconds\n",
      "Epoch [708/1000], Train Loss: 0.0000000109, Train MSE: 0.0000000592,             Test MSE: 0.0000000589, Time: 2.06 seconds\n",
      "Epoch [709/1000], Train Loss: 0.0000000134, Train MSE: 0.0000000300,             Test MSE: 0.0000000237, Time: 1.83 seconds\n",
      "Epoch [710/1000], Train Loss: 0.0000000809, Train MSE: 0.0000000457,             Test MSE: 0.0000000691, Time: 1.80 seconds\n",
      "Epoch [711/1000], Train Loss: 0.0000076790, Train MSE: 0.0000036798,             Test MSE: 0.0000026406, Time: 1.65 seconds\n",
      "Epoch [712/1000], Train Loss: 0.0000046038, Train MSE: 0.0000003986,             Test MSE: 0.0000002500, Time: 1.69 seconds\n",
      "Epoch [713/1000], Train Loss: 0.0000320829, Train MSE: 0.0000018443,             Test MSE: 0.0000017334, Time: 1.88 seconds\n",
      "Epoch [714/1000], Train Loss: 0.0000014989, Train MSE: 0.0000016260,             Test MSE: 0.0000010085, Time: 1.65 seconds\n",
      "Epoch [715/1000], Train Loss: 0.0000017106, Train MSE: 0.0000001116,             Test MSE: 0.0000000407, Time: 1.91 seconds\n",
      "Epoch [716/1000], Train Loss: 0.0000000428, Train MSE: 0.0000000824,             Test MSE: 0.0000000466, Time: 1.70 seconds\n",
      "Epoch [717/1000], Train Loss: 0.0000000573, Train MSE: 0.0000000033,             Test MSE: 0.0000000241, Time: 2.15 seconds\n",
      "Epoch [718/1000], Train Loss: 0.0000000555, Train MSE: 0.0000000375,             Test MSE: 0.0000000840, Time: 1.79 seconds\n",
      "Epoch [719/1000], Train Loss: 0.0000000283, Train MSE: 0.0000001556,             Test MSE: 0.0000002140, Time: 1.95 seconds\n",
      "Epoch [720/1000], Train Loss: 0.0000000524, Train MSE: 0.0000000195,             Test MSE: 0.0000000362, Time: 1.82 seconds\n",
      "Epoch [721/1000], Train Loss: 0.0000001250, Train MSE: 0.0000003250,             Test MSE: 0.0000001993, Time: 1.68 seconds\n",
      "Epoch [722/1000], Train Loss: 0.0000002320, Train MSE: 0.0000001238,             Test MSE: 0.0000000776, Time: 1.70 seconds\n",
      "Epoch [723/1000], Train Loss: 0.0000012880, Train MSE: 0.0000039794,             Test MSE: 0.0000027425, Time: 1.78 seconds\n",
      "Epoch [724/1000], Train Loss: 0.0000012176, Train MSE: 0.0000007464,             Test MSE: 0.0000003804, Time: 2.03 seconds\n",
      "Epoch [725/1000], Train Loss: 0.0000032764, Train MSE: 0.0000000545,             Test MSE: 0.0000000924, Time: 1.86 seconds\n",
      "Epoch [726/1000], Train Loss: 0.0000020643, Train MSE: 0.0000007854,             Test MSE: 0.0000005818, Time: 1.77 seconds\n",
      "Epoch [727/1000], Train Loss: 0.0000017538, Train MSE: 0.0000000147,             Test MSE: 0.0000000801, Time: 1.72 seconds\n",
      "Epoch [728/1000], Train Loss: 0.0000002046, Train MSE: 0.0000000032,             Test MSE: 0.0000000049, Time: 2.12 seconds\n",
      "Epoch [729/1000], Train Loss: 0.0000112292, Train MSE: 0.0000165933,             Test MSE: 0.0000099474, Time: 1.91 seconds\n",
      "Epoch [730/1000], Train Loss: 0.0000035446, Train MSE: 0.0000000472,             Test MSE: 0.0000000418, Time: 1.96 seconds\n",
      "Epoch [731/1000], Train Loss: 0.0000000584, Train MSE: 0.0000002771,             Test MSE: 0.0000001695, Time: 1.73 seconds\n",
      "Epoch [732/1000], Train Loss: 0.0000000270, Train MSE: 0.0000000785,             Test MSE: 0.0000000542, Time: 2.17 seconds\n",
      "Epoch [733/1000], Train Loss: 0.0000000621, Train MSE: 0.0000001074,             Test MSE: 0.0000000563, Time: 1.90 seconds\n",
      "Epoch [734/1000], Train Loss: 0.0000002498, Train MSE: 0.0000000027,             Test MSE: 0.0000000049, Time: 2.01 seconds\n",
      "Epoch [735/1000], Train Loss: 0.0000008222, Train MSE: 0.0000002812,             Test MSE: 0.0000002097, Time: 1.76 seconds\n",
      "Epoch [736/1000], Train Loss: 0.0000015134, Train MSE: 0.0000002164,             Test MSE: 0.0000002194, Time: 2.03 seconds\n",
      "Epoch [737/1000], Train Loss: 0.0000012759, Train MSE: 0.0000006193,             Test MSE: 0.0000005876, Time: 1.80 seconds\n",
      "Epoch [738/1000], Train Loss: 0.0000030143, Train MSE: 0.0000000507,             Test MSE: 0.0000000953, Time: 1.70 seconds\n",
      "Epoch [739/1000], Train Loss: 0.0000005278, Train MSE: 0.0000003680,             Test MSE: 0.0000002652, Time: 1.86 seconds\n",
      "Epoch [740/1000], Train Loss: 0.0000037146, Train MSE: 0.0000185391,             Test MSE: 0.0000115799, Time: 1.78 seconds\n",
      "Epoch [741/1000], Train Loss: 0.0000040028, Train MSE: 0.0000005668,             Test MSE: 0.0000003695, Time: 1.73 seconds\n",
      "Epoch [742/1000], Train Loss: 0.0000009935, Train MSE: 0.0000000923,             Test MSE: 0.0000000784, Time: 1.79 seconds\n",
      "Epoch [743/1000], Train Loss: 0.0000006190, Train MSE: 0.0000001783,             Test MSE: 0.0000001847, Time: 2.10 seconds\n",
      "Epoch [744/1000], Train Loss: 0.0000025644, Train MSE: 0.0000046570,             Test MSE: 0.0000031572, Time: 1.78 seconds\n",
      "Epoch [745/1000], Train Loss: 0.0000128897, Train MSE: 0.0000999227,             Test MSE: 0.0000762842, Time: 1.84 seconds\n",
      "Epoch [746/1000], Train Loss: 0.0000040198, Train MSE: 0.0000000414,             Test MSE: 0.0000000655, Time: 1.71 seconds\n",
      "Epoch [747/1000], Train Loss: 0.0000002580, Train MSE: 0.0000004258,             Test MSE: 0.0000003504, Time: 1.81 seconds\n",
      "Epoch [748/1000], Train Loss: 0.0000000663, Train MSE: 0.0000000136,             Test MSE: 0.0000000106, Time: 1.78 seconds\n",
      "Epoch [749/1000], Train Loss: 0.0000000378, Train MSE: 0.0000003669,             Test MSE: 0.0000002872, Time: 1.71 seconds\n",
      "Epoch [750/1000], Train Loss: 0.0000000295, Train MSE: 0.0000000121,             Test MSE: 0.0000000097, Time: 1.97 seconds\n",
      "Epoch [751/1000], Train Loss: 0.0000000639, Train MSE: 0.0000005084,             Test MSE: 0.0000003560, Time: 1.90 seconds\n",
      "Epoch [752/1000], Train Loss: 0.0000001788, Train MSE: 0.0000005817,             Test MSE: 0.0000004600, Time: 2.07 seconds\n",
      "Epoch [753/1000], Train Loss: 0.0000026131, Train MSE: 0.0000070956,             Test MSE: 0.0000054270, Time: 1.89 seconds\n",
      "Epoch [754/1000], Train Loss: 0.0000036631, Train MSE: 0.0000002953,             Test MSE: 0.0000002609, Time: 2.05 seconds\n",
      "Epoch [755/1000], Train Loss: 0.0000001427, Train MSE: 0.0000000798,             Test MSE: 0.0000000655, Time: 2.20 seconds\n",
      "Epoch [756/1000], Train Loss: 0.0000000786, Train MSE: 0.0000000314,             Test MSE: 0.0000000333, Time: 2.31 seconds\n",
      "Epoch [757/1000], Train Loss: 0.0000012309, Train MSE: 0.0000028539,             Test MSE: 0.0000023130, Time: 2.05 seconds\n",
      "Epoch [758/1000], Train Loss: 0.0000009170, Train MSE: 0.0000095040,             Test MSE: 0.0000074934, Time: 2.02 seconds\n",
      "Epoch [759/1000], Train Loss: 0.0000075415, Train MSE: 0.0000001455,             Test MSE: 0.0000001565, Time: 2.01 seconds\n",
      "Epoch [760/1000], Train Loss: 0.0000025608, Train MSE: 0.0000002595,             Test MSE: 0.0000001978, Time: 2.31 seconds\n",
      "Epoch [761/1000], Train Loss: 0.0000006853, Train MSE: 0.0000000645,             Test MSE: 0.0000000736, Time: 1.98 seconds\n",
      "Epoch [762/1000], Train Loss: 0.0000003601, Train MSE: 0.0000000399,             Test MSE: 0.0000000441, Time: 2.09 seconds\n",
      "Epoch [763/1000], Train Loss: 0.0000001136, Train MSE: 0.0000000122,             Test MSE: 0.0000000140, Time: 1.98 seconds\n",
      "Epoch [764/1000], Train Loss: 0.0000011022, Train MSE: 0.0000023044,             Test MSE: 0.0000019570, Time: 2.05 seconds\n",
      "Epoch [765/1000], Train Loss: 0.0000011386, Train MSE: 0.0000000762,             Test MSE: 0.0000000648, Time: 1.99 seconds\n",
      "Epoch [766/1000], Train Loss: 0.0000023655, Train MSE: 0.0000001076,             Test MSE: 0.0000001204, Time: 2.06 seconds\n",
      "Epoch [767/1000], Train Loss: 0.0000002047, Train MSE: 0.0000001074,             Test MSE: 0.0000001040, Time: 1.99 seconds\n",
      "Epoch [768/1000], Train Loss: 0.0000021655, Train MSE: 0.0000104864,             Test MSE: 0.0000109237, Time: 2.10 seconds\n",
      "Epoch [769/1000], Train Loss: 0.0000195645, Train MSE: 0.0000019038,             Test MSE: 0.0000027135, Time: 1.92 seconds\n",
      "Epoch [770/1000], Train Loss: 0.0000001240, Train MSE: 0.0000000016,             Test MSE: 0.0000000056, Time: 1.95 seconds\n",
      "Epoch [771/1000], Train Loss: 0.0000000151, Train MSE: 0.0000000015,             Test MSE: 0.0000000023, Time: 1.92 seconds\n",
      "Epoch [772/1000], Train Loss: 0.0000000056, Train MSE: 0.0000000015,             Test MSE: 0.0000000026, Time: 1.88 seconds\n",
      "Epoch [773/1000], Train Loss: 0.0000000104, Train MSE: 0.0000000028,             Test MSE: 0.0000000045, Time: 2.00 seconds\n",
      "Epoch [774/1000], Train Loss: 0.0000000215, Train MSE: 0.0000000252,             Test MSE: 0.0000000397, Time: 1.80 seconds\n",
      "Epoch [775/1000], Train Loss: 0.0000000099, Train MSE: 0.0000000031,             Test MSE: 0.0000000054, Time: 1.97 seconds\n",
      "Epoch [776/1000], Train Loss: 0.0000000826, Train MSE: 0.0000000230,             Test MSE: 0.0000000300, Time: 1.78 seconds\n",
      "Epoch [777/1000], Train Loss: 0.0000025565, Train MSE: 0.0000046405,             Test MSE: 0.0000065654, Time: 1.77 seconds\n",
      "Epoch [778/1000], Train Loss: 0.0000023851, Train MSE: 0.0000002395,             Test MSE: 0.0000003158, Time: 1.73 seconds\n",
      "Epoch [779/1000], Train Loss: 0.0000001077, Train MSE: 0.0000008759,             Test MSE: 0.0000012113, Time: 2.32 seconds\n",
      "Epoch [780/1000], Train Loss: 0.0000011587, Train MSE: 0.0000048966,             Test MSE: 0.0000068491, Time: 1.88 seconds\n",
      "Epoch [781/1000], Train Loss: 0.0000072572, Train MSE: 0.0000104220,             Test MSE: 0.0000140363, Time: 1.98 seconds\n",
      "Epoch [782/1000], Train Loss: 0.0000014659, Train MSE: 0.0000002416,             Test MSE: 0.0000003138, Time: 1.74 seconds\n",
      "Epoch [783/1000], Train Loss: 0.0000001890, Train MSE: 0.0000000609,             Test MSE: 0.0000000731, Time: 1.72 seconds\n",
      "Epoch [784/1000], Train Loss: 0.0000000416, Train MSE: 0.0000000040,             Test MSE: 0.0000000043, Time: 1.73 seconds\n",
      "Epoch [785/1000], Train Loss: 0.0000000844, Train MSE: 0.0000000201,             Test MSE: 0.0000000249, Time: 1.71 seconds\n",
      "Epoch [786/1000], Train Loss: 0.0000000681, Train MSE: 0.0000000103,             Test MSE: 0.0000000120, Time: 2.02 seconds\n",
      "Epoch [787/1000], Train Loss: 0.0000001662, Train MSE: 0.0000000221,             Test MSE: 0.0000000349, Time: 1.84 seconds\n",
      "Epoch [788/1000], Train Loss: 0.0000010001, Train MSE: 0.0000002047,             Test MSE: 0.0000002713, Time: 1.91 seconds\n",
      "Epoch [789/1000], Train Loss: 0.0000014893, Train MSE: 0.0000002458,             Test MSE: 0.0000003039, Time: 1.89 seconds\n",
      "Epoch [790/1000], Train Loss: 0.0000022063, Train MSE: 0.0000003857,             Test MSE: 0.0000004814, Time: 1.99 seconds\n",
      "Epoch [791/1000], Train Loss: 0.0000000891, Train MSE: 0.0000001635,             Test MSE: 0.0000001986, Time: 2.83 seconds\n",
      "Epoch [792/1000], Train Loss: 0.0000003992, Train MSE: 0.0000003250,             Test MSE: 0.0000003582, Time: 2.24 seconds\n",
      "Epoch [793/1000], Train Loss: 0.0000037025, Train MSE: 0.0000081290,             Test MSE: 0.0000129082, Time: 2.37 seconds\n",
      "Epoch [794/1000], Train Loss: 0.0000020999, Train MSE: 0.0000000081,             Test MSE: 0.0000000138, Time: 2.91 seconds\n",
      "Epoch [795/1000], Train Loss: 0.0000000063, Train MSE: 0.0000000089,             Test MSE: 0.0000000203, Time: 2.07 seconds\n",
      "Epoch [796/1000], Train Loss: 0.0000000133, Train MSE: 0.0000000020,             Test MSE: 0.0000000014, Time: 2.59 seconds\n",
      "Epoch [797/1000], Train Loss: 0.0000000481, Train MSE: 0.0000001245,             Test MSE: 0.0000002110, Time: 1.93 seconds\n",
      "Epoch [798/1000], Train Loss: 0.0000025688, Train MSE: 0.0000001630,             Test MSE: 0.0000001597, Time: 2.20 seconds\n",
      "Epoch [799/1000], Train Loss: 0.0000005740, Train MSE: 0.0000000411,             Test MSE: 0.0000000509, Time: 1.88 seconds\n",
      "Epoch [800/1000], Train Loss: 0.0000001341, Train MSE: 0.0000003488,             Test MSE: 0.0000005577, Time: 2.07 seconds\n",
      "Epoch [801/1000], Train Loss: 0.0000021378, Train MSE: 0.0000001953,             Test MSE: 0.0000002989, Time: 1.82 seconds\n",
      "Epoch [802/1000], Train Loss: 0.0000000461, Train MSE: 0.0000000012,             Test MSE: 0.0000000019, Time: 1.84 seconds\n",
      "Epoch [803/1000], Train Loss: 0.0000018461, Train MSE: 0.0000000018,             Test MSE: 0.0000000020, Time: 1.74 seconds\n",
      "Epoch [804/1000], Train Loss: 0.0000014218, Train MSE: 0.0000000861,             Test MSE: 0.0000000804, Time: 1.79 seconds\n",
      "Epoch [805/1000], Train Loss: 0.0000003853, Train MSE: 0.0000005323,             Test MSE: 0.0000008441, Time: 1.90 seconds\n",
      "Epoch [806/1000], Train Loss: 0.0000011605, Train MSE: 0.0000001605,             Test MSE: 0.0000002286, Time: 1.88 seconds\n",
      "Epoch [807/1000], Train Loss: 0.0000020114, Train MSE: 0.0000000060,             Test MSE: 0.0000000078, Time: 1.96 seconds\n",
      "Epoch [808/1000], Train Loss: 0.0000010095, Train MSE: 0.0000019933,             Test MSE: 0.0000030048, Time: 1.80 seconds\n",
      "Epoch [809/1000], Train Loss: 0.0000004789, Train MSE: 0.0000017584,             Test MSE: 0.0000029565, Time: 1.95 seconds\n",
      "Epoch [810/1000], Train Loss: 0.0000014441, Train MSE: 0.0000006065,             Test MSE: 0.0000008955, Time: 2.12 seconds\n",
      "Epoch [811/1000], Train Loss: 0.0000020188, Train MSE: 0.0000000084,             Test MSE: 0.0000000154, Time: 2.16 seconds\n",
      "Epoch [812/1000], Train Loss: 0.0000002810, Train MSE: 0.0000006529,             Test MSE: 0.0000010122, Time: 1.73 seconds\n",
      "Epoch [813/1000], Train Loss: 0.0000019413, Train MSE: 0.0000008420,             Test MSE: 0.0000011502, Time: 1.94 seconds\n",
      "Epoch [814/1000], Train Loss: 0.0000004662, Train MSE: 0.0000002463,             Test MSE: 0.0000004010, Time: 1.77 seconds\n",
      "Epoch [815/1000], Train Loss: 0.0000010645, Train MSE: 0.0000041500,             Test MSE: 0.0000060636, Time: 2.11 seconds\n",
      "Epoch [816/1000], Train Loss: 0.0000013514, Train MSE: 0.0000030272,             Test MSE: 0.0000044803, Time: 2.00 seconds\n",
      "Epoch [817/1000], Train Loss: 0.0000012893, Train MSE: 0.0000002916,             Test MSE: 0.0000004200, Time: 2.15 seconds\n",
      "Epoch [818/1000], Train Loss: 0.0000006610, Train MSE: 0.0000002884,             Test MSE: 0.0000004033, Time: 2.31 seconds\n",
      "Epoch [819/1000], Train Loss: 0.0000019108, Train MSE: 0.0000000805,             Test MSE: 0.0000001189, Time: 2.10 seconds\n",
      "Epoch [820/1000], Train Loss: 0.0000011736, Train MSE: 0.0000011125,             Test MSE: 0.0000017695, Time: 2.00 seconds\n",
      "Epoch [821/1000], Train Loss: 0.0000014973, Train MSE: 0.0000014269,             Test MSE: 0.0000020149, Time: 1.86 seconds\n",
      "Epoch [822/1000], Train Loss: 0.0000000794, Train MSE: 0.0000000832,             Test MSE: 0.0000001252, Time: 1.95 seconds\n",
      "Epoch [823/1000], Train Loss: 0.0000022263, Train MSE: 0.0000000003,             Test MSE: 0.0000000012, Time: 1.65 seconds\n",
      "Epoch [824/1000], Train Loss: 0.0000000540, Train MSE: 0.0000019683,             Test MSE: 0.0000028688, Time: 1.79 seconds\n",
      "Epoch [825/1000], Train Loss: 0.0000029799, Train MSE: 0.0000000010,             Test MSE: 0.0000000028, Time: 1.82 seconds\n",
      "Epoch [826/1000], Train Loss: 0.0000000163, Train MSE: 0.0000000157,             Test MSE: 0.0000000204, Time: 1.59 seconds\n",
      "Epoch [827/1000], Train Loss: 0.0000012528, Train MSE: 0.0000002215,             Test MSE: 0.0000003437, Time: 1.79 seconds\n",
      "Epoch [828/1000], Train Loss: 0.0000013653, Train MSE: 0.0000015153,             Test MSE: 0.0000019444, Time: 1.65 seconds\n",
      "Epoch [829/1000], Train Loss: 0.0000007412, Train MSE: 0.0000006065,             Test MSE: 0.0000008234, Time: 1.65 seconds\n",
      "Epoch [830/1000], Train Loss: 0.0000015915, Train MSE: 0.0000017029,             Test MSE: 0.0000023003, Time: 1.75 seconds\n",
      "Epoch [831/1000], Train Loss: 0.0000012317, Train MSE: 0.0000014310,             Test MSE: 0.0000022915, Time: 1.67 seconds\n",
      "Epoch [832/1000], Train Loss: 0.0000012567, Train MSE: 0.0000004131,             Test MSE: 0.0000006053, Time: 1.75 seconds\n",
      "Epoch [833/1000], Train Loss: 0.0000006728, Train MSE: 0.0000083267,             Test MSE: 0.0000120355, Time: 2.15 seconds\n",
      "Epoch [834/1000], Train Loss: 0.0000007557, Train MSE: 0.0000000375,             Test MSE: 0.0000000401, Time: 1.75 seconds\n",
      "Epoch [835/1000], Train Loss: 0.0000022273, Train MSE: 0.0000000649,             Test MSE: 0.0000001137, Time: 1.88 seconds\n",
      "Epoch [836/1000], Train Loss: 0.0000002489, Train MSE: 0.0000051758,             Test MSE: 0.0000074017, Time: 2.01 seconds\n",
      "Epoch [837/1000], Train Loss: 0.0000013291, Train MSE: 0.0000000528,             Test MSE: 0.0000000651, Time: 1.70 seconds\n",
      "Epoch [838/1000], Train Loss: 0.0000014815, Train MSE: 0.0000000925,             Test MSE: 0.0000001153, Time: 1.91 seconds\n",
      "Epoch [839/1000], Train Loss: 0.0000024144, Train MSE: 0.0000008496,             Test MSE: 0.0000014478, Time: 3.44 seconds\n",
      "Epoch [840/1000], Train Loss: 0.0000001882, Train MSE: 0.0000000023,             Test MSE: 0.0000000048, Time: 2.96 seconds\n",
      "Epoch [841/1000], Train Loss: 0.0000010914, Train MSE: 0.0000034977,             Test MSE: 0.0000045209, Time: 3.06 seconds\n",
      "Epoch [842/1000], Train Loss: 0.0000002760, Train MSE: 0.0000033493,             Test MSE: 0.0000047844, Time: 8.23 seconds\n",
      "Epoch [843/1000], Train Loss: 0.0000029553, Train MSE: 0.0000000133,             Test MSE: 0.0000000213, Time: 4.85 seconds\n",
      "Epoch [844/1000], Train Loss: 0.0000000016, Train MSE: 0.0000000000,             Test MSE: 0.0000000001, Time: 3.14 seconds\n",
      "Epoch [845/1000], Train Loss: 0.0000021750, Train MSE: 0.0000000009,             Test MSE: 0.0000000035, Time: 2.40 seconds\n",
      "Epoch [846/1000], Train Loss: 0.0000000444, Train MSE: 0.0000001090,             Test MSE: 0.0000001449, Time: 2.41 seconds\n",
      "Epoch [847/1000], Train Loss: 0.0000010533, Train MSE: 0.0000011427,             Test MSE: 0.0000014851, Time: 2.10 seconds\n",
      "Epoch [848/1000], Train Loss: 0.0000013772, Train MSE: 0.0000000061,             Test MSE: 0.0000000084, Time: 1.73 seconds\n",
      "Epoch [849/1000], Train Loss: 0.0000017451, Train MSE: 0.0000004322,             Test MSE: 0.0000006688, Time: 1.95 seconds\n",
      "Epoch [850/1000], Train Loss: 0.0000000618, Train MSE: 0.0000000006,             Test MSE: 0.0000000007, Time: 1.82 seconds\n",
      "Epoch [851/1000], Train Loss: 0.0000039757, Train MSE: 0.0000000069,             Test MSE: 0.0000000121, Time: 1.92 seconds\n",
      "Epoch [852/1000], Train Loss: 0.0000000085, Train MSE: 0.0000000014,             Test MSE: 0.0000000038, Time: 1.81 seconds\n",
      "Epoch [853/1000], Train Loss: 0.0000000021, Train MSE: 0.0000000226,             Test MSE: 0.0000000336, Time: 1.88 seconds\n",
      "Epoch [854/1000], Train Loss: 0.0000013695, Train MSE: 0.0000000383,             Test MSE: 0.0000000573, Time: 2.10 seconds\n",
      "Epoch [855/1000], Train Loss: 0.0000019662, Train MSE: 0.0000000236,             Test MSE: 0.0000001091, Time: 2.07 seconds\n",
      "Epoch [856/1000], Train Loss: 0.0000000609, Train MSE: 0.0000000609,             Test MSE: 0.0000000819, Time: 2.81 seconds\n",
      "Epoch [857/1000], Train Loss: 0.0000013925, Train MSE: 0.0000000050,             Test MSE: 0.0000000085, Time: 3.50 seconds\n",
      "Epoch [858/1000], Train Loss: 0.0000010855, Train MSE: 0.0000000334,             Test MSE: 0.0000000387, Time: 2.23 seconds\n",
      "Epoch [859/1000], Train Loss: 0.0000010517, Train MSE: 0.0000002019,             Test MSE: 0.0000002457, Time: 1.81 seconds\n",
      "Epoch [860/1000], Train Loss: 0.0000013554, Train MSE: 0.0000000425,             Test MSE: 0.0000000426, Time: 1.74 seconds\n",
      "Epoch [861/1000], Train Loss: 0.0000011547, Train MSE: 0.0000000704,             Test MSE: 0.0000000910, Time: 1.66 seconds\n",
      "Epoch [862/1000], Train Loss: 0.0000032982, Train MSE: 0.0000004625,             Test MSE: 0.0000004999, Time: 1.77 seconds\n",
      "Epoch [863/1000], Train Loss: 0.0000000871, Train MSE: 0.0000000018,             Test MSE: 0.0000000017, Time: 1.74 seconds\n",
      "Epoch [864/1000], Train Loss: 0.0000000064, Train MSE: 0.0000000049,             Test MSE: 0.0000000062, Time: 1.71 seconds\n",
      "Epoch [865/1000], Train Loss: 0.0000018041, Train MSE: 0.0000000096,             Test MSE: 0.0000000110, Time: 1.80 seconds\n",
      "Epoch [866/1000], Train Loss: 0.0000012628, Train MSE: 0.0000049729,             Test MSE: 0.0000062734, Time: 1.67 seconds\n",
      "Epoch [867/1000], Train Loss: 0.0000003818, Train MSE: 0.0000000887,             Test MSE: 0.0000001034, Time: 1.88 seconds\n",
      "Epoch [868/1000], Train Loss: 0.0000014248, Train MSE: 0.0000000403,             Test MSE: 0.0000000585, Time: 1.79 seconds\n",
      "Epoch [869/1000], Train Loss: 0.0000008304, Train MSE: 0.0000005157,             Test MSE: 0.0000006341, Time: 1.64 seconds\n",
      "Epoch [870/1000], Train Loss: 0.0000012796, Train MSE: 0.0000014444,             Test MSE: 0.0000017400, Time: 1.80 seconds\n",
      "Epoch [871/1000], Train Loss: 0.0000008900, Train MSE: 0.0000003285,             Test MSE: 0.0000004013, Time: 1.71 seconds\n",
      "Epoch [872/1000], Train Loss: 0.0000012318, Train MSE: 0.0000000588,             Test MSE: 0.0000000769, Time: 1.81 seconds\n",
      "Epoch [873/1000], Train Loss: 0.0000015028, Train MSE: 0.0000024505,             Test MSE: 0.0000031911, Time: 1.74 seconds\n",
      "Epoch [874/1000], Train Loss: 0.0000009684, Train MSE: 0.0000103680,             Test MSE: 0.0000130494, Time: 1.78 seconds\n",
      "Epoch [875/1000], Train Loss: 0.0000007253, Train MSE: 0.0000000409,             Test MSE: 0.0000000464, Time: 1.65 seconds\n",
      "Epoch [876/1000], Train Loss: 0.0000014816, Train MSE: 0.0000000374,             Test MSE: 0.0000000431, Time: 1.79 seconds\n",
      "Epoch [877/1000], Train Loss: 0.0000011519, Train MSE: 0.0000001597,             Test MSE: 0.0000001993, Time: 1.62 seconds\n",
      "Epoch [878/1000], Train Loss: 0.0000009754, Train MSE: 0.0000001440,             Test MSE: 0.0000002052, Time: 1.86 seconds\n",
      "Epoch [879/1000], Train Loss: 0.0000016862, Train MSE: 0.0000000211,             Test MSE: 0.0000000237, Time: 1.72 seconds\n",
      "Epoch [880/1000], Train Loss: 0.0000012727, Train MSE: 0.0000000734,             Test MSE: 0.0000013318, Time: 1.75 seconds\n",
      "Epoch [881/1000], Train Loss: 0.0000005604, Train MSE: 0.0000000148,             Test MSE: 0.0000000181, Time: 1.82 seconds\n",
      "Epoch [882/1000], Train Loss: 0.0000025816, Train MSE: 0.0000000001,             Test MSE: 0.0000000076, Time: 1.80 seconds\n",
      "Epoch [883/1000], Train Loss: 0.0000000611, Train MSE: 0.0000000118,             Test MSE: 0.0000000151, Time: 1.71 seconds\n",
      "Epoch [884/1000], Train Loss: 0.0000017392, Train MSE: 0.0000060809,             Test MSE: 0.0000075639, Time: 1.68 seconds\n",
      "Epoch [885/1000], Train Loss: 0.0000004836, Train MSE: 0.0000000355,             Test MSE: 0.0000000433, Time: 1.65 seconds\n",
      "Epoch [886/1000], Train Loss: 0.0000013866, Train MSE: 0.0000011279,             Test MSE: 0.0000013531, Time: 1.86 seconds\n",
      "Epoch [887/1000], Train Loss: 0.0000002236, Train MSE: 0.0000024856,             Test MSE: 0.0000030549, Time: 1.76 seconds\n",
      "Epoch [888/1000], Train Loss: 0.0000012643, Train MSE: 0.0000002548,             Test MSE: 0.0000003191, Time: 1.92 seconds\n",
      "Epoch [889/1000], Train Loss: 0.0000012627, Train MSE: 0.0000000787,             Test MSE: 0.0000001098, Time: 1.66 seconds\n",
      "Epoch [890/1000], Train Loss: 0.0000016694, Train MSE: 0.0000001231,             Test MSE: 0.0000001354, Time: 1.70 seconds\n",
      "Epoch [891/1000], Train Loss: 0.0000007080, Train MSE: 0.0000131898,             Test MSE: 0.0000161757, Time: 1.79 seconds\n",
      "Epoch [892/1000], Train Loss: 0.0000009517, Train MSE: 0.0000000111,             Test MSE: 0.0000000132, Time: 1.74 seconds\n",
      "Epoch [893/1000], Train Loss: 0.0000016812, Train MSE: 0.0000000274,             Test MSE: 0.0000000348, Time: 1.75 seconds\n",
      "Epoch [894/1000], Train Loss: 0.0000001318, Train MSE: 0.0000048768,             Test MSE: 0.0000060954, Time: 1.75 seconds\n",
      "Epoch [895/1000], Train Loss: 0.0000020528, Train MSE: 0.0000000033,             Test MSE: 0.0000000037, Time: 1.92 seconds\n",
      "Epoch [896/1000], Train Loss: 0.0000009406, Train MSE: 0.0000014124,             Test MSE: 0.0000017432, Time: 1.72 seconds\n",
      "Epoch [897/1000], Train Loss: 0.0000012350, Train MSE: 0.0000027979,             Test MSE: 0.0000033003, Time: 1.81 seconds\n",
      "Epoch [898/1000], Train Loss: 0.0000006995, Train MSE: 0.0000078130,             Test MSE: 0.0000093964, Time: 1.67 seconds\n",
      "Epoch [899/1000], Train Loss: 0.0000008068, Train MSE: 0.0000001620,             Test MSE: 0.0000002021, Time: 1.81 seconds\n",
      "Epoch [900/1000], Train Loss: 0.0000014243, Train MSE: 0.0000000092,             Test MSE: 0.0000000096, Time: 1.68 seconds\n",
      "Epoch [901/1000], Train Loss: 0.0000014808, Train MSE: 0.0000000385,             Test MSE: 0.0000000388, Time: 1.66 seconds\n",
      "Epoch [902/1000], Train Loss: 0.0000013084, Train MSE: 0.0000002110,             Test MSE: 0.0000002324, Time: 1.75 seconds\n",
      "Epoch [903/1000], Train Loss: 0.0000003263, Train MSE: 0.0000043985,             Test MSE: 0.0000053506, Time: 1.79 seconds\n",
      "Epoch [904/1000], Train Loss: 0.0000009767, Train MSE: 0.0000001155,             Test MSE: 0.0000001392, Time: 1.73 seconds\n",
      "Epoch [905/1000], Train Loss: 0.0000017144, Train MSE: 0.0000000117,             Test MSE: 0.0000000114, Time: 1.65 seconds\n",
      "Epoch [906/1000], Train Loss: 0.0000009934, Train MSE: 0.0000000086,             Test MSE: 0.0000000126, Time: 1.81 seconds\n",
      "Epoch [907/1000], Train Loss: 0.0000014369, Train MSE: 0.0000003906,             Test MSE: 0.0000004697, Time: 1.85 seconds\n",
      "Epoch [908/1000], Train Loss: 0.0000010046, Train MSE: 0.0000007330,             Test MSE: 0.0000008689, Time: 1.84 seconds\n",
      "Epoch [909/1000], Train Loss: 0.0000004055, Train MSE: 0.0000010407,             Test MSE: 0.0000012795, Time: 1.64 seconds\n",
      "Epoch [910/1000], Train Loss: 0.0000012411, Train MSE: 0.0000002020,             Test MSE: 0.0000002415, Time: 1.79 seconds\n",
      "Epoch [911/1000], Train Loss: 0.0000014933, Train MSE: 0.0000005090,             Test MSE: 0.0000006438, Time: 1.63 seconds\n",
      "Epoch [912/1000], Train Loss: 0.0000011793, Train MSE: 0.0000016240,             Test MSE: 0.0000019952, Time: 1.60 seconds\n",
      "Epoch [913/1000], Train Loss: 0.0000011861, Train MSE: 0.0000025514,             Test MSE: 0.0000033058, Time: 1.82 seconds\n",
      "Epoch [914/1000], Train Loss: 0.0000002560, Train MSE: 0.0000014572,             Test MSE: 0.0000017667, Time: 1.71 seconds\n",
      "Epoch [915/1000], Train Loss: 0.0000016317, Train MSE: 0.0000000099,             Test MSE: 0.0000000112, Time: 1.80 seconds\n",
      "Epoch [916/1000], Train Loss: 0.0000016586, Train MSE: 0.0000003707,             Test MSE: 0.0000004515, Time: 1.74 seconds\n",
      "Epoch [917/1000], Train Loss: 0.0000000553, Train MSE: 0.0000002447,             Test MSE: 0.0000002859, Time: 1.76 seconds\n",
      "Epoch [918/1000], Train Loss: 0.0000019116, Train MSE: 0.0000000062,             Test MSE: 0.0000000066, Time: 2.08 seconds\n",
      "Epoch [919/1000], Train Loss: 0.0000013964, Train MSE: 0.0000040623,             Test MSE: 0.0000049632, Time: 1.70 seconds\n",
      "Epoch [920/1000], Train Loss: 0.0000003041, Train MSE: 0.0000000409,             Test MSE: 0.0000000503, Time: 1.69 seconds\n",
      "Epoch [921/1000], Train Loss: 0.0000013647, Train MSE: 0.0000000157,             Test MSE: 0.0000000170, Time: 1.64 seconds\n",
      "Epoch [922/1000], Train Loss: 0.0000017904, Train MSE: 0.0000009318,             Test MSE: 0.0000010751, Time: 1.80 seconds\n",
      "Epoch [923/1000], Train Loss: 0.0000000767, Train MSE: 0.0000000132,             Test MSE: 0.0000000159, Time: 1.70 seconds\n",
      "Epoch [924/1000], Train Loss: 0.0000015501, Train MSE: 0.0000000320,             Test MSE: 0.0000000379, Time: 1.79 seconds\n",
      "Epoch [925/1000], Train Loss: 0.0000014665, Train MSE: 0.0000313737,             Test MSE: 0.0000373645, Time: 1.77 seconds\n",
      "Epoch [926/1000], Train Loss: 0.0000018012, Train MSE: 0.0000000017,             Test MSE: 0.0000000125, Time: 1.70 seconds\n",
      "Epoch [927/1000], Train Loss: 0.0000000043, Train MSE: 0.0000000292,             Test MSE: 0.0000000359, Time: 1.65 seconds\n",
      "Epoch [928/1000], Train Loss: 0.0000017351, Train MSE: 0.0000000104,             Test MSE: 0.0000000101, Time: 1.79 seconds\n",
      "Epoch [929/1000], Train Loss: 0.0000000503, Train MSE: 0.0000006103,             Test MSE: 0.0000007154, Time: 1.76 seconds\n",
      "Epoch [930/1000], Train Loss: 0.0000015006, Train MSE: 0.0000000386,             Test MSE: 0.0000000361, Time: 1.76 seconds\n",
      "Epoch [931/1000], Train Loss: 0.0000013248, Train MSE: 0.0000009223,             Test MSE: 0.0000011405, Time: 1.81 seconds\n",
      "Epoch [932/1000], Train Loss: 0.0000002326, Train MSE: 0.0000003489,             Test MSE: 0.0000004377, Time: 1.69 seconds\n",
      "Epoch [933/1000], Train Loss: 0.0000021599, Train MSE: 0.0000000007,             Test MSE: 0.0000000012, Time: 1.67 seconds\n",
      "Epoch [934/1000], Train Loss: 0.0000005750, Train MSE: 0.0000115277,             Test MSE: 0.0000137516, Time: 1.72 seconds\n",
      "Epoch [935/1000], Train Loss: 0.0000008538, Train MSE: 0.0000000040,             Test MSE: 0.0000000150, Time: 1.65 seconds\n",
      "Epoch [936/1000], Train Loss: 0.0000014990, Train MSE: 0.0000000240,             Test MSE: 0.0000000315, Time: 1.74 seconds\n",
      "Epoch [937/1000], Train Loss: 0.0000010689, Train MSE: 0.0000000378,             Test MSE: 0.0000000441, Time: 1.74 seconds\n",
      "Epoch [938/1000], Train Loss: 0.0000010801, Train MSE: 0.0000007720,             Test MSE: 0.0000009692, Time: 1.81 seconds\n",
      "Epoch [939/1000], Train Loss: 0.0000005826, Train MSE: 0.0000002178,             Test MSE: 0.0000002582, Time: 1.91 seconds\n",
      "Epoch [940/1000], Train Loss: 0.0000011058, Train MSE: 0.0000000531,             Test MSE: 0.0000000628, Time: 1.65 seconds\n",
      "Epoch [941/1000], Train Loss: 0.0000011665, Train MSE: 0.0000000063,             Test MSE: 0.0000000062, Time: 1.92 seconds\n",
      "Epoch [942/1000], Train Loss: 0.0000011536, Train MSE: 0.0000000008,             Test MSE: 0.0000000008, Time: 1.92 seconds\n",
      "Epoch [943/1000], Train Loss: 0.0000010984, Train MSE: 0.0000000115,             Test MSE: 0.0000000126, Time: 2.56 seconds\n",
      "Epoch [944/1000], Train Loss: 0.0000016070, Train MSE: 0.0000001453,             Test MSE: 0.0000001858, Time: 2.12 seconds\n",
      "Epoch [945/1000], Train Loss: 0.0000000135, Train MSE: 0.0000000192,             Test MSE: 0.0000000227, Time: 2.11 seconds\n",
      "Epoch [946/1000], Train Loss: 0.0000030715, Train MSE: 0.0000000179,             Test MSE: 0.0000000194, Time: 2.26 seconds\n",
      "Epoch [947/1000], Train Loss: 0.0000000018, Train MSE: 0.0000000001,             Test MSE: 0.0000000001, Time: 2.02 seconds\n",
      "Epoch [948/1000], Train Loss: 0.0000020633, Train MSE: 0.0000039052,             Test MSE: 0.0000048142, Time: 2.29 seconds\n",
      "Epoch [949/1000], Train Loss: 0.0000002919, Train MSE: 0.0000000001,             Test MSE: 0.0000000002, Time: 1.92 seconds\n",
      "Epoch [950/1000], Train Loss: 0.0000009560, Train MSE: 0.0000014164,             Test MSE: 0.0000017759, Time: 1.88 seconds\n",
      "Epoch [951/1000], Train Loss: 0.0000014412, Train MSE: 0.0000055158,             Test MSE: 0.0000065728, Time: 1.97 seconds\n",
      "Epoch [952/1000], Train Loss: 0.0000003926, Train MSE: 0.0000000011,             Test MSE: 0.0000000013, Time: 1.90 seconds\n",
      "Epoch [953/1000], Train Loss: 0.0000015775, Train MSE: 0.0000000178,             Test MSE: 0.0000000334, Time: 1.97 seconds\n",
      "Epoch [954/1000], Train Loss: 0.0000008926, Train MSE: 0.0000151746,             Test MSE: 0.0000173510, Time: 2.07 seconds\n",
      "Epoch [955/1000], Train Loss: 0.0000009581, Train MSE: 0.0000000005,             Test MSE: 0.0000000006, Time: 2.07 seconds\n",
      "Epoch [956/1000], Train Loss: 0.0000013161, Train MSE: 0.0000001930,             Test MSE: 0.0000002146, Time: 2.13 seconds\n",
      "Epoch [957/1000], Train Loss: 0.0000013469, Train MSE: 0.0000015463,             Test MSE: 0.0000016052, Time: 2.05 seconds\n",
      "Epoch [958/1000], Train Loss: 0.0000004852, Train MSE: 0.0000000000,             Test MSE: 0.0000000010, Time: 1.65 seconds\n",
      "Epoch [959/1000], Train Loss: 0.0000015927, Train MSE: 0.0000003974,             Test MSE: 0.0000004747, Time: 1.72 seconds\n",
      "Epoch [960/1000], Train Loss: 0.0000000507, Train MSE: 0.0000009151,             Test MSE: 0.0000010687, Time: 1.71 seconds\n",
      "Epoch [961/1000], Train Loss: 0.0000015740, Train MSE: 0.0000000040,             Test MSE: 0.0000000045, Time: 1.98 seconds\n",
      "Epoch [962/1000], Train Loss: 0.0000018241, Train MSE: 0.0000006253,             Test MSE: 0.0000008947, Time: 1.77 seconds\n",
      "Epoch [963/1000], Train Loss: 0.0000000387, Train MSE: 0.0000000511,             Test MSE: 0.0000000613, Time: 1.57 seconds\n",
      "Epoch [964/1000], Train Loss: 0.0000013459, Train MSE: 0.0000000249,             Test MSE: 0.0000000270, Time: 1.52 seconds\n",
      "Epoch [965/1000], Train Loss: 0.0000012985, Train MSE: 0.0000000003,             Test MSE: 0.0000000007, Time: 1.66 seconds\n",
      "Epoch [966/1000], Train Loss: 0.0000014091, Train MSE: 0.0000000214,             Test MSE: 0.0000000208, Time: 2.14 seconds\n",
      "Epoch [967/1000], Train Loss: 0.0000001648, Train MSE: 0.0000000116,             Test MSE: 0.0000000143, Time: 1.88 seconds\n",
      "Epoch [968/1000], Train Loss: 0.0000015028, Train MSE: 0.0000000543,             Test MSE: 0.0000000584, Time: 1.94 seconds\n",
      "Epoch [969/1000], Train Loss: 0.0000010196, Train MSE: 0.0000002062,             Test MSE: 0.0000002556, Time: 2.05 seconds\n",
      "Epoch [970/1000], Train Loss: 0.0000009139, Train MSE: 0.0000000411,             Test MSE: 0.0000000519, Time: 1.95 seconds\n",
      "Epoch [971/1000], Train Loss: 0.0000009128, Train MSE: 0.0000000002,             Test MSE: 0.0000000004, Time: 1.92 seconds\n",
      "Epoch [972/1000], Train Loss: 0.0000015426, Train MSE: 0.0000001901,             Test MSE: 0.0000002159, Time: 1.94 seconds\n",
      "Epoch [973/1000], Train Loss: 0.0000010958, Train MSE: 0.0000070296,             Test MSE: 0.0000083262, Time: 2.12 seconds\n",
      "Epoch [974/1000], Train Loss: 0.0000005687, Train MSE: 0.0000000034,             Test MSE: 0.0000000052, Time: 2.13 seconds\n",
      "Epoch [975/1000], Train Loss: 0.0000016101, Train MSE: 0.0000000186,             Test MSE: 0.0000000227, Time: 2.23 seconds\n",
      "Epoch [976/1000], Train Loss: 0.0000000602, Train MSE: 0.0000003677,             Test MSE: 0.0000004305, Time: 2.13 seconds\n",
      "Epoch [977/1000], Train Loss: 0.0000020931, Train MSE: 0.0000000004,             Test MSE: 0.0000000006, Time: 2.07 seconds\n",
      "Epoch [978/1000], Train Loss: 0.0000004839, Train MSE: 0.0000125189,             Test MSE: 0.0000148925, Time: 2.04 seconds\n",
      "Epoch [979/1000], Train Loss: 0.0000011595, Train MSE: 0.0000000017,             Test MSE: 0.0000000027, Time: 2.12 seconds\n",
      "Epoch [980/1000], Train Loss: 0.0000021166, Train MSE: 0.0000000754,             Test MSE: 0.0000001003, Time: 2.11 seconds\n",
      "Epoch [981/1000], Train Loss: 0.0000000519, Train MSE: 0.0000000163,             Test MSE: 0.0000000208, Time: 1.85 seconds\n",
      "Epoch [982/1000], Train Loss: 0.0000013230, Train MSE: 0.0000002091,             Test MSE: 0.0000002491, Time: 1.73 seconds\n",
      "Epoch [983/1000], Train Loss: 0.0000011585, Train MSE: 0.0000008290,             Test MSE: 0.0000010668, Time: 1.92 seconds\n",
      "Epoch [984/1000], Train Loss: 0.0000006093, Train MSE: 0.0000016369,             Test MSE: 0.0000019009, Time: 1.92 seconds\n",
      "Epoch [985/1000], Train Loss: 0.0000015899, Train MSE: 0.0000004362,             Test MSE: 0.0000005168, Time: 1.92 seconds\n",
      "Epoch [986/1000], Train Loss: 0.0000004878, Train MSE: 0.0000061111,             Test MSE: 0.0000070325, Time: 1.89 seconds\n",
      "Epoch [987/1000], Train Loss: 0.0000010005, Train MSE: 0.0000110011,             Test MSE: 0.0000127656, Time: 1.74 seconds\n",
      "Epoch [988/1000], Train Loss: 0.0000010339, Train MSE: 0.0000000105,             Test MSE: 0.0000000176, Time: 1.84 seconds\n",
      "Epoch [989/1000], Train Loss: 0.0000010237, Train MSE: 0.0000000757,             Test MSE: 0.0000000828, Time: 1.92 seconds\n",
      "Epoch [990/1000], Train Loss: 0.0000007320, Train MSE: 0.0000015264,             Test MSE: 0.0000017290, Time: 1.83 seconds\n",
      "Epoch [991/1000], Train Loss: 0.0000011964, Train MSE: 0.0000000710,             Test MSE: 0.0000000804, Time: 1.82 seconds\n",
      "Epoch [992/1000], Train Loss: 0.0000011290, Train MSE: 0.0000006908,             Test MSE: 0.0000008358, Time: 1.81 seconds\n",
      "Epoch [993/1000], Train Loss: 0.0000016666, Train MSE: 0.0000006178,             Test MSE: 0.0000008272, Time: 1.93 seconds\n",
      "Epoch [994/1000], Train Loss: 0.0000000323, Train MSE: 0.0000000556,             Test MSE: 0.0000000660, Time: 1.94 seconds\n",
      "Epoch [995/1000], Train Loss: 0.0000022752, Train MSE: 0.0000000150,             Test MSE: 0.0000000183, Time: 1.84 seconds\n",
      "Epoch [996/1000], Train Loss: 0.0000000113, Train MSE: 0.0000000087,             Test MSE: 0.0000000097, Time: 1.92 seconds\n",
      "Epoch [997/1000], Train Loss: 0.0000017364, Train MSE: 0.0000000044,             Test MSE: 0.0000000042, Time: 1.95 seconds\n",
      "Epoch [998/1000], Train Loss: 0.0000013339, Train MSE: 0.0000000063,             Test MSE: 0.0000000096, Time: 1.81 seconds\n",
      "Epoch [999/1000], Train Loss: 0.0000004611, Train MSE: 0.0000000003,             Test MSE: 0.0000000037, Time: 1.92 seconds\n",
      "Epoch [1000/1000], Train Loss: 0.0000010810, Train MSE: 0.0000001747,             Test MSE: 0.0000002173, Time: 1.86 seconds\n",
      "Total Training Time: 1778.34 seconds\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_mses, test_mses = train(model, train_loader, test_loader, criterion, optimizer, 1000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(train, test, title, metric):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(train)\n",
    "    plt.plot(test)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(train_mses, test_mses, 'MSE over Epochs', 'Mean Squared Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046612084836225094 %\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(test_mses[-1]) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close_log</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Difference_Percentage</th>\n",
       "      <th>Following_Day_Difference_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3628</th>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>60380.953125</td>\n",
       "      <td>64947.062500</td>\n",
       "      <td>60372.050781</td>\n",
       "      <td>64094.355469</td>\n",
       "      <td>42530509233</td>\n",
       "      <td>4.806820</td>\n",
       "      <td>3713.402344</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.001172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3629</th>\n",
       "      <td>2024-08-24</td>\n",
       "      <td>64103.871094</td>\n",
       "      <td>64513.789063</td>\n",
       "      <td>63619.917969</td>\n",
       "      <td>64178.992188</td>\n",
       "      <td>21430585163</td>\n",
       "      <td>4.807393</td>\n",
       "      <td>75.121094</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.002449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>2024-08-25</td>\n",
       "      <td>64176.367188</td>\n",
       "      <td>64996.421875</td>\n",
       "      <td>63833.519531</td>\n",
       "      <td>64333.542969</td>\n",
       "      <td>18827683555</td>\n",
       "      <td>4.808437</td>\n",
       "      <td>157.175781</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>-0.022716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>2024-08-26</td>\n",
       "      <td>64342.226563</td>\n",
       "      <td>64489.707031</td>\n",
       "      <td>62849.558594</td>\n",
       "      <td>62880.660156</td>\n",
       "      <td>27682040631</td>\n",
       "      <td>4.798517</td>\n",
       "      <td>-1461.566407</td>\n",
       "      <td>-0.022716</td>\n",
       "      <td>-0.053683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>2024-08-27</td>\n",
       "      <td>62879.707031</td>\n",
       "      <td>63210.796875</td>\n",
       "      <td>58116.750000</td>\n",
       "      <td>59504.132813</td>\n",
       "      <td>39103882198</td>\n",
       "      <td>4.774547</td>\n",
       "      <td>-3375.574218</td>\n",
       "      <td>-0.053683</td>\n",
       "      <td>-0.008071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>59507.925781</td>\n",
       "      <td>60236.449219</td>\n",
       "      <td>57890.675781</td>\n",
       "      <td>59027.625000</td>\n",
       "      <td>40289564698</td>\n",
       "      <td>4.771055</td>\n",
       "      <td>-480.300781</td>\n",
       "      <td>-0.008071</td>\n",
       "      <td>0.006111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>59027.468750</td>\n",
       "      <td>61184.082031</td>\n",
       "      <td>58786.226563</td>\n",
       "      <td>59388.179688</td>\n",
       "      <td>32224990582</td>\n",
       "      <td>4.773700</td>\n",
       "      <td>360.710938</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>0.002597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          Open          High           Low         Close  \\\n",
       "3628  2024-08-23  60380.953125  64947.062500  60372.050781  64094.355469   \n",
       "3629  2024-08-24  64103.871094  64513.789063  63619.917969  64178.992188   \n",
       "3630  2024-08-25  64176.367188  64996.421875  63833.519531  64333.542969   \n",
       "3631  2024-08-26  64342.226563  64489.707031  62849.558594  62880.660156   \n",
       "3632  2024-08-27  62879.707031  63210.796875  58116.750000  59504.132813   \n",
       "3633  2024-08-28  59507.925781  60236.449219  57890.675781  59027.625000   \n",
       "3634  2024-08-29  59027.468750  61184.082031  58786.226563  59388.179688   \n",
       "\n",
       "           Volume  Close_log   Difference  Difference_Percentage  \\\n",
       "3628  42530509233   4.806820  3713.402344               0.061500   \n",
       "3629  21430585163   4.807393    75.121094               0.001172   \n",
       "3630  18827683555   4.808437   157.175781               0.002449   \n",
       "3631  27682040631   4.798517 -1461.566407              -0.022716   \n",
       "3632  39103882198   4.774547 -3375.574218              -0.053683   \n",
       "3633  40289564698   4.771055  -480.300781              -0.008071   \n",
       "3634  32224990582   4.773700   360.710938               0.006111   \n",
       "\n",
       "      Following_Day_Difference_Percentage  \n",
       "3628                             0.001172  \n",
       "3629                             0.002449  \n",
       "3630                            -0.022716  \n",
       "3631                            -0.053683  \n",
       "3632                            -0.008071  \n",
       "3633                             0.006111  \n",
       "3634                             0.002597  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last7 = cleaned_data.tail(7)\n",
    "last7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tulio\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 7])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the last 7 sequences\n",
    "last7_sequences = last7[['Open', 'High', 'Low', 'Close', 'Volume', 'Close_log', 'Difference', 'Difference_Percentage']].values\n",
    "\n",
    "# Standardize the data\n",
    "last7_sequences = scaler.transform(last7_sequences)\n",
    "\n",
    "# Reshape the data into sequences (assuming SEQUENCE_LENGTH = 7)\n",
    "# In this case, you don't need to create sequences as you are using the entire last7 as input\n",
    "\n",
    "# Reshape to match model input shape (batch_size, num_features, sequence_length)\n",
    "last7_sequences = np.expand_dims(last7_sequences.T, axis=0)\n",
    "\n",
    "# Convert to PyTorch tensor and move to the appropriate device\n",
    "x_pred = torch.tensor(last7_sequences, dtype=torch.float32).to(DEVICE)\n",
    "x_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Following Day Difference Percentage: -0.06074566626921296 %\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    prediction = model(x_pred)\n",
    "\n",
    "# Convert the prediction to numpy (if needed) and display it\n",
    "prediction = prediction.cpu().numpy()\n",
    "print(\"Predicted Following Day Difference Percentage:\", prediction * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
